{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c81aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU dispon√≠vel: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Importa√ß√µes essenciais para deep learning e processamento de dados\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import time\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "\n",
    "# Configura√ß√£o de reprodutibilidade\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU dispon√≠vel: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498c1f9-ddf9-43d5-8bbd-379b72bbf1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configura√ß√µes definidas:\n",
      "- Tamanho da imagem: 96x96\n",
      "- Batch size: 32\n",
      "- √âpocas m√°ximas: 100\n",
      "- Classes de emo√ß√£o: 7\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes do experimento\n",
    "IMG_SIZE = 224  # Tamanho da imagem (224x224 pixels)\n",
    "BATCH_SIZE = 32  # Tamanho do lote para treinamento\n",
    "EPOCHS = 100  # N√∫mero m√°ximo de √©pocas\n",
    "VALIDATION_SPLIT = 0.3  # 30% dos dados para valida√ß√£o\n",
    "\n",
    "# Caminhos dos datasets\n",
    "FER2013_PATH = r\"src/data/FER2013\"\n",
    "RAF_DB_PATH = r\"src/data/ RAF-DB\"\n",
    "DFEW_DB_PATH = r\"src/data/DFEW\"\n",
    "\n",
    "\n",
    "# Mapeamento das 7 emo√ß√µes b√°sicas\n",
    "EMOTION_LABELS = {\n",
    "    'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, \n",
    "    'neutral': 4, 'sadness': 5, 'surprise': 6\n",
    "}\n",
    "\n",
    "print(\"Configura√ß√µes definidas:\")\n",
    "print(f\"- Tamanho da imagem: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- √âpocas m√°ximas: {EPOCHS}\")\n",
    "print(f\"- Classes de emo√ß√£o: {len(EMOTION_LABELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8260fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor:\n",
    "    \"\"\"\n",
    "    Classe para monitorar desempenho computacional durante o treinamento.\n",
    "    Essencial para experimentos cient√≠ficos reproduz√≠veis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.peak_memory_mb = 0\n",
    "        self.initial_memory_mb = 0\n",
    "        self.process = psutil.Process()\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Inicia o monitoramento de tempo e mem√≥ria\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.initial_memory_mb = self._get_memory_usage()\n",
    "        self.peak_memory_mb = self.initial_memory_mb\n",
    "        print(f\"Iniciando treinamento ResNet50...\")\n",
    "        print(f\"Hor√°rio de in√≠cio: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Mem√≥ria inicial: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    def _get_memory_usage(self):\n",
    "        \"\"\"Retorna uso atual de mem√≥ria em MB\"\"\"\n",
    "        return self.process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "    def update_peak_memory(self):\n",
    "        \"\"\"Atualiza o pico de mem√≥ria se necess√°rio\"\"\"\n",
    "        current_memory = self._get_memory_usage()\n",
    "        if current_memory > self.peak_memory_mb:\n",
    "            self.peak_memory_mb = current_memory\n",
    "\n",
    "# Instancia o monitor\n",
    "monitor = TrainingMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data_resnet50_from_images():\n",
    "    \"\"\"\n",
    "    Carrega dados pr√©-processados de imagens JPG com normaliza√ß√£o espec√≠fica para ResNet50.\n",
    "    ResNet50 usa normaliza√ß√£o [0, 1] padr√£o.\n",
    "    \n",
    "    Estrutura esperada:\n",
    "    data/processed/raf_db_temp_gray_aligned/\n",
    "    ‚îú‚îÄ‚îÄ Raiva/\n",
    "    ‚îú‚îÄ‚îÄ Nojo/\n",
    "    ‚îú‚îÄ‚îÄ Medo/\n",
    "    ‚îú‚îÄ‚îÄ Felicidade/\n",
    "    ‚îú‚îÄ‚îÄ Neutro/\n",
    "    ‚îú‚îÄ‚îÄ Tristeza/\n",
    "    ‚îî‚îÄ‚îÄ Surpresa/\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from collections import Counter\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    print(\"Carregando dados pr√©-processados JPG para ResNet50...\")\n",
    "    \n",
    "    # Configura√ß√µes\n",
    "    IMG_SIZE = 224  # Tamanho padr√£o para ResNet50\n",
    "    BASE_PATH = r\".\\data\\processed\\raf_db_temp_gray_aligned\"  # Ajuste para seu caminho\n",
    "    \n",
    "    # Mapeamento das emo√ß√µes em portugu√™s\n",
    "    EMOTION_LABELS = {\n",
    "        'Raiva': 0, 'Nojo': 1, 'Medo': 2, 'Felicidade': 3, \n",
    "        'Neutro': 4, 'Tristeza': 5, 'Surpresa': 6\n",
    "    }\n",
    "    \n",
    "    def load_images_from_directory(directory_path, set_name):\n",
    "        \"\"\"Carrega imagens de um diret√≥rio usando os.path.join\"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(f\"Carregando {set_name} de: {directory_path}\")\n",
    "        \n",
    "        # Verifica se o diret√≥rio existe\n",
    "        if not os.path.exists(directory_path):\n",
    "            print(f\"‚ùå Diret√≥rio n√£o encontrado: {directory_path}\")\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        # Lista subdiret√≥rios (emo√ß√µes)\n",
    "        subdirs = [d for d in os.listdir(directory_path) \n",
    "                  if os.path.isdir(os.path.join(directory_path, d))]\n",
    "        \n",
    "        print(f\"üìÅ Subdiret√≥rios encontrados: {subdirs}\")\n",
    "        \n",
    "        for emotion, label in EMOTION_LABELS.items():\n",
    "            # Usar os.path.join ao inv√©s de /\n",
    "            emotion_path = os.path.join(directory_path, emotion)\n",
    "            \n",
    "            if not os.path.exists(emotion_path):\n",
    "                print(f\"‚ö†Ô∏è  Pasta '{emotion}' n√£o encontrada em {directory_path}\")\n",
    "                print(f\"    Tentando varia√ß√µes de nome...\")\n",
    "                \n",
    "                # Tenta varia√ß√µes do nome da emo√ß√£o\n",
    "                emotion_variations = [\n",
    "                    emotion.lower(),\n",
    "                    emotion.upper(), \n",
    "                    emotion.capitalize(),\n",
    "                    emotion.replace('√ß', 'c'),  # Felicidade -> Felicidade\n",
    "                    emotion.replace('√£', 'a')   # Raiva -> Raiva\n",
    "                ]\n",
    "                \n",
    "                found = False\n",
    "                for variation in emotion_variations:\n",
    "                    test_path = os.path.join(directory_path, variation)\n",
    "                    if os.path.exists(test_path):\n",
    "                        emotion_path = test_path\n",
    "                        print(f\"    ‚úÖ Encontrado: {variation}\")\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    print(f\"    ‚ùå Nenhuma varia√ß√£o encontrada para '{emotion}'\")\n",
    "                    continue\n",
    "            \n",
    "            # Carrega imagens da pasta da emo√ß√£o\n",
    "            count = 0\n",
    "            image_files = []\n",
    "            \n",
    "            # Busca diferentes extens√µes\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "                import glob\n",
    "                pattern = os.path.join(emotion_path, ext)\n",
    "                image_files.extend(glob.glob(pattern))\n",
    "            \n",
    "            print(f\"  üì∏ {emotion}: {len(image_files)} arquivos encontrados\")\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                try:\n",
    "                    # Carrega imagem\n",
    "                    img = cv2.imread(img_file)\n",
    "                    if img is None:\n",
    "                        print(f\"    ‚ö†Ô∏è N√£o foi poss√≠vel carregar: {os.path.basename(img_file)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Converte BGR para RGB\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Redimensiona se necess√°rio\n",
    "                    if img.shape[:2] != (IMG_SIZE, IMG_SIZE):\n",
    "                        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "                    \n",
    "                    # Garante que seja RGB (3 canais)\n",
    "                    if len(img.shape) == 2:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                    elif img.shape[2] == 1:\n",
    "                        img = np.repeat(img, 3, axis=2)\n",
    "                    elif img.shape[2] == 4:  # RGBA\n",
    "                        img = img[:, :, :3]  # Remove canal alpha\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                    count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Erro ao carregar {os.path.basename(img_file)}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  ‚úÖ {emotion}: {count} imagens carregadas com sucesso\")\n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def detect_data_structure(base_path):\n",
    "        \"\"\"Detecta a estrutura dos dados automaticamente\"\"\"\n",
    "        print(f\"üîç Analisando estrutura de: {base_path}\")\n",
    "        \n",
    "        if not os.path.exists(base_path):\n",
    "            print(f\"‚ùå Caminho base n√£o existe: {base_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Lista conte√∫do do diret√≥rio\n",
    "        contents = os.listdir(base_path)\n",
    "        dirs = [d for d in contents if os.path.isdir(os.path.join(base_path, d))]\n",
    "        files = [f for f in contents if os.path.isfile(os.path.join(base_path, f))]\n",
    "        \n",
    "        print(f\"üìÅ Diret√≥rios: {dirs}\")\n",
    "        print(f\"üìÑ Arquivos: {len(files)} encontrados\")\n",
    "        \n",
    "        # Verifica se tem estrutura train/test\n",
    "        if 'train' in dirs and 'test' in dirs:\n",
    "            print(\"‚úÖ Estrutura detectada: train/test/emotion/\")\n",
    "            return 'train_test'\n",
    "        \n",
    "        # Verifica se as pastas s√£o emo√ß√µes diretamente\n",
    "        emotion_names = set(EMOTION_LABELS.keys())\n",
    "        found_emotions = set(dirs) & emotion_names\n",
    "        \n",
    "        if found_emotions:\n",
    "            print(f\"‚úÖ Estrutura detectada: emotion/ direta - Emo√ß√µes: {found_emotions}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        # Verifica varia√ß√µes de nomes\n",
    "        emotion_variations = []\n",
    "        for emotion in EMOTION_LABELS.keys():\n",
    "            variations = [emotion.lower(), emotion.upper(), emotion.capitalize()]\n",
    "            emotion_variations.extend(variations)\n",
    "        \n",
    "        found_variations = set(dirs) & set(emotion_variations)\n",
    "        if found_variations:\n",
    "            print(f\"‚úÖ Estrutura detectada: emotion/ com varia√ß√µes - Encontradas: {found_variations}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        print(\"‚ö†Ô∏è Estrutura n√£o reconhecida automaticamente\")\n",
    "        return 'unknown'\n",
    "    \n",
    "    try:\n",
    "        # Detecta estrutura automaticamente\n",
    "        structure = detect_data_structure(BASE_PATH)\n",
    "        \n",
    "        if structure == 'train_test':\n",
    "            # Estrutura: base/train/emotion/ e base/test/emotion/\n",
    "            train_path = os.path.join(BASE_PATH, \"train\")\n",
    "            test_path = os.path.join(BASE_PATH, \"test\")\n",
    "            \n",
    "            X_train, y_train = load_images_from_directory(train_path, \"TREINO\")\n",
    "            X_test, y_test = load_images_from_directory(test_path, \"TESTE\")\n",
    "            \n",
    "        elif structure == 'emotion_direct':\n",
    "            # Estrutura: base/emotion/ - precisa criar train/test split\n",
    "            print(\"üìä Carregando todas as imagens e criando divis√£o train/test...\")\n",
    "            \n",
    "            all_images, all_labels = load_images_from_directory(BASE_PATH, \"TODAS AS IMAGENS\")\n",
    "            \n",
    "            if len(all_images) == 0:\n",
    "                print(\"‚ùå Nenhuma imagem carregada!\")\n",
    "                return None, None, None, None\n",
    "            \n",
    "            # Cria divis√£o train/test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                all_images, all_labels,\n",
    "                test_size=0.2,\n",
    "                stratify=all_labels,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Divis√£o train/test criada automaticamente (80/20)\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå Estrutura de dados n√£o suportada!\")\n",
    "            print(\"üí° Estruturas esperadas:\")\n",
    "            print(\"   1. base/train/Raiva/*.jpg, base/train/Nojo/*.jpg, etc.\")\n",
    "            print(\"   2. base/Raiva/*.jpg, base/Nojo/*.jpg, etc.\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            print(\"‚ùå Nenhuma imagem carregada. Verifique os caminhos e nomes das pastas!\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        print(f\"\\nüìä Dados carregados com sucesso:\")\n",
    "        print(f\"- X_train: {X_train.shape}\")\n",
    "        print(f\"- y_train: {y_train.shape}\")\n",
    "        print(f\"- X_test: {X_test.shape}\")\n",
    "        print(f\"- y_test: {y_test.shape}\")\n",
    "        \n",
    "        # NORMALIZA√á√ÉO ESPEC√çFICA PARA RESNET50: [0, 255] -> [0, 1]\n",
    "        print(\"üîÑ Aplicando normaliza√ß√£o ResNet50...\")\n",
    "        \n",
    "        X_train = X_train.astype(np.float32)\n",
    "        X_test = X_test.astype(np.float32)\n",
    "        \n",
    "        # ResNet50 normaliza√ß√£o padr√£o: [0, 255] -> [0, 1]\n",
    "        X_train = X_train / 255.0\n",
    "        X_test = X_test / 255.0\n",
    "        \n",
    "        print(\"‚úÖ Normaliza√ß√£o ResNet50 aplicada: [0,255] -> [0,1]\")\n",
    "        \n",
    "        # Verifica resultado final\n",
    "        print(f\"\\nüîç Verifica√ß√£o final:\")\n",
    "        print(f\"- X_train range: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "        print(f\"- X_test range: [{X_test.min():.3f}, {X_test.max():.3f}]\")\n",
    "        print(f\"- Formato das imagens: {X_train.shape[1:]} (deve ser {IMG_SIZE}x{IMG_SIZE}x3)\")\n",
    "        \n",
    "        # Verifica distribui√ß√£o de classes\n",
    "        train_distribution = dict(Counter(y_train))\n",
    "        test_distribution = dict(Counter(y_test))\n",
    "        \n",
    "        print(f\"\\nüìà Distribui√ß√£o de classes:\")\n",
    "        emotion_names = list(EMOTION_LABELS.keys())\n",
    "        print(\"- Treino:\")\n",
    "        for label, count in train_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        print(\"- Teste:\")\n",
    "        for label, count in test_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar dados: {e}\")\n",
    "        print(f\"üìç Erro detalhado: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(\"\\nüí° Solu√ß√µes poss√≠veis:\")\n",
    "        print(\"1. Verifique se o caminho est√° correto\")\n",
    "        print(\"2. Verifique se as pastas de emo√ß√µes existem\")\n",
    "        print(\"3. Verifique se h√° imagens nas pastas\")\n",
    "        print(\"4. Verifique permiss√µes de acesso\")\n",
    "        \n",
    "        return None, None, None, None\n",
    "\n",
    "# Executa carregamento para ResNet50\n",
    "X_train, y_train, X_test, y_test = load_preprocessed_data_resnet50_from_images()\n",
    "monitor.update_peak_memory()\n",
    "\n",
    "if X_train is not None:\n",
    "    print(f\"\\nüéØ ResNet50: Dados prontos para treinamento!\")\n",
    "    print(f\"üìè Formato final: {X_train.shape}\")\n",
    "    print(f\"üé® Range de valores: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "    print(f\"‚úÖ Pronto para ResNet50!\")\n",
    "else:\n",
    "    print(\"‚ùå Falha no carregamento dos dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment_structure():\n",
    "    \"\"\"\n",
    "    Cria estrutura de diret√≥rios para salvar modelos e m√©tricas.\n",
    "    \"\"\"\n",
    "    # Cria timestamp √∫nico para o experimento\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    experiment_id = f\"resnet50_emotion_{timestamp}\"\n",
    "    \n",
    "    # Cria diret√≥rios\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"metrics\", exist_ok=True)\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    \n",
    "    return experiment_id\n",
    "\n",
    "def save_model_if_good_performance(model, accuracy, f1_score, experiment_id, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Salva modelo apenas se a performance for boa.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        accuracy: Acur√°cia do modelo\n",
    "        f1_score: F1-score macro do modelo\n",
    "        experiment_id: ID √∫nico do experimento\n",
    "        threshold: Limite m√≠nimo para salvar (default: 85%)\n",
    "    \"\"\"\n",
    "    if accuracy >= threshold or f1_score >= threshold:\n",
    "        model_path = f\"models/resnet50_emotion_{experiment_id}.pkl\"\n",
    "        \n",
    "        # Salva apenas os pesos para economia de espa√ßo\n",
    "        model.save_weights(f\"models/weights_resnet50_{experiment_id}.h5\")\n",
    "        \n",
    "        # Salva configura√ß√£o do modelo\n",
    "        model_config = {\n",
    "            'architecture': 'ResNet50',\n",
    "            'img_size': IMG_SIZE,\n",
    "            'num_classes': 7,\n",
    "            'experiment_id': experiment_id,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_score,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(f\"models/config_resnet50_{experiment_id}.pkl\", 'wb') as f:\n",
    "            pickle.dump(model_config, f)\n",
    "        \n",
    "        print(f\"Modelo salvo! Performance: Acc={accuracy:.4f}, F1={f1_score:.4f}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Performance insuficiente para salvar. Acc={accuracy:.4f}, F1={f1_score:.4f} < {threshold}\")\n",
    "        return False\n",
    "\n",
    "def save_metrics_to_csv(metrics_dict, experiment_id):\n",
    "    \"\"\"\n",
    "    Salva m√©tricas de performance em arquivo CSV.\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: Dicion√°rio com todas as m√©tricas\n",
    "        experiment_id: ID √∫nico do experimento\n",
    "    \"\"\"\n",
    "    # Converte m√©tricas para DataFrame\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "    \n",
    "    # Arquivo CSV principal\n",
    "    csv_path = \"metrics/performance_metrics.csv\"\n",
    "    \n",
    "    # Append ao CSV se j√° existir, sen√£o cria novo\n",
    "    if os.path.exists(csv_path):\n",
    "        metrics_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Salva tamb√©m arquivo individual do experimento\n",
    "    individual_csv = f\"metrics/metrics_{experiment_id}.csv\"\n",
    "    metrics_df.to_csv(individual_csv, index=False)\n",
    "    \n",
    "    print(f\"M√©tricas salvas em: {csv_path} e {individual_csv}\")\n",
    "\n",
    "# Inicializa estrutura do experimento\n",
    "experiment_id = create_experiment_structure()\n",
    "print(f\"Experimento iniciado: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet50_model():\n",
    "    \"\"\"\n",
    "    Cria modelo ResNet50 com transfer learning para classifica√ß√£o de emo√ß√µes.\n",
    "    \n",
    "    Arquitetura:\n",
    "    - ResNet50 pr√©-treinado (ImageNet) como feature extractor\n",
    "    - Global Average Pooling para redu√ß√£o dimensional\n",
    "    - Camadas densas para classifica√ß√£o final\n",
    "    - Dropout para regulariza√ß√£o\n",
    "    \n",
    "    Returns:\n",
    "        keras.Model: Modelo compilado pronto para treinamento\n",
    "    \"\"\"\n",
    "    # Carrega ResNet50 pr√©-treinado no ImageNet\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',          # Pesos pr√©-treinados\n",
    "        include_top=False,           # Remove camadas de classifica√ß√£o originais\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)  # Define formato de entrada\n",
    "    )\n",
    "    \n",
    "    # Congela camadas base para transfer learning\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Adiciona camadas de classifica√ß√£o customizadas\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)           # Reduz dimensionalidade espacial\n",
    "    x = Dense(512, activation='relu')(x)       # Primeira camada densa\n",
    "    x = Dropout(0.5)(x)                       # Regulariza√ß√£o forte\n",
    "    x = Dense(256, activation='relu')(x)       # Segunda camada densa\n",
    "    x = Dropout(0.3)(x)                       # Regulariza√ß√£o moderada\n",
    "    predictions = Dense(7, activation='softmax')(x)  # Classifica√ß√£o final (7 emo√ß√µes)\n",
    "    \n",
    "    # Cria modelo final\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compila√ß√£o otimizada para classifica√ß√£o multiclasse\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Verifica se os dados foram carregados corretamente antes de criar o modelo\n",
    "if X_train is not None:\n",
    "    print(\"Criando modelo ResNet50 otimizado...\")\n",
    "    model, base_model = create_resnet50_model()\n",
    "    \n",
    "    print(f\"Modelo criado com sucesso:\")\n",
    "    print(f\"- Total de par√¢metros: {model.count_params():,}\")\n",
    "    print(f\"- Par√¢metros trein√°veis: {sum([tf.keras.backend.count_params(p) for p in model.trainable_weights]):,}\")\n",
    "    print(f\"- Camadas congeladas: {len([l for l in base_model.layers if not l.trainable])}\")\n",
    "    \n",
    "    monitor.update_peak_memory()\n",
    "else:\n",
    "    print(\"Erro: Dados n√£o carregados. Verifique a c√©lula anterior.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback customizado para monitoramento de mem√≥ria durante treinamento.\n",
    "    Essencial para experimentos com recursos limitados.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.monitor.update_peak_memory()\n",
    "        if epoch % 5 == 0:  # Log a cada 5 √©pocas\n",
    "            current_memory = self.monitor._get_memory_usage()\n",
    "            print(f\"√âpoca {epoch+1} - Mem√≥ria atual: {current_memory:.2f} MB\")\n",
    "\n",
    "def setup_training_callbacks(monitor):\n",
    "    \"\"\"\n",
    "    Configura callbacks para treinamento otimizado.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de callbacks configurados\n",
    "    \"\"\"\n",
    "    # Early Stopping: Para evitar overfitting\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',           # M√©trica para monitorar\n",
    "        patience=15,                  # √âpocas sem melhoria antes de parar\n",
    "        restore_best_weights=True,    # Restaura melhores pesos\n",
    "        verbose=1,                    # Mostra quando para\n",
    "        mode='min'                    # Minimizar loss\n",
    "    )\n",
    "    \n",
    "    # Reduce Learning Rate: Ajuste adaptativo da taxa de aprendizado\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',           # M√©trica para monitorar\n",
    "        factor=0.2,                   # Fator de redu√ß√£o (lr = lr * factor)\n",
    "        patience=10,                  # √âpocas sem melhoria antes de reduzir\n",
    "        min_lr=1e-7,                  # Taxa m√≠nima de aprendizado\n",
    "        verbose=1,                    # Mostra quando reduz\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Memory monitoring callback\n",
    "    memory_callback = MemoryCallback(monitor)\n",
    "    \n",
    "    return [early_stopping, reduce_lr, memory_callback]\n",
    "\n",
    "# Prepara√ß√£o dos dados para treinamento\n",
    "print(\"Preparando dados para treinamento...\")\n",
    "\n",
    "# Divis√£o treino/valida√ß√£o estratificada\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=VALIDATION_SPLIT,   # 30% para valida√ß√£o\n",
    "    stratify=y_train,             # Mant√©m propor√ß√£o por classe\n",
    "    random_state=42               # Reprodutibilidade\n",
    ")\n",
    "\n",
    "# Converte labels para formato categorical (one-hot encoding)\n",
    "y_train_cat = to_categorical(y_train_split, 7)\n",
    "y_val_cat = to_categorical(y_val, 7)\n",
    "y_test_cat = to_categorical(y_test, 7)\n",
    "\n",
    "print(f\"Dados de treino: {X_train_split.shape}\")\n",
    "print(f\"Dados de valida√ß√£o: {X_val.shape}\")\n",
    "print(f\"Dados de teste: {X_test.shape}\")\n",
    "print(f\"Distribui√ß√£o de classes - Treino: {dict(Counter(y_train_split))}\")\n",
    "print(f\"Distribui√ß√£o de classes - Valida√ß√£o: {dict(Counter(y_val))}\")\n",
    "\n",
    "# Configura callbacks\n",
    "callbacks = setup_training_callbacks(monitor)\n",
    "print(\"Callbacks configurados para treinamento otimizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1149a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet50_model(model, X_train, y_train, X_val, y_val, monitor, callbacks):\n",
    "    \"\"\"\n",
    "    Executa treinamento completo do ResNet50 com monitoramento detalhado.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (history, training_metrics)\n",
    "    \"\"\"\n",
    "    print(\"Iniciando treinamento ResNet50...\")\n",
    "    monitor.start_monitoring()\n",
    "    \n",
    "    # Inicia cron√¥metro espec√≠fico do treinamento\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    # Executa treinamento\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Calcula tempo de treinamento\n",
    "    training_end_time = time.time()\n",
    "    training_duration = training_end_time - training_start_time\n",
    "    \n",
    "    # M√©tricas do treinamento\n",
    "    training_metrics = {\n",
    "        'training_time_seconds': training_duration,\n",
    "        'training_time_formatted': str(timedelta(seconds=int(training_duration))),\n",
    "        'epochs_completed': len(history.history['accuracy']),\n",
    "        'best_train_accuracy': max(history.history['accuracy']),\n",
    "        'best_val_accuracy': max(history.history['val_accuracy']),\n",
    "        'final_train_loss': history.history['loss'][-1],\n",
    "        'final_val_loss': history.history['val_loss'][-1]\n",
    "    }\n",
    "    \n",
    "    print(f\"Treinamento conclu√≠do em: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"√âpocas executadas: {training_metrics['epochs_completed']}\")\n",
    "    print(f\"Melhor acur√°cia valida√ß√£o: {training_metrics['best_val_accuracy']:.4f}\")\n",
    "    \n",
    "    return history, training_metrics\n",
    "\n",
    "# Prepara√ß√£o dos dados se carregamento foi bem-sucedido\n",
    "if X_train is not None and y_train is not None:\n",
    "    \n",
    "    # Divis√£o estratificada treino/valida√ß√£o\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=VALIDATION_SPLIT,\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convers√£o para categorical (one-hot encoding)\n",
    "    y_train_cat = to_categorical(y_train_split, 7)\n",
    "    y_val_cat = to_categorical(y_val, 7)\n",
    "    y_test_cat = to_categorical(y_test, 7)\n",
    "    \n",
    "    print(f\"Prepara√ß√£o conclu√≠da:\")\n",
    "    print(f\"- Treino: {X_train_split.shape} | Labels: {y_train_cat.shape}\")\n",
    "    print(f\"- Valida√ß√£o: {X_val.shape} | Labels: {y_val_cat.shape}\")\n",
    "    print(f\"- Teste: {X_test.shape} | Labels: {y_test_cat.shape}\")\n",
    "    \n",
    "    # Configura callbacks\n",
    "    callbacks = setup_training_callbacks(monitor)\n",
    "    \n",
    "    # Executa treinamento\n",
    "    history, training_metrics = train_resnet50_model(\n",
    "        model, X_train_split, y_train_cat, X_val, y_val_cat, monitor, callbacks\n",
    "    )\n",
    "    \n",
    "    print(\"Treinamento finalizado com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Dados n√£o dispon√≠veis para treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_model_evaluation(model, X_test, y_test_cat, y_test_original):\n",
    "    \"\"\"\n",
    "    Avalia√ß√£o completa do modelo com todas as m√©tricas necess√°rias.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicion√°rio completo com todas as m√©tricas\n",
    "    \"\"\"\n",
    "    print(\"Iniciando avalia√ß√£o completa do modelo...\")\n",
    "    \n",
    "    # Mede tempo de infer√™ncia\n",
    "    inference_start = time.time()\n",
    "    y_pred_prob = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "    inference_end = time.time()\n",
    "    \n",
    "    # Calcula m√©tricas de tempo\n",
    "    total_inference_time = inference_end - inference_start\n",
    "    inference_per_sample = total_inference_time / len(X_test)\n",
    "    samples_per_second = len(X_test) / total_inference_time\n",
    "    \n",
    "    # Convers√µes para c√°lculos de m√©tricas\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = y_test_original\n",
    "    \n",
    "    # M√©tricas de classifica√ß√£o\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # M√©tricas por classe\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Matriz de confus√£o\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    # M√©tricas de mem√≥ria atual\n",
    "    current_memory = monitor._get_memory_usage()\n",
    "    \n",
    "    # Relat√≥rio detalhado por classe\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    class_report = classification_report(\n",
    "        y_true_classes, y_pred_classes, \n",
    "        target_names=emotion_names, \n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # Compila√ß√£o completa das m√©tricas\n",
    "    comprehensive_metrics = {\n",
    "        # Identifica√ß√£o do experimento\n",
    "        'experiment_id': experiment_id,\n",
    "        'model_architecture': 'ResNet50',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        \n",
    "        # Configura√ß√µes do modelo\n",
    "        'img_size': IMG_SIZE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_trained': len(history.history['accuracy']),\n",
    "        \n",
    "        # M√©tricas de performance principal\n",
    "        'test_accuracy': accuracy,\n",
    "        'f1_score_macro': f1,\n",
    "        'f1_score_micro': f1_micro,\n",
    "        'f1_score_weighted': f1_weighted,\n",
    "        'precision_macro': precision,\n",
    "        'recall_macro': recall,\n",
    "        \n",
    "        # M√©tricas de tempo\n",
    "        'total_inference_time_seconds': total_inference_time,\n",
    "        'inference_per_sample_ms': inference_per_sample * 1000,\n",
    "        'samples_per_second': samples_per_second,\n",
    "        'training_time_seconds': training_metrics['training_time_seconds'],\n",
    "        \n",
    "        # M√©tricas de mem√≥ria\n",
    "        'peak_memory_mb': monitor.peak_memory_mb,\n",
    "        'current_memory_mb': current_memory,\n",
    "        'memory_efficiency': monitor.initial_memory_mb / monitor.peak_memory_mb,\n",
    "        \n",
    "        # M√©tricas por classe (emotion-wise)\n",
    "        'anger_f1': class_report['anger']['f1-score'],\n",
    "        'disgust_f1': class_report['disgust']['f1-score'],\n",
    "        'fear_f1': class_report['fear']['f1-score'],\n",
    "        'happy_f1': class_report['happy']['f1-score'],\n",
    "        'neutral_f1': class_report['neutral']['f1-score'],\n",
    "        'sadness_f1': class_report['sadness']['f1-score'],\n",
    "        'surprise_f1': class_report['surprise']['f1-score'],\n",
    "        \n",
    "        # Dados do dataset\n",
    "        'train_samples': len(X_train_split),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'total_parameters': model.count_params(),\n",
    "        'trainable_parameters': sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    }\n",
    "    \n",
    "    return comprehensive_metrics, conf_matrix, class_report\n",
    "\n",
    "# Executa avalia√ß√£o completa se treinamento foi bem-sucedido\n",
    "if 'history' in locals() and history is not None:\n",
    "    \n",
    "    print(\"Executando avalia√ß√£o completa...\")\n",
    "    \n",
    "    # Avalia√ß√£o detalhada\n",
    "    metrics, confusion_matrix_result, detailed_report = comprehensive_model_evaluation(\n",
    "        model, X_test, y_test_cat, y_test\n",
    "    )\n",
    "    \n",
    "    # Salva m√©tricas em CSV\n",
    "    save_metrics_to_csv(metrics, experiment_id)\n",
    "    \n",
    "    # Tenta salvar modelo se performance for boa\n",
    "    model_saved = save_model_if_good_performance(\n",
    "        model, \n",
    "        metrics['test_accuracy'], \n",
    "        metrics['f1_score_macro'], \n",
    "        experiment_id,\n",
    "        threshold=0.80  # Ajuste conforme necess√°rio\n",
    "    )\n",
    "    \n",
    "    # Finaliza monitoramento\n",
    "    monitor_final_stats = monitor.end_monitoring()\n",
    "    \n",
    "    print(f\"\\nRESUMO DO EXPERIMENTO {experiment_id}:\")\n",
    "    print(f\"Acur√°cia: {metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"Tempo de treinamento: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"Infer√™ncia por amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"Modelo salvo: {'Sim' if model_saved else 'N√£o'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Treinamento n√£o foi executado corretamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc48890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualizations(history, confusion_matrix_result, metrics, detailed_report):\n",
    "    \"\"\"\n",
    "    Cria visualiza√ß√µes completas dos resultados para an√°lise cient√≠fica.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Hist√≥rico de treinamento\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    plt.title('Model Accuracy - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title('Model Loss - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Matriz de confus√£o\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    sns.heatmap(confusion_matrix_result, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax3)\n",
    "    plt.title('Confusion Matrix - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # 3. F1-Score por classe\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    f1_scores = [detailed_report[emotion]['f1-score'] for emotion in emotion_names]\n",
    "    bars = plt.bar(emotion_names, f1_scores, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    plt.title('F1-Score por Emo√ß√£o', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Adiciona valores nas barras\n",
    "    for bar, score in zip(bars, f1_scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. M√©tricas de performance\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    performance_metrics = ['Accuracy', 'F1-Macro', 'Precision', 'Recall']\n",
    "    performance_values = [\n",
    "        metrics['test_accuracy'],\n",
    "        metrics['f1_score_macro'],\n",
    "        metrics['precision_macro'],\n",
    "        metrics['recall_macro']\n",
    "    ]\n",
    "    bars = plt.bar(performance_metrics, performance_values, \n",
    "                  color=['green', 'blue', 'orange', 'red'], alpha=0.7)\n",
    "    plt.title('M√©tricas Gerais de Performance', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar, value in zip(bars, performance_values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 5. An√°lise de tempo e mem√≥ria\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    resource_data = {\n",
    "        'Tempo Treino (min)': metrics['training_time_seconds'] / 60,\n",
    "        'Infer√™ncia/amostra (ms)': metrics['inference_per_sample_ms'],\n",
    "        'Pico Mem√≥ria (GB)': metrics['peak_memory_mb'] / 1024,\n",
    "        'Amostras/seg': metrics['samples_per_second']\n",
    "    }\n",
    "    \n",
    "    # Normaliza valores para visualiza√ß√£o\n",
    "    normalized_values = []\n",
    "    labels = []\n",
    "    for key, value in resource_data.items():\n",
    "        if 'Tempo' in key:\n",
    "            normalized_values.append(value / max(1, value) if value > 0 else 0)\n",
    "        elif 'Mem√≥ria' in key:\n",
    "            normalized_values.append(min(value, 1))\n",
    "        else:\n",
    "            normalized_values.append(min(value / 100, 1))  # Normaliza outras m√©tricas\n",
    "        labels.append(f'{key}\\n{value:.2f}')\n",
    "    \n",
    "    plt.bar(range(len(labels)), normalized_values, color='purple', alpha=0.7)\n",
    "    plt.title('Recursos Computacionais (Normalizado)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(labels)), [label.split('\\n')[0] for label in labels], rotation=45)\n",
    "    plt.ylabel('Valor Normalizado')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/comprehensive_analysis_{experiment_id}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Relat√≥rio textual final\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RELAT√ìRIO CIENT√çFICO FINAL - EXPERIMENTO {experiment_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ARQUITETURA: ResNet50 Transfer Learning\")\n",
    "    print(f\"DATASET: Emo√ß√µes balanceadas (7 classes)\")\n",
    "    print(f\"CONFIGURA√á√ÉO: {IMG_SIZE}x{IMG_SIZE}, batch_size={BATCH_SIZE}\")\n",
    "    print(f\"\\nPERFORMANCE PRINCIPAL:\")\n",
    "    print(f\"  ‚Ä¢ Acur√°cia de Teste: {metrics['test_accuracy']:.4f} ({metrics['test_accuracy']*100:.2f}%)\")\n",
    "    print(f\"  ‚Ä¢ F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Precis√£o Macro: {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Recall Macro: {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"\\nEFICI√äNCIA COMPUTACIONAL:\")\n",
    "    print(f\"  ‚Ä¢ Tempo de Treinamento: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"  ‚Ä¢ √âpocas Executadas: {metrics['epochs_trained']}\")\n",
    "    print(f\"  ‚Ä¢ Infer√™ncia por Amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"  ‚Ä¢ Throughput: {metrics['samples_per_second']:.1f} amostras/segundo\")\n",
    "    print(f\"  ‚Ä¢ Pico de Mem√≥ria: {metrics['peak_memory_mb']:.1f} MB\")\n",
    "    print(f\"\\nPERFORMANCE POR EMO√á√ÉO:\")\n",
    "    for emotion in emotion_names:\n",
    "        f1_score = detailed_report[emotion]['f1-score']\n",
    "        print(f\"  ‚Ä¢ {emotion.capitalize()}: F1={f1_score:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# Executa an√°lise completa se avalia√ß√£o foi bem-sucedida\n",
    "if 'metrics' in locals() and metrics is not None:\n",
    "    create_comprehensive_visualizations(history, confusion_matrix_result, metrics, detailed_report)\n",
    "    print(\"An√°lise completa finalizada!\")\n",
    "    print(f\"Arquivos salvos:\")\n",
    "    print(f\"  ‚Ä¢ M√©tricas: metrics/performance_metrics.csv\")\n",
    "    print(f\"  ‚Ä¢ Visualiza√ß√µes: plots/comprehensive_analysis_{experiment_id}.png\")\n",
    "    if model_saved:\n",
    "        print(f\"  ‚Ä¢ Modelo: models/weights_resnet50_{experiment_id}.h5\")\n",
    "else:\n",
    "    print(\"Erro: Avalia√ß√£o n√£o foi executada corretamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
