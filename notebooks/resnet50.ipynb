{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c81aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU disponível: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Importações essenciais para deep learning e processamento de dados\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import time\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "\n",
    "# Configuração de reprodutibilidade\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponível: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498c1f9-ddf9-43d5-8bbd-379b72bbf1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurações definidas:\n",
      "- Tamanho da imagem: 96x96\n",
      "- Batch size: 32\n",
      "- Épocas máximas: 100\n",
      "- Classes de emoção: 7\n"
     ]
    }
   ],
   "source": [
    "# Configurações do experimento\n",
    "IMG_SIZE = 224  # Tamanho da imagem (224x224 pixels)\n",
    "BATCH_SIZE = 32  # Tamanho do lote para treinamento\n",
    "EPOCHS = 100  # Número máximo de épocas\n",
    "VALIDATION_SPLIT = 0.3  # 30% dos dados para validação\n",
    "\n",
    "# Caminhos dos datasets\n",
    "FER2013_PATH = r\"src/data/FER2013\"\n",
    "RAF_DB_PATH = r\"src/data/ RAF-DB\"\n",
    "DFEW_DB_PATH = r\"src/data/DFEW\"\n",
    "\n",
    "\n",
    "# Mapeamento das 7 emoções básicas\n",
    "EMOTION_LABELS = {\n",
    "    'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, \n",
    "    'neutral': 4, 'sadness': 5, 'surprise': 6\n",
    "}\n",
    "\n",
    "print(\"Configurações definidas:\")\n",
    "print(f\"- Tamanho da imagem: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Épocas máximas: {EPOCHS}\")\n",
    "print(f\"- Classes de emoção: {len(EMOTION_LABELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8260fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor:\n",
    "    \"\"\"\n",
    "    Classe para monitorar desempenho computacional durante o treinamento.\n",
    "    Essencial para experimentos científicos reproduzíveis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.peak_memory_mb = 0\n",
    "        self.initial_memory_mb = 0\n",
    "        self.process = psutil.Process()\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Inicia o monitoramento de tempo e memória\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.initial_memory_mb = self._get_memory_usage()\n",
    "        self.peak_memory_mb = self.initial_memory_mb\n",
    "        print(f\"Iniciando treinamento ResNet50...\")\n",
    "        print(f\"Horário de início: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Memória inicial: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    def _get_memory_usage(self):\n",
    "        \"\"\"Retorna uso atual de memória em MB\"\"\"\n",
    "        return self.process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "    def update_peak_memory(self):\n",
    "        \"\"\"Atualiza o pico de memória se necessário\"\"\"\n",
    "        current_memory = self._get_memory_usage()\n",
    "        if current_memory > self.peak_memory_mb:\n",
    "            self.peak_memory_mb = current_memory\n",
    "\n",
    "# Instancia o monitor\n",
    "monitor = TrainingMonitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827d327",
   "metadata": {},
   "source": [
    "# VER COM LU COMO ELA SALVO OS DADOS PRÉ-PROCESSADOS E ARRUMAR A CELULA ABAIXO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_preprocessed_data():\n",
    "    \"\"\"\n",
    "    Carrega dados já pré-processados e balanceados do formato pickle.\n",
    "    Converte imagens de escala de cinza para RGB para compatibilidade com ResNet50.\n",
    "    \"\"\"\n",
    "    print(\"Carregando dados pré-processados do pickle...\")\n",
    "    \n",
    "    try:\n",
    "        # Carrega os dados do pickle\n",
    "        with open('X_train.pkl', 'rb') as f:\n",
    "            X_train = pickle.load(f)\n",
    "        with open('y_train.pkl', 'rb') as f:\n",
    "            y_train = pickle.load(f)\n",
    "        with open('X_test.pkl', 'rb') as f:\n",
    "            X_test = pickle.load(f)\n",
    "        with open('y_test.pkl', 'rb') as f:\n",
    "            y_test = pickle.load(f)\n",
    "        \n",
    "        print(f\"Dados carregados com sucesso:\")\n",
    "        print(f\"- X_train: {X_train.shape}\")\n",
    "        print(f\"- y_train: {y_train.shape}\")\n",
    "        print(f\"- X_test: {X_test.shape}\")\n",
    "        print(f\"- y_test: {y_test.shape}\")\n",
    "        \n",
    "        # Converte de escala de cinza (H, W, 1) para RGB (H, W, 3)\n",
    "        # ResNet50 foi treinado com 3 canais\n",
    "        if X_train.shape[-1] == 1:\n",
    "            X_train = np.repeat(X_train, 3, axis=-1)\n",
    "            X_test = np.repeat(X_test, 3, axis=-1)\n",
    "            print(\"Imagens convertidas de escala de cinza para RGB (3 canais)\")\n",
    "        \n",
    "        # Verifica distribuição de classes\n",
    "        train_distribution = dict(Counter(y_train))\n",
    "        test_distribution = dict(Counter(y_test))\n",
    "        \n",
    "        print(f\"Distribuição treino: {train_distribution}\")\n",
    "        print(f\"Distribuição teste: {test_distribution}\")\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado - {e}\")\n",
    "        print(\"Certifique-se de que os arquivos pickle estão no diretório correto\")\n",
    "        return None, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar dados: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# Carrega os dados\n",
    "X_train, y_train, X_test, y_test = load_preprocessed_data()\n",
    "monitor.update_peak_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment_structure():\n",
    "    \"\"\"\n",
    "    Cria estrutura de diretórios para salvar modelos e métricas.\n",
    "    \"\"\"\n",
    "    # Cria timestamp único para o experimento\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    experiment_id = f\"resnet50_emotion_{timestamp}\"\n",
    "    \n",
    "    # Cria diretórios\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"metrics\", exist_ok=True)\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    \n",
    "    return experiment_id\n",
    "\n",
    "def save_model_if_good_performance(model, accuracy, f1_score, experiment_id, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Salva modelo apenas se a performance for boa.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        accuracy: Acurácia do modelo\n",
    "        f1_score: F1-score macro do modelo\n",
    "        experiment_id: ID único do experimento\n",
    "        threshold: Limite mínimo para salvar (default: 85%)\n",
    "    \"\"\"\n",
    "    if accuracy >= threshold or f1_score >= threshold:\n",
    "        model_path = f\"models/resnet50_emotion_{experiment_id}.pkl\"\n",
    "        \n",
    "        # Salva apenas os pesos para economia de espaço\n",
    "        model.save_weights(f\"models/weights_resnet50_{experiment_id}.h5\")\n",
    "        \n",
    "        # Salva configuração do modelo\n",
    "        model_config = {\n",
    "            'architecture': 'ResNet50',\n",
    "            'img_size': IMG_SIZE,\n",
    "            'num_classes': 7,\n",
    "            'experiment_id': experiment_id,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_score,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(f\"models/config_resnet50_{experiment_id}.pkl\", 'wb') as f:\n",
    "            pickle.dump(model_config, f)\n",
    "        \n",
    "        print(f\"Modelo salvo! Performance: Acc={accuracy:.4f}, F1={f1_score:.4f}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Performance insuficiente para salvar. Acc={accuracy:.4f}, F1={f1_score:.4f} < {threshold}\")\n",
    "        return False\n",
    "\n",
    "def save_metrics_to_csv(metrics_dict, experiment_id):\n",
    "    \"\"\"\n",
    "    Salva métricas de performance em arquivo CSV.\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: Dicionário com todas as métricas\n",
    "        experiment_id: ID único do experimento\n",
    "    \"\"\"\n",
    "    # Converte métricas para DataFrame\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "    \n",
    "    # Arquivo CSV principal\n",
    "    csv_path = \"metrics/performance_metrics.csv\"\n",
    "    \n",
    "    # Append ao CSV se já existir, senão cria novo\n",
    "    if os.path.exists(csv_path):\n",
    "        metrics_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Salva também arquivo individual do experimento\n",
    "    individual_csv = f\"metrics/metrics_{experiment_id}.csv\"\n",
    "    metrics_df.to_csv(individual_csv, index=False)\n",
    "    \n",
    "    print(f\"Métricas salvas em: {csv_path} e {individual_csv}\")\n",
    "\n",
    "# Inicializa estrutura do experimento\n",
    "experiment_id = create_experiment_structure()\n",
    "print(f\"Experimento iniciado: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet50_model():\n",
    "    \"\"\"\n",
    "    Cria modelo ResNet50 com transfer learning para classificação de emoções.\n",
    "    \n",
    "    Arquitetura:\n",
    "    - ResNet50 pré-treinado (ImageNet) como feature extractor\n",
    "    - Global Average Pooling para redução dimensional\n",
    "    - Camadas densas para classificação final\n",
    "    - Dropout para regularização\n",
    "    \n",
    "    Returns:\n",
    "        keras.Model: Modelo compilado pronto para treinamento\n",
    "    \"\"\"\n",
    "    # Carrega ResNet50 pré-treinado no ImageNet\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',          # Pesos pré-treinados\n",
    "        include_top=False,           # Remove camadas de classificação originais\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)  # Define formato de entrada\n",
    "    )\n",
    "    \n",
    "    # Congela camadas base para transfer learning\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Adiciona camadas de classificação customizadas\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)           # Reduz dimensionalidade espacial\n",
    "    x = Dense(512, activation='relu')(x)       # Primeira camada densa\n",
    "    x = Dropout(0.5)(x)                       # Regularização forte\n",
    "    x = Dense(256, activation='relu')(x)       # Segunda camada densa\n",
    "    x = Dropout(0.3)(x)                       # Regularização moderada\n",
    "    predictions = Dense(7, activation='softmax')(x)  # Classificação final (7 emoções)\n",
    "    \n",
    "    # Cria modelo final\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compilação otimizada para classificação multiclasse\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Verifica se os dados foram carregados corretamente antes de criar o modelo\n",
    "if X_train is not None:\n",
    "    print(\"Criando modelo ResNet50 otimizado...\")\n",
    "    model, base_model = create_resnet50_model()\n",
    "    \n",
    "    print(f\"Modelo criado com sucesso:\")\n",
    "    print(f\"- Total de parâmetros: {model.count_params():,}\")\n",
    "    print(f\"- Parâmetros treináveis: {sum([tf.keras.backend.count_params(p) for p in model.trainable_weights]):,}\")\n",
    "    print(f\"- Camadas congeladas: {len([l for l in base_model.layers if not l.trainable])}\")\n",
    "    \n",
    "    monitor.update_peak_memory()\n",
    "else:\n",
    "    print(\"Erro: Dados não carregados. Verifique a célula anterior.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback customizado para monitoramento de memória durante treinamento.\n",
    "    Essencial para experimentos com recursos limitados.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.monitor.update_peak_memory()\n",
    "        if epoch % 5 == 0:  # Log a cada 5 épocas\n",
    "            current_memory = self.monitor._get_memory_usage()\n",
    "            print(f\"Época {epoch+1} - Memória atual: {current_memory:.2f} MB\")\n",
    "\n",
    "def setup_training_callbacks(monitor):\n",
    "    \"\"\"\n",
    "    Configura callbacks para treinamento otimizado.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de callbacks configurados\n",
    "    \"\"\"\n",
    "    # Early Stopping: Para evitar overfitting\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',           # Métrica para monitorar\n",
    "        patience=15,                  # Épocas sem melhoria antes de parar\n",
    "        restore_best_weights=True,    # Restaura melhores pesos\n",
    "        verbose=1,                    # Mostra quando para\n",
    "        mode='min'                    # Minimizar loss\n",
    "    )\n",
    "    \n",
    "    # Reduce Learning Rate: Ajuste adaptativo da taxa de aprendizado\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',           # Métrica para monitorar\n",
    "        factor=0.2,                   # Fator de redução (lr = lr * factor)\n",
    "        patience=10,                  # Épocas sem melhoria antes de reduzir\n",
    "        min_lr=1e-7,                  # Taxa mínima de aprendizado\n",
    "        verbose=1,                    # Mostra quando reduz\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Memory monitoring callback\n",
    "    memory_callback = MemoryCallback(monitor)\n",
    "    \n",
    "    return [early_stopping, reduce_lr, memory_callback]\n",
    "\n",
    "# Preparação dos dados para treinamento\n",
    "print(\"Preparando dados para treinamento...\")\n",
    "\n",
    "# Divisão treino/validação estratificada\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=VALIDATION_SPLIT,   # 30% para validação\n",
    "    stratify=y_train,             # Mantém proporção por classe\n",
    "    random_state=42               # Reprodutibilidade\n",
    ")\n",
    "\n",
    "# Converte labels para formato categorical (one-hot encoding)\n",
    "y_train_cat = to_categorical(y_train_split, 7)\n",
    "y_val_cat = to_categorical(y_val, 7)\n",
    "y_test_cat = to_categorical(y_test, 7)\n",
    "\n",
    "print(f\"Dados de treino: {X_train_split.shape}\")\n",
    "print(f\"Dados de validação: {X_val.shape}\")\n",
    "print(f\"Dados de teste: {X_test.shape}\")\n",
    "print(f\"Distribuição de classes - Treino: {dict(Counter(y_train_split))}\")\n",
    "print(f\"Distribuição de classes - Validação: {dict(Counter(y_val))}\")\n",
    "\n",
    "# Configura callbacks\n",
    "callbacks = setup_training_callbacks(monitor)\n",
    "print(\"Callbacks configurados para treinamento otimizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1149a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet50_model(model, X_train, y_train, X_val, y_val, monitor, callbacks):\n",
    "    \"\"\"\n",
    "    Executa treinamento completo do ResNet50 com monitoramento detalhado.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (history, training_metrics)\n",
    "    \"\"\"\n",
    "    print(\"Iniciando treinamento ResNet50...\")\n",
    "    monitor.start_monitoring()\n",
    "    \n",
    "    # Inicia cronômetro específico do treinamento\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    # Executa treinamento\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Calcula tempo de treinamento\n",
    "    training_end_time = time.time()\n",
    "    training_duration = training_end_time - training_start_time\n",
    "    \n",
    "    # Métricas do treinamento\n",
    "    training_metrics = {\n",
    "        'training_time_seconds': training_duration,\n",
    "        'training_time_formatted': str(timedelta(seconds=int(training_duration))),\n",
    "        'epochs_completed': len(history.history['accuracy']),\n",
    "        'best_train_accuracy': max(history.history['accuracy']),\n",
    "        'best_val_accuracy': max(history.history['val_accuracy']),\n",
    "        'final_train_loss': history.history['loss'][-1],\n",
    "        'final_val_loss': history.history['val_loss'][-1]\n",
    "    }\n",
    "    \n",
    "    print(f\"Treinamento concluído em: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"Épocas executadas: {training_metrics['epochs_completed']}\")\n",
    "    print(f\"Melhor acurácia validação: {training_metrics['best_val_accuracy']:.4f}\")\n",
    "    \n",
    "    return history, training_metrics\n",
    "\n",
    "# Preparação dos dados se carregamento foi bem-sucedido\n",
    "if X_train is not None and y_train is not None:\n",
    "    \n",
    "    # Divisão estratificada treino/validação\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=VALIDATION_SPLIT,\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Conversão para categorical (one-hot encoding)\n",
    "    y_train_cat = to_categorical(y_train_split, 7)\n",
    "    y_val_cat = to_categorical(y_val, 7)\n",
    "    y_test_cat = to_categorical(y_test, 7)\n",
    "    \n",
    "    print(f\"Preparação concluída:\")\n",
    "    print(f\"- Treino: {X_train_split.shape} | Labels: {y_train_cat.shape}\")\n",
    "    print(f\"- Validação: {X_val.shape} | Labels: {y_val_cat.shape}\")\n",
    "    print(f\"- Teste: {X_test.shape} | Labels: {y_test_cat.shape}\")\n",
    "    \n",
    "    # Configura callbacks\n",
    "    callbacks = setup_training_callbacks(monitor)\n",
    "    \n",
    "    # Executa treinamento\n",
    "    history, training_metrics = train_resnet50_model(\n",
    "        model, X_train_split, y_train_cat, X_val, y_val_cat, monitor, callbacks\n",
    "    )\n",
    "    \n",
    "    print(\"Treinamento finalizado com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Dados não disponíveis para treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_model_evaluation(model, X_test, y_test_cat, y_test_original):\n",
    "    \"\"\"\n",
    "    Avaliação completa do modelo com todas as métricas necessárias.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário completo com todas as métricas\n",
    "    \"\"\"\n",
    "    print(\"Iniciando avaliação completa do modelo...\")\n",
    "    \n",
    "    # Mede tempo de inferência\n",
    "    inference_start = time.time()\n",
    "    y_pred_prob = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "    inference_end = time.time()\n",
    "    \n",
    "    # Calcula métricas de tempo\n",
    "    total_inference_time = inference_end - inference_start\n",
    "    inference_per_sample = total_inference_time / len(X_test)\n",
    "    samples_per_second = len(X_test) / total_inference_time\n",
    "    \n",
    "    # Conversões para cálculos de métricas\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = y_test_original\n",
    "    \n",
    "    # Métricas de classificação\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Métricas por classe\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    # Métricas de memória atual\n",
    "    current_memory = monitor._get_memory_usage()\n",
    "    \n",
    "    # Relatório detalhado por classe\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    class_report = classification_report(\n",
    "        y_true_classes, y_pred_classes, \n",
    "        target_names=emotion_names, \n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # Compilação completa das métricas\n",
    "    comprehensive_metrics = {\n",
    "        # Identificação do experimento\n",
    "        'experiment_id': experiment_id,\n",
    "        'model_architecture': 'ResNet50',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        \n",
    "        # Configurações do modelo\n",
    "        'img_size': IMG_SIZE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_trained': len(history.history['accuracy']),\n",
    "        \n",
    "        # Métricas de performance principal\n",
    "        'test_accuracy': accuracy,\n",
    "        'f1_score_macro': f1,\n",
    "        'f1_score_micro': f1_micro,\n",
    "        'f1_score_weighted': f1_weighted,\n",
    "        'precision_macro': precision,\n",
    "        'recall_macro': recall,\n",
    "        \n",
    "        # Métricas de tempo\n",
    "        'total_inference_time_seconds': total_inference_time,\n",
    "        'inference_per_sample_ms': inference_per_sample * 1000,\n",
    "        'samples_per_second': samples_per_second,\n",
    "        'training_time_seconds': training_metrics['training_time_seconds'],\n",
    "        \n",
    "        # Métricas de memória\n",
    "        'peak_memory_mb': monitor.peak_memory_mb,\n",
    "        'current_memory_mb': current_memory,\n",
    "        'memory_efficiency': monitor.initial_memory_mb / monitor.peak_memory_mb,\n",
    "        \n",
    "        # Métricas por classe (emotion-wise)\n",
    "        'anger_f1': class_report['anger']['f1-score'],\n",
    "        'disgust_f1': class_report['disgust']['f1-score'],\n",
    "        'fear_f1': class_report['fear']['f1-score'],\n",
    "        'happy_f1': class_report['happy']['f1-score'],\n",
    "        'neutral_f1': class_report['neutral']['f1-score'],\n",
    "        'sadness_f1': class_report['sadness']['f1-score'],\n",
    "        'surprise_f1': class_report['surprise']['f1-score'],\n",
    "        \n",
    "        # Dados do dataset\n",
    "        'train_samples': len(X_train_split),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'total_parameters': model.count_params(),\n",
    "        'trainable_parameters': sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    }\n",
    "    \n",
    "    return comprehensive_metrics, conf_matrix, class_report\n",
    "\n",
    "# Executa avaliação completa se treinamento foi bem-sucedido\n",
    "if 'history' in locals() and history is not None:\n",
    "    \n",
    "    print(\"Executando avaliação completa...\")\n",
    "    \n",
    "    # Avaliação detalhada\n",
    "    metrics, confusion_matrix_result, detailed_report = comprehensive_model_evaluation(\n",
    "        model, X_test, y_test_cat, y_test\n",
    "    )\n",
    "    \n",
    "    # Salva métricas em CSV\n",
    "    save_metrics_to_csv(metrics, experiment_id)\n",
    "    \n",
    "    # Tenta salvar modelo se performance for boa\n",
    "    model_saved = save_model_if_good_performance(\n",
    "        model, \n",
    "        metrics['test_accuracy'], \n",
    "        metrics['f1_score_macro'], \n",
    "        experiment_id,\n",
    "        threshold=0.80  # Ajuste conforme necessário\n",
    "    )\n",
    "    \n",
    "    # Finaliza monitoramento\n",
    "    monitor_final_stats = monitor.end_monitoring()\n",
    "    \n",
    "    print(f\"\\nRESUMO DO EXPERIMENTO {experiment_id}:\")\n",
    "    print(f\"Acurácia: {metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"Tempo de treinamento: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"Inferência por amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"Modelo salvo: {'Sim' if model_saved else 'Não'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Treinamento não foi executado corretamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc48890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualizations(history, confusion_matrix_result, metrics, detailed_report):\n",
    "    \"\"\"\n",
    "    Cria visualizações completas dos resultados para análise científica.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Histórico de treinamento\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    plt.title('Model Accuracy - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title('Model Loss - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Matriz de confusão\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    sns.heatmap(confusion_matrix_result, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax3)\n",
    "    plt.title('Confusion Matrix - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # 3. F1-Score por classe\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    f1_scores = [detailed_report[emotion]['f1-score'] for emotion in emotion_names]\n",
    "    bars = plt.bar(emotion_names, f1_scores, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    plt.title('F1-Score por Emoção', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Adiciona valores nas barras\n",
    "    for bar, score in zip(bars, f1_scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. Métricas de performance\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    performance_metrics = ['Accuracy', 'F1-Macro', 'Precision', 'Recall']\n",
    "    performance_values = [\n",
    "        metrics['test_accuracy'],\n",
    "        metrics['f1_score_macro'],\n",
    "        metrics['precision_macro'],\n",
    "        metrics['recall_macro']\n",
    "    ]\n",
    "    bars = plt.bar(performance_metrics, performance_values, \n",
    "                  color=['green', 'blue', 'orange', 'red'], alpha=0.7)\n",
    "    plt.title('Métricas Gerais de Performance', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar, value in zip(bars, performance_values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 5. Análise de tempo e memória\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    resource_data = {\n",
    "        'Tempo Treino (min)': metrics['training_time_seconds'] / 60,\n",
    "        'Inferência/amostra (ms)': metrics['inference_per_sample_ms'],\n",
    "        'Pico Memória (GB)': metrics['peak_memory_mb'] / 1024,\n",
    "        'Amostras/seg': metrics['samples_per_second']\n",
    "    }\n",
    "    \n",
    "    # Normaliza valores para visualização\n",
    "    normalized_values = []\n",
    "    labels = []\n",
    "    for key, value in resource_data.items():\n",
    "        if 'Tempo' in key:\n",
    "            normalized_values.append(value / max(1, value) if value > 0 else 0)\n",
    "        elif 'Memória' in key:\n",
    "            normalized_values.append(min(value, 1))\n",
    "        else:\n",
    "            normalized_values.append(min(value / 100, 1))  # Normaliza outras métricas\n",
    "        labels.append(f'{key}\\n{value:.2f}')\n",
    "    \n",
    "    plt.bar(range(len(labels)), normalized_values, color='purple', alpha=0.7)\n",
    "    plt.title('Recursos Computacionais (Normalizado)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(labels)), [label.split('\\n')[0] for label in labels], rotation=45)\n",
    "    plt.ylabel('Valor Normalizado')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/comprehensive_analysis_{experiment_id}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Relatório textual final\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RELATÓRIO CIENTÍFICO FINAL - EXPERIMENTO {experiment_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ARQUITETURA: ResNet50 Transfer Learning\")\n",
    "    print(f\"DATASET: Emoções balanceadas (7 classes)\")\n",
    "    print(f\"CONFIGURAÇÃO: {IMG_SIZE}x{IMG_SIZE}, batch_size={BATCH_SIZE}\")\n",
    "    print(f\"\\nPERFORMANCE PRINCIPAL:\")\n",
    "    print(f\"  • Acurácia de Teste: {metrics['test_accuracy']:.4f} ({metrics['test_accuracy']*100:.2f}%)\")\n",
    "    print(f\"  • F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"  • Precisão Macro: {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"  • Recall Macro: {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"\\nEFICIÊNCIA COMPUTACIONAL:\")\n",
    "    print(f\"  • Tempo de Treinamento: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"  • Épocas Executadas: {metrics['epochs_trained']}\")\n",
    "    print(f\"  • Inferência por Amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"  • Throughput: {metrics['samples_per_second']:.1f} amostras/segundo\")\n",
    "    print(f\"  • Pico de Memória: {metrics['peak_memory_mb']:.1f} MB\")\n",
    "    print(f\"\\nPERFORMANCE POR EMOÇÃO:\")\n",
    "    for emotion in emotion_names:\n",
    "        f1_score = detailed_report[emotion]['f1-score']\n",
    "        print(f\"  • {emotion.capitalize()}: F1={f1_score:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# Executa análise completa se avaliação foi bem-sucedida\n",
    "if 'metrics' in locals() and metrics is not None:\n",
    "    create_comprehensive_visualizations(history, confusion_matrix_result, metrics, detailed_report)\n",
    "    print(\"Análise completa finalizada!\")\n",
    "    print(f\"Arquivos salvos:\")\n",
    "    print(f\"  • Métricas: metrics/performance_metrics.csv\")\n",
    "    print(f\"  • Visualizações: plots/comprehensive_analysis_{experiment_id}.png\")\n",
    "    if model_saved:\n",
    "        print(f\"  • Modelo: models/weights_resnet50_{experiment_id}.h5\")\n",
    "else:\n",
    "    print(\"Erro: Avaliação não foi executada corretamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
