{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c81aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando disponibilidade de GPU...\n",
      "CUDA disponível: True\n",
      "Número de dispositivos CUDA: 1\n",
      "GPU encontrada:\n",
      "- Nome: NVIDIA GeForce RTX 2080\n",
      "- VRAM total: 7.6 GB\n",
      "- CUDA version: 11.8\n",
      "- Teste GPU: SUCESSO (resultado: -0.001607)\n",
      "\n",
      "Configuração final:\n",
      "- Dispositivo: cuda\n",
      "- GPU funcional: True\n",
      "PyTorch GPU funcionando perfeitamente!\n",
      "\n",
      "Informações do ambiente:\n",
      "- PyTorch version: 2.7.1+cu118\n",
      "- Reprodutibilidade configurada\n",
      "- Dispositivo selecionado: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import time\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# VERIFICAÇÃO SEGURA DE GPU\n",
    "def check_gpu_availability():\n",
    "    \"\"\"\n",
    "    Verifica disponibilidade de GPU com tratamento de erros robusto.\n",
    "    \"\"\"\n",
    "    print(\"Verificando disponibilidade de GPU...\")\n",
    "    \n",
    "    # Verificação básica CUDA\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA disponível: {cuda_available}\")\n",
    "    \n",
    "    if cuda_available:\n",
    "        try:\n",
    "            # Verifica número de dispositivos\n",
    "            device_count = torch.cuda.device_count()\n",
    "            print(f\"Número de dispositivos CUDA: {device_count}\")\n",
    "            \n",
    "            if device_count > 0:\n",
    "                # Tenta acessar dispositivo 0\n",
    "                try:\n",
    "                    device_name = torch.cuda.get_device_name(0)\n",
    "                    device_props = torch.cuda.get_device_properties(0)\n",
    "                    cuda_version = torch.version.cuda\n",
    "                    \n",
    "                    print(f\"GPU encontrada:\")\n",
    "                    print(f\"- Nome: {device_name}\")\n",
    "                    print(f\"- VRAM total: {device_props.total_memory / 1024**3:.1f} GB\")\n",
    "                    print(f\"- CUDA version: {cuda_version}\")\n",
    "                    \n",
    "                    # Teste funcional da GPU\n",
    "                    try:\n",
    "                        test_tensor = torch.randn(100, 100).cuda()\n",
    "                        result = torch.mean(test_tensor)\n",
    "                        print(f\"- Teste GPU: SUCESSO (resultado: {result.item():.6f})\")\n",
    "                        \n",
    "                        # Limpa tensor de teste\n",
    "                        del test_tensor\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                        return torch.device(\"cuda\"), True\n",
    "                        \n",
    "                    except Exception as gpu_test_error:\n",
    "                        print(f\"- Teste GPU: FALHOU ({gpu_test_error})\")\n",
    "                        return torch.device(\"cpu\"), False\n",
    "                        \n",
    "                except Exception as gpu_access_error:\n",
    "                    print(f\"Erro ao acessar GPU: {gpu_access_error}\")\n",
    "                    return torch.device(\"cpu\"), False\n",
    "            else:\n",
    "                print(\"Nenhum dispositivo CUDA encontrado\")\n",
    "                return torch.device(\"cpu\"), False\n",
    "                \n",
    "        except Exception as cuda_error:\n",
    "            print(f\"Erro na verificação CUDA: {cuda_error}\")\n",
    "            return torch.device(\"cpu\"), False\n",
    "    else:\n",
    "        print(\"CUDA não disponível - usando CPU\")\n",
    "        return torch.device(\"cpu\"), False\n",
    "\n",
    "# Executa verificação\n",
    "device, gpu_available = check_gpu_availability()\n",
    "\n",
    "print(f\"\\nConfiguração final:\")\n",
    "print(f\"- Dispositivo: {device}\")\n",
    "print(f\"- GPU funcional: {gpu_available}\")\n",
    "\n",
    "if gpu_available:\n",
    "    print(\"PyTorch GPU funcionando perfeitamente!\")\n",
    "else:\n",
    "    print(\"Usando CPU - funcional mas mais lento\")\n",
    "\n",
    "# Configuração de reprodutibilidade\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "if gpu_available:\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"\\nInformações do ambiente:\")\n",
    "print(f\"- PyTorch version: {torch.__version__}\")\n",
    "print(f\"- Reprodutibilidade configurada\")\n",
    "print(f\"- Dispositivo selecionado: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63dc036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNÓSTICO PYTORCH:\n",
      "- PyTorch version: 2.7.1+cu118\n",
      "- Torchvision disponível: Não\n",
      "\n",
      "CUDA:\n",
      "- torch.cuda.is_available(): True\n",
      "- torch.version.cuda: 11.8\n",
      "- torch.cuda.device_count(): 1\n",
      "- torch.cuda.current_device(): 0\n",
      "\n",
      "CPU:\n",
      "- torch.get_num_threads(): 6\n",
      "- Operação básica: OK\n"
     ]
    }
   ],
   "source": [
    "# Diagnóstico completo do ambiente\n",
    "def diagnose_pytorch_environment():\n",
    "    \"\"\"Diagnóstico completo do ambiente PyTorch\"\"\"\n",
    "    \n",
    "    print(\"DIAGNÓSTICO PYTORCH:\")\n",
    "    print(f\"- PyTorch version: {torch.__version__}\")\n",
    "    print(f\"- Torchvision disponível: {'Sim' if 'torchvision' in globals() else 'Não'}\")\n",
    "    \n",
    "    # CUDA\n",
    "    print(f\"\\nCUDA:\")\n",
    "    print(f\"- torch.cuda.is_available(): {torch.cuda.is_available()}\")\n",
    "    print(f\"- torch.version.cuda: {torch.version.cuda}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            print(f\"- torch.cuda.device_count(): {torch.cuda.device_count()}\")\n",
    "            print(f\"- torch.cuda.current_device(): {torch.cuda.current_device()}\")\n",
    "        except:\n",
    "            print(\"- Erro ao acessar informações CUDA\")\n",
    "    \n",
    "    # CPU\n",
    "    print(f\"\\nCPU:\")\n",
    "    print(f\"- torch.get_num_threads(): {torch.get_num_threads()}\")\n",
    "    \n",
    "    # Teste básico\n",
    "    try:\n",
    "        x = torch.randn(5, 5)\n",
    "        y = torch.mm(x, x.t())\n",
    "        print(f\"- Operação básica: OK\")\n",
    "    except Exception as e:\n",
    "        print(f\"- Operação básica: ERRO ({e})\")\n",
    "\n",
    "# Executa diagnóstico\n",
    "diagnose_pytorch_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c498c1f9-ddf9-43d5-8bbd-379b72bbf1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurações definidas:\n",
      "- Tamanho da imagem: 224x224\n",
      "- Batch size: 16\n",
      "- Épocas máximas: 50\n",
      "- Classes de emoção: 7\n"
     ]
    }
   ],
   "source": [
    "# Configurações do experimento (mantidas do original)\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16 if torch.cuda.is_available() else 8  # Maior para GPU\n",
    "EPOCHS = 50\n",
    "VALIDATION_SPLIT = 0.3\n",
    "\n",
    "# Caminhos dos datasets (mantidos do original)\n",
    "BASE_PATH = \"/home/leandro/Documents/TCC/emotion_recognition_tcc/data/processed/raf_db_temp_gray_aligned\"\n",
    "\n",
    "# Mapeamento das 7 emoções básicas (mantido do original)\n",
    "EMOTION_LABELS = {\n",
    "    'Raiva': 0, 'Nojo': 1, 'Medo': 2, 'Felicidade': 3, \n",
    "    'Neutro': 4, 'Tristeza': 5, 'Surpresa': 6\n",
    "}\n",
    "\n",
    "print(\"Configurações definidas:\")\n",
    "print(f\"- Tamanho da imagem: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Épocas máximas: {EPOCHS}\")\n",
    "print(f\"- Classes de emoção: {len(EMOTION_LABELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8260fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor:\n",
    "    \"\"\"\n",
    "    Classe para monitorar desempenho computacional durante o treinamento.\n",
    "    Essencial para experimentos científicos reproduzíveis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.peak_memory_mb = 0\n",
    "        self.initial_memory_mb = 0\n",
    "        self.process = psutil.Process()\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Inicia o monitoramento de tempo e memória\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.initial_memory_mb = self._get_memory_usage()\n",
    "        self.peak_memory_mb = self.initial_memory_mb\n",
    "        print(f\"Iniciando treinamento ResNet50...\")\n",
    "        print(f\"Horário de início: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Memória inicial: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    def _get_memory_usage(self):\n",
    "        \"\"\"Retorna uso atual de memória em MB\"\"\"\n",
    "        return self.process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "    def update_peak_memory(self):\n",
    "        \"\"\"Atualiza o pico de memória se necessário\"\"\"\n",
    "        current_memory = self._get_memory_usage()\n",
    "        if current_memory > self.peak_memory_mb:\n",
    "            self.peak_memory_mb = current_memory\n",
    "\n",
    "# Instancia o monitor\n",
    "monitor = TrainingMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e13fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados pré-processados JPG para ResNet50...\n",
      "🔍 Analisando estrutura de: ../data/processed/raf_db_temp_gray_aligned\n",
      "📁 Diretórios: ['test', 'train']\n",
      "📄 Arquivos: 0 encontrados\n",
      "✅ Estrutura detectada: train/test/emotion/\n",
      "Carregando TREINO de: ../data/processed/raf_db_temp_gray_aligned/train\n",
      "📁 Subdiretórios encontrados: ['Tristeza', 'Raiva', 'Neutro', 'Surpresa', 'Felicidade', 'Medo', 'Nojo']\n",
      "  📸 Raiva: 365 arquivos encontrados\n",
      "  ✅ Raiva: 365 imagens carregadas com sucesso\n",
      "  📸 Nojo: 434 arquivos encontrados\n",
      "  ✅ Nojo: 434 imagens carregadas com sucesso\n",
      "  📸 Medo: 155 arquivos encontrados\n",
      "  ✅ Medo: 155 imagens carregadas com sucesso\n",
      "  📸 Felicidade: 1881 arquivos encontrados\n",
      "  ✅ Felicidade: 1881 imagens carregadas com sucesso\n",
      "  📸 Neutro: 1470 arquivos encontrados\n",
      "  ✅ Neutro: 1470 imagens carregadas com sucesso\n",
      "  📸 Tristeza: 1023 arquivos encontrados\n",
      "  ✅ Tristeza: 1023 imagens carregadas com sucesso\n",
      "  📸 Surpresa: 689 arquivos encontrados\n",
      "  ✅ Surpresa: 689 imagens carregadas com sucesso\n",
      "Carregando TESTE de: ../data/processed/raf_db_temp_gray_aligned/test\n",
      "📁 Subdiretórios encontrados: ['Tristeza', 'Raiva', 'Neutro', 'Surpresa', 'Felicidade', 'Medo', 'Nojo']\n",
      "  📸 Raiva: 91 arquivos encontrados\n",
      "  ✅ Raiva: 91 imagens carregadas com sucesso\n",
      "  📸 Nojo: 110 arquivos encontrados\n",
      "  ✅ Nojo: 110 imagens carregadas com sucesso\n",
      "  📸 Medo: 37 arquivos encontrados\n",
      "  ✅ Medo: 37 imagens carregadas com sucesso\n",
      "  📸 Felicidade: 487 arquivos encontrados\n",
      "  ✅ Felicidade: 487 imagens carregadas com sucesso\n",
      "  📸 Neutro: 409 arquivos encontrados\n",
      "  ✅ Neutro: 409 imagens carregadas com sucesso\n",
      "  📸 Tristeza: 226 arquivos encontrados\n",
      "  ✅ Tristeza: 226 imagens carregadas com sucesso\n",
      "  📸 Surpresa: 166 arquivos encontrados\n",
      "  ✅ Surpresa: 166 imagens carregadas com sucesso\n",
      "\n",
      "📊 Dados carregados com sucesso:\n",
      "- X_train: (6017, 224, 224, 3)\n",
      "- y_train: (6017,)\n",
      "- X_test: (1526, 224, 224, 3)\n",
      "- y_test: (1526,)\n",
      "🔄 Aplicando normalização ResNet50...\n",
      "✅ Normalização ResNet50 aplicada: [0,255] -> [0,1]\n",
      "\n",
      "🔍 Verificação final:\n",
      "- X_train range: [0.000, 1.000]\n",
      "- X_test range: [0.000, 1.000]\n",
      "- Formato das imagens: (224, 224, 3) (deve ser 224x224x3)\n",
      "\n",
      "📈 Distribuição de classes:\n",
      "- Treino:\n",
      "  Raiva: 365 imagens\n",
      "  Nojo: 434 imagens\n",
      "  Medo: 155 imagens\n",
      "  Felicidade: 1881 imagens\n",
      "  Neutro: 1470 imagens\n",
      "  Tristeza: 1023 imagens\n",
      "  Surpresa: 689 imagens\n",
      "- Teste:\n",
      "  Raiva: 91 imagens\n",
      "  Nojo: 110 imagens\n",
      "  Medo: 37 imagens\n",
      "  Felicidade: 487 imagens\n",
      "  Neutro: 409 imagens\n",
      "  Tristeza: 226 imagens\n",
      "  Surpresa: 166 imagens\n",
      "\n",
      "🎯 ResNet50: Dados prontos para treinamento!\n",
      "📏 Formato final: (6017, 224, 224, 3)\n",
      "🎨 Range de valores: [0.000, 1.000]\n",
      "✅ Pronto para ResNet50!\n"
     ]
    }
   ],
   "source": [
    "def load_preprocessed_data_resnet50_from_images():\n",
    "    \"\"\"\n",
    "    Carrega dados pré-processados de imagens JPG com normalização específica para ResNet50.\n",
    "    ResNet50 usa normalização [0, 1] padrão.\n",
    "    \n",
    "    Estrutura esperada:\n",
    "    data/processed/raf_db_temp_gray_aligned/\n",
    "    ├── Raiva/\n",
    "    ├── Nojo/\n",
    "    ├── Medo/\n",
    "    ├── Felicidade/\n",
    "    ├── Neutro/\n",
    "    ├── Tristeza/\n",
    "    └── Surpresa/\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from collections import Counter\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    print(\"Carregando dados pré-processados JPG para ResNet50...\")\n",
    "    \n",
    "    # Configurações\n",
    "    IMG_SIZE = 224  # Tamanho padrão para ResNet50\n",
    "    BASE_PATH = r\"../data/processed/raf_db_temp_gray_aligned\"  # Ajuste para seu caminho\n",
    "    \n",
    "    # Mapeamento das emoções em português\n",
    "    EMOTION_LABELS = {\n",
    "        'Raiva': 0, 'Nojo': 1, 'Medo': 2, 'Felicidade': 3, \n",
    "        'Neutro': 4, 'Tristeza': 5, 'Surpresa': 6\n",
    "    }\n",
    "    \n",
    "    def load_images_from_directory(directory_path, set_name):\n",
    "        \"\"\"Carrega imagens de um diretório usando os.path.join\"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(f\"Carregando {set_name} de: {directory_path}\")\n",
    "        \n",
    "        # Verifica se o diretório existe\n",
    "        if not os.path.exists(directory_path):\n",
    "            print(f\"❌ Diretório não encontrado: {directory_path}\")\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        # Lista subdiretórios (emoções)\n",
    "        subdirs = [d for d in os.listdir(directory_path) \n",
    "                  if os.path.isdir(os.path.join(directory_path, d))]\n",
    "        \n",
    "        print(f\"📁 Subdiretórios encontrados: {subdirs}\")\n",
    "        \n",
    "        for emotion, label in EMOTION_LABELS.items():\n",
    "            # Usar os.path.join ao invés de /\n",
    "            emotion_path = os.path.join(directory_path, emotion)\n",
    "            \n",
    "            if not os.path.exists(emotion_path):\n",
    "                print(f\"⚠️  Pasta '{emotion}' não encontrada em {directory_path}\")\n",
    "                print(f\"    Tentando variações de nome...\")\n",
    "                \n",
    "                # Tenta variações do nome da emoção\n",
    "                emotion_variations = [\n",
    "                    emotion.lower(),\n",
    "                    emotion.upper(), \n",
    "                    emotion.capitalize(),\n",
    "                    emotion.replace('ç', 'c'),  # Felicidade -> Felicidade\n",
    "                    emotion.replace('ã', 'a')   # Raiva -> Raiva\n",
    "                ]\n",
    "                \n",
    "                found = False\n",
    "                for variation in emotion_variations:\n",
    "                    test_path = os.path.join(directory_path, variation)\n",
    "                    if os.path.exists(test_path):\n",
    "                        emotion_path = test_path\n",
    "                        print(f\"    ✅ Encontrado: {variation}\")\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    print(f\"    ❌ Nenhuma variação encontrada para '{emotion}'\")\n",
    "                    continue\n",
    "            \n",
    "            # Carrega imagens da pasta da emoção\n",
    "            count = 0\n",
    "            image_files = []\n",
    "            \n",
    "            # Busca diferentes extensões\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "                import glob\n",
    "                pattern = os.path.join(emotion_path, ext)\n",
    "                image_files.extend(glob.glob(pattern))\n",
    "            \n",
    "            print(f\"  📸 {emotion}: {len(image_files)} arquivos encontrados\")\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                try:\n",
    "                    # Carrega imagem\n",
    "                    img = cv2.imread(img_file)\n",
    "                    if img is None:\n",
    "                        print(f\"    ⚠️ Não foi possível carregar: {os.path.basename(img_file)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Converte BGR para RGB\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Redimensiona se necessário\n",
    "                    if img.shape[:2] != (IMG_SIZE, IMG_SIZE):\n",
    "                        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "                    \n",
    "                    # Garante que seja RGB (3 canais)\n",
    "                    if len(img.shape) == 2:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                    elif img.shape[2] == 1:\n",
    "                        img = np.repeat(img, 3, axis=2)\n",
    "                    elif img.shape[2] == 4:  # RGBA\n",
    "                        img = img[:, :, :3]  # Remove canal alpha\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                    count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ❌ Erro ao carregar {os.path.basename(img_file)}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  ✅ {emotion}: {count} imagens carregadas com sucesso\")\n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def detect_data_structure(base_path):\n",
    "        \"\"\"Detecta a estrutura dos dados automaticamente\"\"\"\n",
    "        print(f\"🔍 Analisando estrutura de: {base_path}\")\n",
    "        \n",
    "        if not os.path.exists(base_path):\n",
    "            print(f\"❌ Caminho base não existe: {base_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Lista conteúdo do diretório\n",
    "        contents = os.listdir(base_path)\n",
    "        dirs = [d for d in contents if os.path.isdir(os.path.join(base_path, d))]\n",
    "        files = [f for f in contents if os.path.isfile(os.path.join(base_path, f))]\n",
    "        \n",
    "        print(f\"📁 Diretórios: {dirs}\")\n",
    "        print(f\"📄 Arquivos: {len(files)} encontrados\")\n",
    "        \n",
    "        # Verifica se tem estrutura train/test\n",
    "        if 'train' in dirs and 'test' in dirs:\n",
    "            print(\"✅ Estrutura detectada: train/test/emotion/\")\n",
    "            return 'train_test'\n",
    "        \n",
    "        # Verifica se as pastas são emoções diretamente\n",
    "        emotion_names = set(EMOTION_LABELS.keys())\n",
    "        found_emotions = set(dirs) & emotion_names\n",
    "        \n",
    "        if found_emotions:\n",
    "            print(f\"✅ Estrutura detectada: emotion/ direta - Emoções: {found_emotions}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        # Verifica variações de nomes\n",
    "        emotion_variations = []\n",
    "        for emotion in EMOTION_LABELS.keys():\n",
    "            variations = [emotion.lower(), emotion.upper(), emotion.capitalize()]\n",
    "            emotion_variations.extend(variations)\n",
    "        \n",
    "        found_variations = set(dirs) & set(emotion_variations)\n",
    "        if found_variations:\n",
    "            print(f\"✅ Estrutura detectada: emotion/ com variações - Encontradas: {found_variations}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        print(\"⚠️ Estrutura não reconhecida automaticamente\")\n",
    "        return 'unknown'\n",
    "    \n",
    "    try:\n",
    "        # Detecta estrutura automaticamente\n",
    "        structure = detect_data_structure(BASE_PATH)\n",
    "        \n",
    "        if structure == 'train_test':\n",
    "            # Estrutura: base/train/emotion/ e base/test/emotion/\n",
    "            train_path = os.path.join(BASE_PATH, \"train\")\n",
    "            test_path = os.path.join(BASE_PATH, \"test\")\n",
    "            \n",
    "            X_train, y_train = load_images_from_directory(train_path, \"TREINO\")\n",
    "            X_test, y_test = load_images_from_directory(test_path, \"TESTE\")\n",
    "            \n",
    "        elif structure == 'emotion_direct':\n",
    "            # Estrutura: base/emotion/ - precisa criar train/test split\n",
    "            print(\"📊 Carregando todas as imagens e criando divisão train/test...\")\n",
    "            \n",
    "            all_images, all_labels = load_images_from_directory(BASE_PATH, \"TODAS AS IMAGENS\")\n",
    "            \n",
    "            if len(all_images) == 0:\n",
    "                print(\"❌ Nenhuma imagem carregada!\")\n",
    "                return None, None, None, None\n",
    "            \n",
    "            # Cria divisão train/test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                all_images, all_labels,\n",
    "                test_size=0.2,\n",
    "                stratify=all_labels,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            print(\"✅ Divisão train/test criada automaticamente (80/20)\")\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ Estrutura de dados não suportada!\")\n",
    "            print(\"💡 Estruturas esperadas:\")\n",
    "            print(\"   1. base/train/Raiva/*.jpg, base/train/Nojo/*.jpg, etc.\")\n",
    "            print(\"   2. base/Raiva/*.jpg, base/Nojo/*.jpg, etc.\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            print(\"❌ Nenhuma imagem carregada. Verifique os caminhos e nomes das pastas!\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        print(f\"\\n📊 Dados carregados com sucesso:\")\n",
    "        print(f\"- X_train: {X_train.shape}\")\n",
    "        print(f\"- y_train: {y_train.shape}\")\n",
    "        print(f\"- X_test: {X_test.shape}\")\n",
    "        print(f\"- y_test: {y_test.shape}\")\n",
    "        \n",
    "        # NORMALIZAÇÃO ESPECÍFICA PARA RESNET50: [0, 255] -> [0, 1]\n",
    "        print(\"🔄 Aplicando normalização ResNet50...\")\n",
    "        \n",
    "        X_train = X_train.astype(np.float32)\n",
    "        X_test = X_test.astype(np.float32)\n",
    "        \n",
    "        # ResNet50 normalização padrão: [0, 255] -> [0, 1]\n",
    "        X_train = X_train / 255.0\n",
    "        X_test = X_test / 255.0\n",
    "        \n",
    "        print(\"✅ Normalização ResNet50 aplicada: [0,255] -> [0,1]\")\n",
    "        \n",
    "        # Verifica resultado final\n",
    "        print(f\"\\n🔍 Verificação final:\")\n",
    "        print(f\"- X_train range: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "        print(f\"- X_test range: [{X_test.min():.3f}, {X_test.max():.3f}]\")\n",
    "        print(f\"- Formato das imagens: {X_train.shape[1:]} (deve ser {IMG_SIZE}x{IMG_SIZE}x3)\")\n",
    "        \n",
    "        # Verifica distribuição de classes\n",
    "        train_distribution = dict(Counter(y_train))\n",
    "        test_distribution = dict(Counter(y_test))\n",
    "        \n",
    "        print(f\"\\n📈 Distribuição de classes:\")\n",
    "        emotion_names = list(EMOTION_LABELS.keys())\n",
    "        print(\"- Treino:\")\n",
    "        for label, count in train_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        print(\"- Teste:\")\n",
    "        for label, count in test_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao carregar dados: {e}\")\n",
    "        print(f\"📍 Erro detalhado: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(\"\\n💡 Soluções possíveis:\")\n",
    "        print(\"1. Verifique se o caminho está correto\")\n",
    "        print(\"2. Verifique se as pastas de emoções existem\")\n",
    "        print(\"3. Verifique se há imagens nas pastas\")\n",
    "        print(\"4. Verifique permissões de acesso\")\n",
    "        \n",
    "        return None, None, None, None\n",
    "\n",
    "# Executa carregamento para ResNet50\n",
    "X_train, y_train, X_test, y_test = load_preprocessed_data_resnet50_from_images()\n",
    "monitor.update_peak_memory()\n",
    "\n",
    "if X_train is not None:\n",
    "    print(f\"\\n🎯 ResNet50: Dados prontos para treinamento!\")\n",
    "    print(f\"📏 Formato final: {X_train.shape}\")\n",
    "    print(f\"🎨 Range de valores: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "    print(f\"✅ Pronto para ResNet50!\")\n",
    "else:\n",
    "    print(\"❌ Falha no carregamento dos dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94cd085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento iniciado: resnet50_emotion_20250925_214459\n"
     ]
    }
   ],
   "source": [
    "def create_experiment_structure():\n",
    "    \"\"\"\n",
    "    Cria estrutura de diretórios para salvar modelos e métricas.\n",
    "    \"\"\"\n",
    "    # Cria timestamp único para o experimento\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    experiment_id = f\"resnet50_emotion_{timestamp}\"\n",
    "    \n",
    "    # Cria diretórios\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"metrics\", exist_ok=True)\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    \n",
    "    return experiment_id\n",
    "\n",
    "def save_model_if_good_performance(model, accuracy, f1_score, experiment_id, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Salva modelo apenas se a performance for boa.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        accuracy: Acurácia do modelo\n",
    "        f1_score: F1-score macro do modelo\n",
    "        experiment_id: ID único do experimento\n",
    "        threshold: Limite mínimo para salvar (default: 85%)\n",
    "    \"\"\"\n",
    "    if accuracy >= threshold or f1_score >= threshold:\n",
    "        model_path = f\"models/resnet50_emotion_{experiment_id}.pkl\"\n",
    "        \n",
    "        # Salva apenas os pesos para economia de espaço\n",
    "        model.save_weights(f\"models/weights_resnet50_{experiment_id}.h5\")\n",
    "        \n",
    "        # Salva configuração do modelo\n",
    "        model_config = {\n",
    "            'architecture': 'ResNet50',\n",
    "            'img_size': IMG_SIZE,\n",
    "            'num_classes': 7,\n",
    "            'experiment_id': experiment_id,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_score,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(f\"models/config_resnet50_{experiment_id}.pkl\", 'wb') as f:\n",
    "            pickle.dump(model_config, f)\n",
    "        \n",
    "        print(f\"Modelo salvo! Performance: Acc={accuracy:.4f}, F1={f1_score:.4f}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Performance insuficiente para salvar. Acc={accuracy:.4f}, F1={f1_score:.4f} < {threshold}\")\n",
    "        return False\n",
    "\n",
    "def save_metrics_to_csv(metrics_dict, experiment_id):\n",
    "    \"\"\"\n",
    "    Salva métricas de performance em arquivo CSV.\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: Dicionário com todas as métricas\n",
    "        experiment_id: ID único do experimento\n",
    "    \"\"\"\n",
    "    # Converte métricas para DataFrame\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "    \n",
    "    # Arquivo CSV principal\n",
    "    csv_path = \"metrics/performance_metrics.csv\"\n",
    "    \n",
    "    # Append ao CSV se já existir, senão cria novo\n",
    "    if os.path.exists(csv_path):\n",
    "        metrics_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Salva também arquivo individual do experimento\n",
    "    individual_csv = f\"metrics/metrics_{experiment_id}.csv\"\n",
    "    metrics_df.to_csv(individual_csv, index=False)\n",
    "    \n",
    "    print(f\"Métricas salvas em: {csv_path} e {individual_csv}\")\n",
    "\n",
    "# Inicializa estrutura do experimento\n",
    "experiment_id = create_experiment_structure()\n",
    "print(f\"Experimento iniciado: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf7137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU COMPLETAMENTE DESABILITADA - Usando apenas CPU\n"
     ]
    }
   ],
   "source": [
    "# CÉLULA 1: Desabilita GPU COMPLETAMENTE\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Desabilita GPU ANTES de importar TensorFlow\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Suprime warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"GPU COMPLETAMENTE DESABILITADA - Usando apenas CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd32e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos físicos: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU disponível: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Usando dispositivo: CPU apenas\n"
     ]
    }
   ],
   "source": [
    "# CÉLULA 2: Importa TensorFlow APÓS desabilitar GPU\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Verifica se GPU está realmente desabilitada\n",
    "print(f\"Dispositivos físicos: {tf.config.list_physical_devices()}\")\n",
    "print(f\"GPU disponível: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"Usando dispositivo: CPU apenas\")\n",
    "\n",
    "# Limpa qualquer sessão anterior\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77eb9d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando ResNet50 com CPU puro...\n",
      "ResNet50 base carregado com sucesso\n",
      "Modelo ResNet50 criado com CPU\n",
      "SUCESSO - Modelo criado:\n",
      "- Total parâmetros: 24,769,927\n",
      "- Treináveis: 1,182,215\n",
      "- Dispositivo: CPU\n",
      "- Memória atual: 9937.3 MB\n"
     ]
    }
   ],
   "source": [
    "# CÉLULA 3: Cria modelo ResNet50 APENAS com CPU\n",
    "def create_resnet50_model_cpu_pure():\n",
    "    \"\"\"\n",
    "    Cria modelo ResNet50 forçando CPU puro - SEM GPU\n",
    "    \"\"\"\n",
    "    print(\"Criando ResNet50 com CPU puro...\")\n",
    "    \n",
    "    # Força explicitamente CPU\n",
    "    with tf.device('/CPU:0'):\n",
    "        # Limpa sessão\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        try:\n",
    "            # ResNet50 base\n",
    "            base_model = ResNet50(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "            )\n",
    "            \n",
    "            print(\"ResNet50 base carregado com sucesso\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro com pesos ImageNet: {e}\")\n",
    "            print(\"Tentando sem pesos pré-treinados...\")\n",
    "            \n",
    "            # Fallback sem pesos\n",
    "            base_model = ResNet50(\n",
    "                weights=None,\n",
    "                include_top=False,\n",
    "                input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "            )\n",
    "            print(\"ResNet50 criado SEM pesos pré-treinados\")\n",
    "        \n",
    "        # Congela base\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        # Adiciona camadas customizadas\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "        x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "        x = Dropout(0.5, name='dropout_1')(x)\n",
    "        x = Dense(256, activation='relu', name='dense_256')(x)\n",
    "        x = Dropout(0.3, name='dropout_2')(x)\n",
    "        predictions = Dense(7, activation='softmax', name='predictions')(x)\n",
    "        \n",
    "        # Modelo final\n",
    "        model = Model(inputs=base_model.input, outputs=predictions, name='ResNet50_Emotion_CPU')\n",
    "        \n",
    "        print(\"Modelo ResNet50 criado com CPU\")\n",
    "        \n",
    "        return model, base_model\n",
    "\n",
    "# Executa criação\n",
    "if X_train is not None:\n",
    "    model, base_model = create_resnet50_model_cpu_pure()\n",
    "    \n",
    "    if model is not None:\n",
    "        total_params = model.count_params()\n",
    "        trainable_params = sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "        \n",
    "        print(f\"SUCESSO - Modelo criado:\")\n",
    "        print(f\"- Total parâmetros: {total_params:,}\")\n",
    "        print(f\"- Treináveis: {trainable_params:,}\")\n",
    "        print(f\"- Dispositivo: CPU\")\n",
    "        print(f\"- Memória atual: {monitor._get_memory_usage():.1f} MB\")\n",
    "        \n",
    "        monitor.update_peak_memory()\n",
    "    else:\n",
    "        print(\"FALHA na criação do modelo\")\n",
    "else:\n",
    "    print(\"Dados não carregados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7013d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para treinamento...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     52\u001b[39m X_train_split, X_val, y_train_split, y_val = train_test_split(\n\u001b[32m     53\u001b[39m     X_train, y_train, \n\u001b[32m     54\u001b[39m     test_size=VALIDATION_SPLIT,   \u001b[38;5;66;03m# 30% para validação\u001b[39;00m\n\u001b[32m     55\u001b[39m     stratify=y_train,             \u001b[38;5;66;03m# Mantém proporção por classe\u001b[39;00m\n\u001b[32m     56\u001b[39m     random_state=\u001b[32m42\u001b[39m               \u001b[38;5;66;03m# Reprodutibilidade\u001b[39;00m\n\u001b[32m     57\u001b[39m )\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Converte labels para formato categorical (one-hot encoding)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m y_train_cat = \u001b[43mto_categorical\u001b[49m(y_train_split, \u001b[32m7\u001b[39m)\n\u001b[32m     61\u001b[39m y_val_cat = to_categorical(y_val, \u001b[32m7\u001b[39m)\n\u001b[32m     62\u001b[39m y_test_cat = to_categorical(y_test, \u001b[32m7\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback customizado para monitoramento de memória durante treinamento.\n",
    "    Essencial para experimentos com recursos limitados.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.monitor.update_peak_memory()\n",
    "        if epoch % 5 == 0:  # Log a cada 5 épocas\n",
    "            current_memory = self.monitor._get_memory_usage()\n",
    "            print(f\"Época {epoch+1} - Memória atual: {current_memory:.2f} MB\")\n",
    "\n",
    "def setup_training_callbacks(monitor):\n",
    "    \"\"\"\n",
    "    Configura callbacks para treinamento otimizado.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de callbacks configurados\n",
    "    \"\"\"\n",
    "    # Early Stopping: Para evitar overfitting\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',           # Métrica para monitorar\n",
    "        patience=15,                  # Épocas sem melhoria antes de parar\n",
    "        restore_best_weights=True,    # Restaura melhores pesos\n",
    "        verbose=1,                    # Mostra quando para\n",
    "        mode='min'                    # Minimizar loss\n",
    "    )\n",
    "    \n",
    "    # Reduce Learning Rate: Ajuste adaptativo da taxa de aprendizado\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',           # Métrica para monitorar\n",
    "        factor=0.2,                   # Fator de redução (lr = lr * factor)\n",
    "        patience=10,                  # Épocas sem melhoria antes de reduzir\n",
    "        min_lr=1e-7,                  # Taxa mínima de aprendizado\n",
    "        verbose=1,                    # Mostra quando reduz\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Memory monitoring callback\n",
    "    memory_callback = MemoryCallback(monitor)\n",
    "    \n",
    "    return [early_stopping, reduce_lr, memory_callback]\n",
    "\n",
    "# Preparação dos dados para treinamento\n",
    "print(\"Preparando dados para treinamento...\")\n",
    "\n",
    "# Divisão treino/validação estratificada\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=VALIDATION_SPLIT,   # 30% para validação\n",
    "    stratify=y_train,             # Mantém proporção por classe\n",
    "    random_state=42               # Reprodutibilidade\n",
    ")\n",
    "\n",
    "# Converte labels para formato categorical (one-hot encoding)\n",
    "y_train_cat = to_categorical(y_train_split, 7)\n",
    "y_val_cat = to_categorical(y_val, 7)\n",
    "y_test_cat = to_categorical(y_test, 7)\n",
    "\n",
    "print(f\"Dados de treino: {X_train_split.shape}\")\n",
    "print(f\"Dados de validação: {X_val.shape}\")\n",
    "print(f\"Dados de teste: {X_test.shape}\")\n",
    "print(f\"Distribuição de classes - Treino: {dict(Counter(y_train_split))}\")\n",
    "print(f\"Distribuição de classes - Validação: {dict(Counter(y_val))}\")\n",
    "\n",
    "# Configura callbacks\n",
    "callbacks = setup_training_callbacks(monitor)\n",
    "print(\"Callbacks configurados para treinamento otimizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808ede0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recriando modelo ResNet50 com compilação...\n",
      "Criando ResNet50 com CPU puro...\n",
      "ResNet50 base carregado com sucesso\n",
      "Modelo ResNet50 criado e COMPILADO com CPU\n",
      "SUCESSO - Modelo criado e compilado:\n",
      "- Total parâmetros: 24,769,927\n",
      "- Treináveis: 1,182,215\n",
      "- Optimizer: Adam (lr=0.0001)\n",
      "- Loss: categorical_crossentropy\n",
      "- Metrics: accuracy\n",
      "- Dispositivo: CPU\n"
     ]
    }
   ],
   "source": [
    "def create_resnet50_model_cpu_pure():\n",
    "    \"\"\"\n",
    "    Cria modelo ResNet50 forçando CPU puro - SEM GPU\n",
    "    VERSÃO CORRIGIDA: Inclui compilação do modelo\n",
    "    \"\"\"\n",
    "    print(\"Criando ResNet50 com CPU puro...\")\n",
    "    \n",
    "    # Força explicitamente CPU\n",
    "    with tf.device('/CPU:0'):\n",
    "        # Limpa sessão\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        try:\n",
    "            # ResNet50 base\n",
    "            base_model = ResNet50(\n",
    "                weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "            )\n",
    "            \n",
    "            print(\"ResNet50 base carregado com sucesso\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro com pesos ImageNet: {e}\")\n",
    "            print(\"Tentando sem pesos pré-treinados...\")\n",
    "            \n",
    "            # Fallback sem pesos\n",
    "            base_model = ResNet50(\n",
    "                weights=None,\n",
    "                include_top=False,\n",
    "                input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "            )\n",
    "            print(\"ResNet50 criado SEM pesos pré-treinados\")\n",
    "        \n",
    "        # Congela base\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        # Adiciona camadas customizadas\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "        x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "        x = Dropout(0.5, name='dropout_1')(x)\n",
    "        x = Dense(256, activation='relu', name='dense_256')(x)\n",
    "        x = Dropout(0.3, name='dropout_2')(x)\n",
    "        predictions = Dense(7, activation='softmax', name='predictions')(x)\n",
    "        \n",
    "        # Modelo final\n",
    "        model = Model(inputs=base_model.input, outputs=predictions, name='ResNet50_Emotion_CPU')\n",
    "        \n",
    "        # ADICIONADO: COMPILAÇÃO DO MODELO\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.0001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        print(\"Modelo ResNet50 criado e COMPILADO com CPU\")\n",
    "        \n",
    "        return model, base_model\n",
    "\n",
    "# Recria o modelo COM compilação\n",
    "if X_train is not None:\n",
    "    print(\"Recriando modelo ResNet50 com compilação...\")\n",
    "    model, base_model = create_resnet50_model_cpu_pure()\n",
    "    \n",
    "    if model is not None:\n",
    "        total_params = model.count_params()\n",
    "        trainable_params = sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "        \n",
    "        print(f\"SUCESSO - Modelo criado e compilado:\")\n",
    "        print(f\"- Total parâmetros: {total_params:,}\")\n",
    "        print(f\"- Treináveis: {trainable_params:,}\")\n",
    "        print(f\"- Optimizer: Adam (lr=0.0001)\")\n",
    "        print(f\"- Loss: categorical_crossentropy\")\n",
    "        print(f\"- Metrics: accuracy\")\n",
    "        print(f\"- Dispositivo: CPU\")\n",
    "        \n",
    "        monitor.update_peak_memory()\n",
    "    else:\n",
    "        print(\"FALHA na criação do modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1149a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparação concluída:\n",
      "- Treino: (4211, 224, 224, 3) | Labels: (4211, 7)\n",
      "- Validação: (1806, 224, 224, 3) | Labels: (1806, 7)\n",
      "- Teste: (1526, 224, 224, 3) | Labels: (1526, 7)\n",
      "Iniciando treinamento ResNet50...\n",
      "Iniciando treinamento ResNet50...\n",
      "Horário de início: 2025-09-16 18:20:29\n",
      "Memória inicial: 15723.20 MB\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 18:20:30.043772: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 2535493632 exceeds 10% of free system memory.\n",
      "2025-09-16 18:20:32.144027: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 2535493632 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 18:20:38.320394: W tensorflow/core/framework/op_kernel.cc:1855] OP_REQUIRES failed at xla_ops.cc:528 : INVALID_ARGUMENT: Trying to access resource conv1_conv/kernel/2285 (defined @ /home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_73437/884529358.py\", line 71, in <module>\n\n  File \"/tmp/ipykernel_73437/884529358.py\", line 15, in train_resnet50_model\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nTrying to access resource conv1_conv/kernel/2285 (defined @ /home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_39849]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m     callbacks = setup_training_callbacks(monitor)\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# Executa treinamento\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     history, training_metrics = \u001b[43mtrain_resnet50_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTreinamento finalizado com sucesso!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain_resnet50_model\u001b[39m\u001b[34m(model, X_train, y_train, X_val, y_val, monitor, callbacks)\u001b[39m\n\u001b[32m     12\u001b[39m training_start_time = time.time()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Executa treinamento\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Calcula tempo de treinamento\u001b[39;00m\n\u001b[32m     26\u001b[39m training_end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_73437/884529358.py\", line 71, in <module>\n\n  File \"/tmp/ipykernel_73437/884529358.py\", line 15, in train_resnet50_model\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nTrying to access resource conv1_conv/kernel/2285 (defined @ /home/joao/Desktop/emotion_recognition_tcc/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:42) located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_39849]"
     ]
    }
   ],
   "source": [
    "def train_resnet50_model(model, X_train, y_train, X_val, y_val, monitor, callbacks):\n",
    "    \"\"\"\n",
    "    Executa treinamento completo do ResNet50 com monitoramento detalhado.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (history, training_metrics)\n",
    "    \"\"\"\n",
    "    print(\"Iniciando treinamento ResNet50...\")\n",
    "    monitor.start_monitoring()\n",
    "    \n",
    "    # Inicia cronômetro específico do treinamento\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    # Executa treinamento\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Calcula tempo de treinamento\n",
    "    training_end_time = time.time()\n",
    "    training_duration = training_end_time - training_start_time\n",
    "    \n",
    "    # Métricas do treinamento\n",
    "    training_metrics = {\n",
    "        'training_time_seconds': training_duration,\n",
    "        'training_time_formatted': str(timedelta(seconds=int(training_duration))),\n",
    "        'epochs_completed': len(history.history['accuracy']),\n",
    "        'best_train_accuracy': max(history.history['accuracy']),\n",
    "        'best_val_accuracy': max(history.history['val_accuracy']),\n",
    "        'final_train_loss': history.history['loss'][-1],\n",
    "        'final_val_loss': history.history['val_loss'][-1]\n",
    "    }\n",
    "    \n",
    "    print(f\"Treinamento concluído em: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"Épocas executadas: {training_metrics['epochs_completed']}\")\n",
    "    print(f\"Melhor acurácia validação: {training_metrics['best_val_accuracy']:.4f}\")\n",
    "    \n",
    "    return history, training_metrics\n",
    "\n",
    "# Preparação dos dados se carregamento foi bem-sucedido\n",
    "if X_train is not None and y_train is not None:\n",
    "    \n",
    "    # Divisão estratificada treino/validação\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=VALIDATION_SPLIT,\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Conversão para categorical (one-hot encoding)\n",
    "    y_train_cat = to_categorical(y_train_split, 7)\n",
    "    y_val_cat = to_categorical(y_val, 7)\n",
    "    y_test_cat = to_categorical(y_test, 7)\n",
    "    \n",
    "    print(f\"Preparação concluída:\")\n",
    "    print(f\"- Treino: {X_train_split.shape} | Labels: {y_train_cat.shape}\")\n",
    "    print(f\"- Validação: {X_val.shape} | Labels: {y_val_cat.shape}\")\n",
    "    print(f\"- Teste: {X_test.shape} | Labels: {y_test_cat.shape}\")\n",
    "    \n",
    "    # Configura callbacks\n",
    "    callbacks = setup_training_callbacks(monitor)\n",
    "    \n",
    "    # Executa treinamento\n",
    "    history, training_metrics = train_resnet50_model(\n",
    "        model, X_train_split, y_train_cat, X_val, y_val_cat, monitor, callbacks\n",
    "    )\n",
    "    \n",
    "    print(\"Treinamento finalizado com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Dados não disponíveis para treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_model_evaluation(model, X_test, y_test_cat, y_test_original):\n",
    "    \"\"\"\n",
    "    Avaliação completa do modelo com todas as métricas necessárias.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário completo com todas as métricas\n",
    "    \"\"\"\n",
    "    print(\"Iniciando avaliação completa do modelo...\")\n",
    "    \n",
    "    # Mede tempo de inferência\n",
    "    inference_start = time.time()\n",
    "    y_pred_prob = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "    inference_end = time.time()\n",
    "    \n",
    "    # Calcula métricas de tempo\n",
    "    total_inference_time = inference_end - inference_start\n",
    "    inference_per_sample = total_inference_time / len(X_test)\n",
    "    samples_per_second = len(X_test) / total_inference_time\n",
    "    \n",
    "    # Conversões para cálculos de métricas\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = y_test_original\n",
    "    \n",
    "    # Métricas de classificação\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Métricas por classe\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    # Métricas de memória atual\n",
    "    current_memory = monitor._get_memory_usage()\n",
    "    \n",
    "    # Relatório detalhado por classe\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    class_report = classification_report(\n",
    "        y_true_classes, y_pred_classes, \n",
    "        target_names=emotion_names, \n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # Compilação completa das métricas\n",
    "    comprehensive_metrics = {\n",
    "        # Identificação do experimento\n",
    "        'experiment_id': experiment_id,\n",
    "        'model_architecture': 'ResNet50',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        \n",
    "        # Configurações do modelo\n",
    "        'img_size': IMG_SIZE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_trained': len(history.history['accuracy']),\n",
    "        \n",
    "        # Métricas de performance principal\n",
    "        'test_accuracy': accuracy,\n",
    "        'f1_score_macro': f1,\n",
    "        'f1_score_micro': f1_micro,\n",
    "        'f1_score_weighted': f1_weighted,\n",
    "        'precision_macro': precision,\n",
    "        'recall_macro': recall,\n",
    "        \n",
    "        # Métricas de tempo\n",
    "        'total_inference_time_seconds': total_inference_time,\n",
    "        'inference_per_sample_ms': inference_per_sample * 1000,\n",
    "        'samples_per_second': samples_per_second,\n",
    "        'training_time_seconds': training_metrics['training_time_seconds'],\n",
    "        \n",
    "        # Métricas de memória\n",
    "        'peak_memory_mb': monitor.peak_memory_mb,\n",
    "        'current_memory_mb': current_memory,\n",
    "        'memory_efficiency': monitor.initial_memory_mb / monitor.peak_memory_mb,\n",
    "        \n",
    "        # Métricas por classe (emotion-wise)\n",
    "        'anger_f1': class_report['anger']['f1-score'],\n",
    "        'disgust_f1': class_report['disgust']['f1-score'],\n",
    "        'fear_f1': class_report['fear']['f1-score'],\n",
    "        'happy_f1': class_report['happy']['f1-score'],\n",
    "        'neutral_f1': class_report['neutral']['f1-score'],\n",
    "        'sadness_f1': class_report['sadness']['f1-score'],\n",
    "        'surprise_f1': class_report['surprise']['f1-score'],\n",
    "        \n",
    "        # Dados do dataset\n",
    "        'train_samples': len(X_train_split),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'total_parameters': model.count_params(),\n",
    "        'trainable_parameters': sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    }\n",
    "    \n",
    "    return comprehensive_metrics, conf_matrix, class_report\n",
    "\n",
    "# Executa avaliação completa se treinamento foi bem-sucedido\n",
    "if 'history' in locals() and history is not None:\n",
    "    \n",
    "    print(\"Executando avaliação completa...\")\n",
    "    \n",
    "    # Avaliação detalhada\n",
    "    metrics, confusion_matrix_result, detailed_report = comprehensive_model_evaluation(\n",
    "        model, X_test, y_test_cat, y_test\n",
    "    )\n",
    "    \n",
    "    # Salva métricas em CSV\n",
    "    save_metrics_to_csv(metrics, experiment_id)\n",
    "    \n",
    "    # Tenta salvar modelo se performance for boa\n",
    "    model_saved = save_model_if_good_performance(\n",
    "        model, \n",
    "        metrics['test_accuracy'], \n",
    "        metrics['f1_score_macro'], \n",
    "        experiment_id,\n",
    "        threshold=0.80  # Ajuste conforme necessário\n",
    "    )\n",
    "    \n",
    "    # Finaliza monitoramento\n",
    "    monitor_final_stats = monitor.end_monitoring()\n",
    "    \n",
    "    print(f\"\\nRESUMO DO EXPERIMENTO {experiment_id}:\")\n",
    "    print(f\"Acurácia: {metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"Tempo de treinamento: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"Inferência por amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"Modelo salvo: {'Sim' if model_saved else 'Não'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Treinamento não foi executado corretamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc48890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualizations(history, confusion_matrix_result, metrics, detailed_report):\n",
    "    \"\"\"\n",
    "    Cria visualizações completas dos resultados para análise científica.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Histórico de treinamento\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    plt.title('Model Accuracy - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title('Model Loss - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Matriz de confusão\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    sns.heatmap(confusion_matrix_result, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax3)\n",
    "    plt.title('Confusion Matrix - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # 3. F1-Score por classe\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    f1_scores = [detailed_report[emotion]['f1-score'] for emotion in emotion_names]\n",
    "    bars = plt.bar(emotion_names, f1_scores, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    plt.title('F1-Score por Emoção', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Adiciona valores nas barras\n",
    "    for bar, score in zip(bars, f1_scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. Métricas de performance\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    performance_metrics = ['Accuracy', 'F1-Macro', 'Precision', 'Recall']\n",
    "    performance_values = [\n",
    "        metrics['test_accuracy'],\n",
    "        metrics['f1_score_macro'],\n",
    "        metrics['precision_macro'],\n",
    "        metrics['recall_macro']\n",
    "    ]\n",
    "    bars = plt.bar(performance_metrics, performance_values, \n",
    "                  color=['green', 'blue', 'orange', 'red'], alpha=0.7)\n",
    "    plt.title('Métricas Gerais de Performance', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar, value in zip(bars, performance_values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 5. Análise de tempo e memória\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    resource_data = {\n",
    "        'Tempo Treino (min)': metrics['training_time_seconds'] / 60,\n",
    "        'Inferência/amostra (ms)': metrics['inference_per_sample_ms'],\n",
    "        'Pico Memória (GB)': metrics['peak_memory_mb'] / 1024,\n",
    "        'Amostras/seg': metrics['samples_per_second']\n",
    "    }\n",
    "    \n",
    "    # Normaliza valores para visualização\n",
    "    normalized_values = []\n",
    "    labels = []\n",
    "    for key, value in resource_data.items():\n",
    "        if 'Tempo' in key:\n",
    "            normalized_values.append(value / max(1, value) if value > 0 else 0)\n",
    "        elif 'Memória' in key:\n",
    "            normalized_values.append(min(value, 1))\n",
    "        else:\n",
    "            normalized_values.append(min(value / 100, 1))  # Normaliza outras métricas\n",
    "        labels.append(f'{key}\\n{value:.2f}')\n",
    "    \n",
    "    plt.bar(range(len(labels)), normalized_values, color='purple', alpha=0.7)\n",
    "    plt.title('Recursos Computacionais (Normalizado)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(labels)), [label.split('\\n')[0] for label in labels], rotation=45)\n",
    "    plt.ylabel('Valor Normalizado')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/comprehensive_analysis_{experiment_id}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Relatório textual final\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RELATÓRIO CIENTÍFICO FINAL - EXPERIMENTO {experiment_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ARQUITETURA: ResNet50 Transfer Learning\")\n",
    "    print(f\"DATASET: Emoções balanceadas (7 classes)\")\n",
    "    print(f\"CONFIGURAÇÃO: {IMG_SIZE}x{IMG_SIZE}, batch_size={BATCH_SIZE}\")\n",
    "    print(f\"\\nPERFORMANCE PRINCIPAL:\")\n",
    "    print(f\"  • Acurácia de Teste: {metrics['test_accuracy']:.4f} ({metrics['test_accuracy']*100:.2f}%)\")\n",
    "    print(f\"  • F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"  • Precisão Macro: {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"  • Recall Macro: {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"\\nEFICIÊNCIA COMPUTACIONAL:\")\n",
    "    print(f\"  • Tempo de Treinamento: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"  • Épocas Executadas: {metrics['epochs_trained']}\")\n",
    "    print(f\"  • Inferência por Amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"  • Throughput: {metrics['samples_per_second']:.1f} amostras/segundo\")\n",
    "    print(f\"  • Pico de Memória: {metrics['peak_memory_mb']:.1f} MB\")\n",
    "    print(f\"\\nPERFORMANCE POR EMOÇÃO:\")\n",
    "    for emotion in emotion_names:\n",
    "        f1_score = detailed_report[emotion]['f1-score']\n",
    "        print(f\"  • {emotion.capitalize()}: F1={f1_score:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# Executa análise completa se avaliação foi bem-sucedida\n",
    "if 'metrics' in locals() and metrics is not None:\n",
    "    create_comprehensive_visualizations(history, confusion_matrix_result, metrics, detailed_report)\n",
    "    print(\"Análise completa finalizada!\")\n",
    "    print(f\"Arquivos salvos:\")\n",
    "    print(f\"  • Métricas: metrics/performance_metrics.csv\")\n",
    "    print(f\"  • Visualizações: plots/comprehensive_analysis_{experiment_id}.png\")\n",
    "    if model_saved:\n",
    "        print(f\"  • Modelo: models/weights_resnet50_{experiment_id}.h5\")\n",
    "else:\n",
    "    print(\"Erro: Avaliação não foi executada corretamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
