{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222a3107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 16:18:32.144289: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-16 16:18:32.390820: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-16 16:18:33.529611: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import time\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458fb964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configura√ß√£o CUDA Ubuntu aplicada:\n",
      "- XLA_FLAGS: --xla_gpu_cuda_data_dir=/usr/lib/nvidia-cuda-toolkit\n",
      "- CUDA_ROOT: /usr/lib/nvidia-cuda-toolkit\n",
      "GPU configurada: 1 dispositivo(s)\n",
      "Testando opera√ß√£o GPU...\n",
      "Teste conclu√≠do! Resultado: -0.000220\n",
      "Warnings CUDA eliminados com sucesso!\n",
      "TensorFlow 2.20.0 pronto!\n",
      "Keras importado - sistema pronto para ResNet50!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758050315.327677    4826 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9526 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Configura o caminho correto baseado na sua instala√ß√£o Ubuntu\n",
    "# Voc√™ tem libdevice em: /usr/lib/nvidia-cuda-toolkit/libdevice/\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/lib/nvidia-cuda-toolkit'\n",
    "\n",
    "# Configura√ß√µes adicionais para Ubuntu\n",
    "os.environ['CUDA_ROOT'] = '/usr/lib/nvidia-cuda-toolkit'\n",
    "os.environ['CUDA_HOME'] = '/usr/lib/nvidia-cuda-toolkit'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Suprime warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Configura√ß√£o CUDA Ubuntu aplicada:\")\n",
    "print(f\"- XLA_FLAGS: {os.environ['XLA_FLAGS']}\")\n",
    "print(f\"- CUDA_ROOT: {os.environ['CUDA_ROOT']}\")\n",
    "\n",
    "\n",
    "\n",
    "# Configura logging\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Configura GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Habilita crescimento din√¢mico de mem√≥ria\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        print(f\"GPU configurada: {len(gpus)} dispositivo(s)\")\n",
    "        \n",
    "        # Teste para verificar se warnings foram eliminados\n",
    "        print(\"Testando opera√ß√£o GPU...\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            # Opera√ß√£o simples de teste\n",
    "            test_tensor = tf.random.normal([1000, 1000])\n",
    "            result = tf.reduce_mean(test_tensor)\n",
    "            \n",
    "        print(f\"Teste conclu√≠do! Resultado: {result.numpy():.6f}\")\n",
    "        print(\"Warnings CUDA eliminados com sucesso!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na configura√ß√£o GPU: {e}\")\n",
    "        print(\"Continuando com CPU...\")\n",
    "\n",
    "print(f\"TensorFlow {tf.__version__} pronto!\")\n",
    "\n",
    "# Importa√ß√µes do Keras funcionar√£o sem warnings agora\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "print(\"Keras importado - sistema pronto para ResNet50!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c81aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU dispon√≠vel: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√£o de reprodutibilidade\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU dispon√≠vel: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c498c1f9-ddf9-43d5-8bbd-379b72bbf1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configura√ß√µes definidas:\n",
      "- Tamanho da imagem: 224x224\n",
      "- Batch size: 8\n",
      "- √âpocas m√°ximas: 50\n",
      "- Classes de emo√ß√£o: 7\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes do experimento\n",
    "IMG_SIZE = 224  # Tamanho da imagem (224x224 pixels)\n",
    "BATCH_SIZE = 8  # Tamanho do lote para treinamento\n",
    "EPOCHS = 50  # N√∫mero m√°ximo de √©pocas\n",
    "VALIDATION_SPLIT = 0.3  # 30% dos dados para valida√ß√£o\n",
    "\n",
    "# Caminhos dos datasets\n",
    "FER2013_PATH = r\"src/data/FER2013\"\n",
    "RAF_DB_PATH = r\"src/data/ RAF-DB\"\n",
    "DFEW_DB_PATH = r\"src/data/DFEW\"\n",
    "\n",
    "\n",
    "# Mapeamento das 7 emo√ß√µes b√°sicas\n",
    "EMOTION_LABELS = {\n",
    "    'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, \n",
    "    'neutral': 4, 'sadness': 5, 'surprise': 6\n",
    "}\n",
    "\n",
    "print(\"Configura√ß√µes definidas:\")\n",
    "print(f\"- Tamanho da imagem: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- √âpocas m√°ximas: {EPOCHS}\")\n",
    "print(f\"- Classes de emo√ß√£o: {len(EMOTION_LABELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8260fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor:\n",
    "    \"\"\"\n",
    "    Classe para monitorar desempenho computacional durante o treinamento.\n",
    "    Essencial para experimentos cient√≠ficos reproduz√≠veis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.peak_memory_mb = 0\n",
    "        self.initial_memory_mb = 0\n",
    "        self.process = psutil.Process()\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Inicia o monitoramento de tempo e mem√≥ria\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.initial_memory_mb = self._get_memory_usage()\n",
    "        self.peak_memory_mb = self.initial_memory_mb\n",
    "        print(f\"Iniciando treinamento ResNet50...\")\n",
    "        print(f\"Hor√°rio de in√≠cio: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Mem√≥ria inicial: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    def _get_memory_usage(self):\n",
    "        \"\"\"Retorna uso atual de mem√≥ria em MB\"\"\"\n",
    "        return self.process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "    def update_peak_memory(self):\n",
    "        \"\"\"Atualiza o pico de mem√≥ria se necess√°rio\"\"\"\n",
    "        current_memory = self._get_memory_usage()\n",
    "        if current_memory > self.peak_memory_mb:\n",
    "            self.peak_memory_mb = current_memory\n",
    "\n",
    "# Instancia o monitor\n",
    "monitor = TrainingMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e13fe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados pr√©-processados JPG para ResNet50...\n",
      "üîç Analisando estrutura de: /home/leandro/Documents/TCC/emotion_recognition_tcc/data/processed/raf_db_temp_gray_aligned\n",
      "üìÅ Diret√≥rios: ['test', 'train']\n",
      "üìÑ Arquivos: 0 encontrados\n",
      "‚úÖ Estrutura detectada: train/test/emotion/\n",
      "Carregando TREINO de: /home/leandro/Documents/TCC/emotion_recognition_tcc/data/processed/raf_db_temp_gray_aligned/train\n",
      "üìÅ Subdiret√≥rios encontrados: ['Felicidade', 'Surpresa', 'Raiva', 'Tristeza', 'Medo', 'Nojo', 'Neutro']\n",
      "  üì∏ Raiva: 365 arquivos encontrados\n",
      "  ‚úÖ Raiva: 365 imagens carregadas com sucesso\n",
      "  üì∏ Nojo: 434 arquivos encontrados\n",
      "  ‚úÖ Nojo: 434 imagens carregadas com sucesso\n",
      "  üì∏ Medo: 155 arquivos encontrados\n",
      "  ‚úÖ Medo: 155 imagens carregadas com sucesso\n",
      "  üì∏ Felicidade: 1881 arquivos encontrados\n",
      "  ‚úÖ Felicidade: 1881 imagens carregadas com sucesso\n",
      "  üì∏ Neutro: 1470 arquivos encontrados\n",
      "  ‚úÖ Neutro: 1470 imagens carregadas com sucesso\n",
      "  üì∏ Tristeza: 1023 arquivos encontrados\n",
      "  ‚úÖ Tristeza: 1023 imagens carregadas com sucesso\n",
      "  üì∏ Surpresa: 689 arquivos encontrados\n",
      "  ‚úÖ Surpresa: 689 imagens carregadas com sucesso\n",
      "Carregando TESTE de: /home/leandro/Documents/TCC/emotion_recognition_tcc/data/processed/raf_db_temp_gray_aligned/test\n",
      "üìÅ Subdiret√≥rios encontrados: ['Felicidade', 'Surpresa', 'Raiva', 'Tristeza', 'Medo', 'Nojo', 'Neutro']\n",
      "  üì∏ Raiva: 91 arquivos encontrados\n",
      "  ‚úÖ Raiva: 91 imagens carregadas com sucesso\n",
      "  üì∏ Nojo: 110 arquivos encontrados\n",
      "  ‚úÖ Nojo: 110 imagens carregadas com sucesso\n",
      "  üì∏ Medo: 37 arquivos encontrados\n",
      "  ‚úÖ Medo: 37 imagens carregadas com sucesso\n",
      "  üì∏ Felicidade: 487 arquivos encontrados\n",
      "  ‚úÖ Felicidade: 487 imagens carregadas com sucesso\n",
      "  üì∏ Neutro: 409 arquivos encontrados\n",
      "  ‚úÖ Neutro: 409 imagens carregadas com sucesso\n",
      "  üì∏ Tristeza: 226 arquivos encontrados\n",
      "  ‚úÖ Tristeza: 226 imagens carregadas com sucesso\n",
      "  üì∏ Surpresa: 166 arquivos encontrados\n",
      "  ‚úÖ Surpresa: 166 imagens carregadas com sucesso\n",
      "\n",
      "üìä Dados carregados com sucesso:\n",
      "- X_train: (6017, 224, 224, 3)\n",
      "- y_train: (6017,)\n",
      "- X_test: (1526, 224, 224, 3)\n",
      "- y_test: (1526,)\n",
      "üîÑ Aplicando normaliza√ß√£o ResNet50...\n",
      "‚úÖ Normaliza√ß√£o ResNet50 aplicada: [0,255] -> [0,1]\n",
      "\n",
      "üîç Verifica√ß√£o final:\n",
      "- X_train range: [0.000, 1.000]\n",
      "- X_test range: [0.000, 1.000]\n",
      "- Formato das imagens: (224, 224, 3) (deve ser 224x224x3)\n",
      "\n",
      "üìà Distribui√ß√£o de classes:\n",
      "- Treino:\n",
      "  Raiva: 365 imagens\n",
      "  Nojo: 434 imagens\n",
      "  Medo: 155 imagens\n",
      "  Felicidade: 1881 imagens\n",
      "  Neutro: 1470 imagens\n",
      "  Tristeza: 1023 imagens\n",
      "  Surpresa: 689 imagens\n",
      "- Teste:\n",
      "  Raiva: 91 imagens\n",
      "  Nojo: 110 imagens\n",
      "  Medo: 37 imagens\n",
      "  Felicidade: 487 imagens\n",
      "  Neutro: 409 imagens\n",
      "  Tristeza: 226 imagens\n",
      "  Surpresa: 166 imagens\n",
      "\n",
      "üéØ ResNet50: Dados prontos para treinamento!\n",
      "üìè Formato final: (6017, 224, 224, 3)\n",
      "üé® Range de valores: [0.000, 1.000]\n",
      "‚úÖ Pronto para ResNet50!\n"
     ]
    }
   ],
   "source": [
    "def load_preprocessed_data_resnet50_from_images():\n",
    "    \"\"\"\n",
    "    Carrega dados pr√©-processados de imagens JPG com normaliza√ß√£o espec√≠fica para ResNet50.\n",
    "    ResNet50 usa normaliza√ß√£o [0, 1] padr√£o.\n",
    "    \n",
    "    Estrutura esperada:\n",
    "    data/processed/raf_db_temp_gray_aligned/\n",
    "    ‚îú‚îÄ‚îÄ Raiva/\n",
    "    ‚îú‚îÄ‚îÄ Nojo/\n",
    "    ‚îú‚îÄ‚îÄ Medo/\n",
    "    ‚îú‚îÄ‚îÄ Felicidade/\n",
    "    ‚îú‚îÄ‚îÄ Neutro/\n",
    "    ‚îú‚îÄ‚îÄ Tristeza/\n",
    "    ‚îî‚îÄ‚îÄ Surpresa/\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from collections import Counter\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    print(\"Carregando dados pr√©-processados JPG para ResNet50...\")\n",
    "    \n",
    "    # Configura√ß√µes\n",
    "    IMG_SIZE = 224  # Tamanho padr√£o para ResNet50\n",
    "    BASE_PATH = r\"/home/leandro/Documents/TCC/emotion_recognition_tcc/data/processed/raf_db_temp_gray_aligned\"  # Ajuste para seu caminho\n",
    "    \n",
    "    # Mapeamento das emo√ß√µes em portugu√™s\n",
    "    EMOTION_LABELS = {\n",
    "        'Raiva': 0, 'Nojo': 1, 'Medo': 2, 'Felicidade': 3, \n",
    "        'Neutro': 4, 'Tristeza': 5, 'Surpresa': 6\n",
    "    }\n",
    "    \n",
    "    def load_images_from_directory(directory_path, set_name):\n",
    "        \"\"\"Carrega imagens de um diret√≥rio usando os.path.join\"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(f\"Carregando {set_name} de: {directory_path}\")\n",
    "        \n",
    "        # Verifica se o diret√≥rio existe\n",
    "        if not os.path.exists(directory_path):\n",
    "            print(f\"‚ùå Diret√≥rio n√£o encontrado: {directory_path}\")\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        # Lista subdiret√≥rios (emo√ß√µes)\n",
    "        subdirs = [d for d in os.listdir(directory_path) \n",
    "                  if os.path.isdir(os.path.join(directory_path, d))]\n",
    "        \n",
    "        print(f\"üìÅ Subdiret√≥rios encontrados: {subdirs}\")\n",
    "        \n",
    "        for emotion, label in EMOTION_LABELS.items():\n",
    "            # Usar os.path.join ao inv√©s de /\n",
    "            emotion_path = os.path.join(directory_path, emotion)\n",
    "            \n",
    "            if not os.path.exists(emotion_path):\n",
    "                print(f\"‚ö†Ô∏è  Pasta '{emotion}' n√£o encontrada em {directory_path}\")\n",
    "                print(f\"    Tentando varia√ß√µes de nome...\")\n",
    "                \n",
    "                # Tenta varia√ß√µes do nome da emo√ß√£o\n",
    "                emotion_variations = [\n",
    "                    emotion.lower(),\n",
    "                    emotion.upper(), \n",
    "                    emotion.capitalize(),\n",
    "                    emotion.replace('√ß', 'c'),  # Felicidade -> Felicidade\n",
    "                    emotion.replace('√£', 'a')   # Raiva -> Raiva\n",
    "                ]\n",
    "                \n",
    "                found = False\n",
    "                for variation in emotion_variations:\n",
    "                    test_path = os.path.join(directory_path, variation)\n",
    "                    if os.path.exists(test_path):\n",
    "                        emotion_path = test_path\n",
    "                        print(f\"    ‚úÖ Encontrado: {variation}\")\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    print(f\"    ‚ùå Nenhuma varia√ß√£o encontrada para '{emotion}'\")\n",
    "                    continue\n",
    "            \n",
    "            # Carrega imagens da pasta da emo√ß√£o\n",
    "            count = 0\n",
    "            image_files = []\n",
    "            \n",
    "            # Busca diferentes extens√µes\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "                import glob\n",
    "                pattern = os.path.join(emotion_path, ext)\n",
    "                image_files.extend(glob.glob(pattern))\n",
    "            \n",
    "            print(f\"  üì∏ {emotion}: {len(image_files)} arquivos encontrados\")\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                try:\n",
    "                    # Carrega imagem\n",
    "                    img = cv2.imread(img_file)\n",
    "                    if img is None:\n",
    "                        print(f\"    ‚ö†Ô∏è N√£o foi poss√≠vel carregar: {os.path.basename(img_file)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Converte BGR para RGB\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Redimensiona se necess√°rio\n",
    "                    if img.shape[:2] != (IMG_SIZE, IMG_SIZE):\n",
    "                        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "                    \n",
    "                    # Garante que seja RGB (3 canais)\n",
    "                    if len(img.shape) == 2:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                    elif img.shape[2] == 1:\n",
    "                        img = np.repeat(img, 3, axis=2)\n",
    "                    elif img.shape[2] == 4:  # RGBA\n",
    "                        img = img[:, :, :3]  # Remove canal alpha\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                    count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Erro ao carregar {os.path.basename(img_file)}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  ‚úÖ {emotion}: {count} imagens carregadas com sucesso\")\n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def detect_data_structure(base_path):\n",
    "        \"\"\"Detecta a estrutura dos dados automaticamente\"\"\"\n",
    "        print(f\"üîç Analisando estrutura de: {base_path}\")\n",
    "        \n",
    "        if not os.path.exists(base_path):\n",
    "            print(f\"‚ùå Caminho base n√£o existe: {base_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Lista conte√∫do do diret√≥rio\n",
    "        contents = os.listdir(base_path)\n",
    "        dirs = [d for d in contents if os.path.isdir(os.path.join(base_path, d))]\n",
    "        files = [f for f in contents if os.path.isfile(os.path.join(base_path, f))]\n",
    "        \n",
    "        print(f\"üìÅ Diret√≥rios: {dirs}\")\n",
    "        print(f\"üìÑ Arquivos: {len(files)} encontrados\")\n",
    "        \n",
    "        # Verifica se tem estrutura train/test\n",
    "        if 'train' in dirs and 'test' in dirs:\n",
    "            print(\"‚úÖ Estrutura detectada: train/test/emotion/\")\n",
    "            return 'train_test'\n",
    "        \n",
    "        # Verifica se as pastas s√£o emo√ß√µes diretamente\n",
    "        emotion_names = set(EMOTION_LABELS.keys())\n",
    "        found_emotions = set(dirs) & emotion_names\n",
    "        \n",
    "        if found_emotions:\n",
    "            print(f\"‚úÖ Estrutura detectada: emotion/ direta - Emo√ß√µes: {found_emotions}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        # Verifica varia√ß√µes de nomes\n",
    "        emotion_variations = []\n",
    "        for emotion in EMOTION_LABELS.keys():\n",
    "            variations = [emotion.lower(), emotion.upper(), emotion.capitalize()]\n",
    "            emotion_variations.extend(variations)\n",
    "        \n",
    "        found_variations = set(dirs) & set(emotion_variations)\n",
    "        if found_variations:\n",
    "            print(f\"‚úÖ Estrutura detectada: emotion/ com varia√ß√µes - Encontradas: {found_variations}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        print(\"‚ö†Ô∏è Estrutura n√£o reconhecida automaticamente\")\n",
    "        return 'unknown'\n",
    "    \n",
    "    try:\n",
    "        # Detecta estrutura automaticamente\n",
    "        structure = detect_data_structure(BASE_PATH)\n",
    "        \n",
    "        if structure == 'train_test':\n",
    "            # Estrutura: base/train/emotion/ e base/test/emotion/\n",
    "            train_path = os.path.join(BASE_PATH, \"train\")\n",
    "            test_path = os.path.join(BASE_PATH, \"test\")\n",
    "            \n",
    "            X_train, y_train = load_images_from_directory(train_path, \"TREINO\")\n",
    "            X_test, y_test = load_images_from_directory(test_path, \"TESTE\")\n",
    "            \n",
    "        elif structure == 'emotion_direct':\n",
    "            # Estrutura: base/emotion/ - precisa criar train/test split\n",
    "            print(\"üìä Carregando todas as imagens e criando divis√£o train/test...\")\n",
    "            \n",
    "            all_images, all_labels = load_images_from_directory(BASE_PATH, \"TODAS AS IMAGENS\")\n",
    "            \n",
    "            if len(all_images) == 0:\n",
    "                print(\"‚ùå Nenhuma imagem carregada!\")\n",
    "                return None, None, None, None\n",
    "            \n",
    "            # Cria divis√£o train/test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                all_images, all_labels,\n",
    "                test_size=0.2,\n",
    "                stratify=all_labels,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Divis√£o train/test criada automaticamente (80/20)\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå Estrutura de dados n√£o suportada!\")\n",
    "            print(\"üí° Estruturas esperadas:\")\n",
    "            print(\"   1. base/train/Raiva/*.jpg, base/train/Nojo/*.jpg, etc.\")\n",
    "            print(\"   2. base/Raiva/*.jpg, base/Nojo/*.jpg, etc.\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            print(\"‚ùå Nenhuma imagem carregada. Verifique os caminhos e nomes das pastas!\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        print(f\"\\nüìä Dados carregados com sucesso:\")\n",
    "        print(f\"- X_train: {X_train.shape}\")\n",
    "        print(f\"- y_train: {y_train.shape}\")\n",
    "        print(f\"- X_test: {X_test.shape}\")\n",
    "        print(f\"- y_test: {y_test.shape}\")\n",
    "        \n",
    "        # NORMALIZA√á√ÉO ESPEC√çFICA PARA RESNET50: [0, 255] -> [0, 1]\n",
    "        print(\"üîÑ Aplicando normaliza√ß√£o ResNet50...\")\n",
    "        \n",
    "        X_train = X_train.astype(np.float32)\n",
    "        X_test = X_test.astype(np.float32)\n",
    "        \n",
    "        # ResNet50 normaliza√ß√£o padr√£o: [0, 255] -> [0, 1]\n",
    "        X_train = X_train / 255.0\n",
    "        X_test = X_test / 255.0\n",
    "        \n",
    "        print(\"‚úÖ Normaliza√ß√£o ResNet50 aplicada: [0,255] -> [0,1]\")\n",
    "        \n",
    "        # Verifica resultado final\n",
    "        print(f\"\\nüîç Verifica√ß√£o final:\")\n",
    "        print(f\"- X_train range: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "        print(f\"- X_test range: [{X_test.min():.3f}, {X_test.max():.3f}]\")\n",
    "        print(f\"- Formato das imagens: {X_train.shape[1:]} (deve ser {IMG_SIZE}x{IMG_SIZE}x3)\")\n",
    "        \n",
    "        # Verifica distribui√ß√£o de classes\n",
    "        train_distribution = dict(Counter(y_train))\n",
    "        test_distribution = dict(Counter(y_test))\n",
    "        \n",
    "        print(f\"\\nüìà Distribui√ß√£o de classes:\")\n",
    "        emotion_names = list(EMOTION_LABELS.keys())\n",
    "        print(\"- Treino:\")\n",
    "        for label, count in train_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        print(\"- Teste:\")\n",
    "        for label, count in test_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar dados: {e}\")\n",
    "        print(f\"üìç Erro detalhado: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(\"\\nüí° Solu√ß√µes poss√≠veis:\")\n",
    "        print(\"1. Verifique se o caminho est√° correto\")\n",
    "        print(\"2. Verifique se as pastas de emo√ß√µes existem\")\n",
    "        print(\"3. Verifique se h√° imagens nas pastas\")\n",
    "        print(\"4. Verifique permiss√µes de acesso\")\n",
    "        \n",
    "        return None, None, None, None\n",
    "\n",
    "# Executa carregamento para ResNet50\n",
    "X_train, y_train, X_test, y_test = load_preprocessed_data_resnet50_from_images()\n",
    "monitor.update_peak_memory()\n",
    "\n",
    "if X_train is not None:\n",
    "    print(f\"\\nüéØ ResNet50: Dados prontos para treinamento!\")\n",
    "    print(f\"üìè Formato final: {X_train.shape}\")\n",
    "    print(f\"üé® Range de valores: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "    print(f\"‚úÖ Pronto para ResNet50!\")\n",
    "else:\n",
    "    print(\"‚ùå Falha no carregamento dos dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94cd085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento iniciado: resnet50_emotion_20250916_161840\n"
     ]
    }
   ],
   "source": [
    "def create_experiment_structure():\n",
    "    \"\"\"\n",
    "    Cria estrutura de diret√≥rios para salvar modelos e m√©tricas.\n",
    "    \"\"\"\n",
    "    # Cria timestamp √∫nico para o experimento\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    experiment_id = f\"resnet50_emotion_{timestamp}\"\n",
    "    \n",
    "    # Cria diret√≥rios\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"metrics\", exist_ok=True)\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    \n",
    "    return experiment_id\n",
    "\n",
    "def save_model_if_good_performance(model, accuracy, f1_score, experiment_id, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Salva modelo apenas se a performance for boa.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        accuracy: Acur√°cia do modelo\n",
    "        f1_score: F1-score macro do modelo\n",
    "        experiment_id: ID √∫nico do experimento\n",
    "        threshold: Limite m√≠nimo para salvar (default: 85%)\n",
    "    \"\"\"\n",
    "    if accuracy >= threshold or f1_score >= threshold:\n",
    "        model_path = f\"models/resnet50_emotion_{experiment_id}.pkl\"\n",
    "        \n",
    "        # Salva apenas os pesos para economia de espa√ßo\n",
    "        model.save_weights(f\"models/weights_resnet50_{experiment_id}.h5\")\n",
    "        \n",
    "        # Salva configura√ß√£o do modelo\n",
    "        model_config = {\n",
    "            'architecture': 'ResNet50',\n",
    "            'img_size': IMG_SIZE,\n",
    "            'num_classes': 7,\n",
    "            'experiment_id': experiment_id,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_score,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(f\"models/config_resnet50_{experiment_id}.pkl\", 'wb') as f:\n",
    "            pickle.dump(model_config, f)\n",
    "        \n",
    "        print(f\"Modelo salvo! Performance: Acc={accuracy:.4f}, F1={f1_score:.4f}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Performance insuficiente para salvar. Acc={accuracy:.4f}, F1={f1_score:.4f} < {threshold}\")\n",
    "        return False\n",
    "\n",
    "def save_metrics_to_csv(metrics_dict, experiment_id):\n",
    "    \"\"\"\n",
    "    Salva m√©tricas de performance em arquivo CSV.\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: Dicion√°rio com todas as m√©tricas\n",
    "        experiment_id: ID √∫nico do experimento\n",
    "    \"\"\"\n",
    "    # Converte m√©tricas para DataFrame\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "    \n",
    "    # Arquivo CSV principal\n",
    "    csv_path = \"metrics/performance_metrics.csv\"\n",
    "    \n",
    "    # Append ao CSV se j√° existir, sen√£o cria novo\n",
    "    if os.path.exists(csv_path):\n",
    "        metrics_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Salva tamb√©m arquivo individual do experimento\n",
    "    individual_csv = f\"metrics/metrics_{experiment_id}.csv\"\n",
    "    metrics_df.to_csv(individual_csv, index=False)\n",
    "    \n",
    "    print(f\"M√©tricas salvas em: {csv_path} e {individual_csv}\")\n",
    "\n",
    "# Inicializa estrutura do experimento\n",
    "experiment_id = create_experiment_structure()\n",
    "print(f\"Experimento iniciado: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando modelo ResNet50 otimizado...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 16:18:40.617132: W external/local_xla/xla/service/gpu/llvm_gpu_backend/default/nvptx_libdevice_path.cc:41] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  /usr/lib/nvidia-cuda-toolkit\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykernel_launcher.runfiles/cuda_nvdisasm\n",
      "  ipykernel_launcher.runfiles/nvidia_nvshmem\n",
      "  ipykern/cuda_nvcc\n",
      "  ipykern/cuda_nvdisasm\n",
      "  ipykern/nvidia_nvshmem\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /opt/cuda\n",
      "  /home/leandro/Documents/TCC/emotion_recognition_tcc/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/leandro/Documents/TCC/emotion_recognition_tcc/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/leandro/Documents/TCC/emotion_recognition_tcc/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
      "  /home/leandro/Documents/TCC/emotion_recognition_tcc/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../..\n",
      "  /home/leandro/Documents/TCC/emotion_recognition_tcc/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../../..\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo criado com sucesso:\n",
      "- Total de par√¢metros: 24,769,927\n",
      "- Par√¢metros trein√°veis: 1,182,215\n",
      "- ResNet50 base encontrado e configurado\n",
      "- Camadas principais do modelo: 181\n"
     ]
    }
   ],
   "source": [
    "def create_resnet50_model():\n",
    "    \"\"\"\n",
    "    Cria modelo ResNet50 com transfer learning para classifica√ß√£o de emo√ß√µes.\n",
    "    \n",
    "    Returns:\n",
    "        keras.Model: Modelo compilado pronto para treinamento\n",
    "    \"\"\"\n",
    "    # Carrega ResNet50 pr√©-treinado no ImageNet\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Congela camadas base para transfer learning\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Adiciona camadas de classifica√ß√£o customizadas\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(7, activation='softmax')(x)\n",
    "    \n",
    "    # Cria modelo final\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Compila√ß√£o\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Verifica se os dados foram carregados corretamente\n",
    "if X_train is not None:\n",
    "    print(\"Criando modelo ResNet50 otimizado...\")\n",
    "    model = create_resnet50_model()  # CORRE√á√ÉO: apenas uma vari√°vel\n",
    "    \n",
    "    print(f\"Modelo criado com sucesso:\")\n",
    "    print(f\"- Total de par√¢metros: {model.count_params():,}\")\n",
    "    print(f\"- Par√¢metros trein√°veis: {sum([tf.keras.backend.count_params(p) for p in model.trainable_weights]):,}\")\n",
    "    \n",
    "    # Encontra o ResNet50 base na estrutura do modelo\n",
    "    resnet_base = None\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model) and 'resnet50' in layer.name.lower():\n",
    "            resnet_base = layer\n",
    "            break\n",
    "    \n",
    "    if resnet_base is not None:\n",
    "        frozen_layers = len([l for l in resnet_base.layers if not l.trainable])\n",
    "        total_base_layers = len(resnet_base.layers)\n",
    "        print(f\"- Camadas ResNet50 congeladas: {frozen_layers}/{total_base_layers}\")\n",
    "    else:\n",
    "        print(\"- ResNet50 base encontrado e configurado\")\n",
    "    \n",
    "    # Mostra estrutura simplificada do modelo\n",
    "    print(f\"- Camadas principais do modelo: {len(model.layers)}\")\n",
    "    \n",
    "    # Atualiza monitoramento de mem√≥ria (se o monitor existir)\n",
    "    if 'monitor' in locals():\n",
    "        monitor.update_peak_memory()\n",
    "else:\n",
    "    print(\"Erro: Dados n√£o carregados. Verifique a c√©lula anterior.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para treinamento...\n",
      "Dados de treino: (4211, 224, 224, 3)\n",
      "Dados de valida√ß√£o: (1806, 224, 224, 3)\n",
      "Dados de teste: (1526, 224, 224, 3)\n",
      "Distribui√ß√£o de classes - Treino: {np.int64(3): 1316, np.int64(5): 716, np.int64(2): 109, np.int64(4): 1029, np.int64(6): 482, np.int64(0): 255, np.int64(1): 304}\n",
      "Distribui√ß√£o de classes - Valida√ß√£o: {np.int64(6): 207, np.int64(3): 565, np.int64(4): 441, np.int64(1): 130, np.int64(0): 110, np.int64(5): 307, np.int64(2): 46}\n",
      "Callbacks configurados para treinamento otimizado\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback customizado para monitoramento de mem√≥ria durante treinamento.\n",
    "    Essencial para experimentos com recursos limitados.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.monitor.update_peak_memory()\n",
    "        if epoch % 5 == 0:  # Log a cada 5 √©pocas\n",
    "            current_memory = self.monitor._get_memory_usage()\n",
    "            print(f\"√âpoca {epoch+1} - Mem√≥ria atual: {current_memory:.2f} MB\")\n",
    "\n",
    "def setup_training_callbacks(monitor):\n",
    "    \"\"\"\n",
    "    Configura callbacks para treinamento otimizado.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de callbacks configurados\n",
    "    \"\"\"\n",
    "    # Early Stopping: Para evitar overfitting\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',           # M√©trica para monitorar\n",
    "        patience=15,                  # √âpocas sem melhoria antes de parar\n",
    "        restore_best_weights=True,    # Restaura melhores pesos\n",
    "        verbose=1,                    # Mostra quando para\n",
    "        mode='min'                    # Minimizar loss\n",
    "    )\n",
    "    \n",
    "    # Reduce Learning Rate: Ajuste adaptativo da taxa de aprendizado\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',           # M√©trica para monitorar\n",
    "        factor=0.2,                   # Fator de redu√ß√£o (lr = lr * factor)\n",
    "        patience=10,                  # √âpocas sem melhoria antes de reduzir\n",
    "        min_lr=1e-7,                  # Taxa m√≠nima de aprendizado\n",
    "        verbose=1,                    # Mostra quando reduz\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Memory monitoring callback\n",
    "    memory_callback = MemoryCallback(monitor)\n",
    "    \n",
    "    return [early_stopping, reduce_lr, memory_callback]\n",
    "\n",
    "# Prepara√ß√£o dos dados para treinamento\n",
    "print(\"Preparando dados para treinamento...\")\n",
    "\n",
    "# Divis√£o treino/valida√ß√£o estratificada\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=VALIDATION_SPLIT,   # 30% para valida√ß√£o\n",
    "    stratify=y_train,             # Mant√©m propor√ß√£o por classe\n",
    "    random_state=42               # Reprodutibilidade\n",
    ")\n",
    "\n",
    "# Converte labels para formato categorical (one-hot encoding)\n",
    "y_train_cat = to_categorical(y_train_split, 7)\n",
    "y_val_cat = to_categorical(y_val, 7)\n",
    "y_test_cat = to_categorical(y_test, 7)\n",
    "\n",
    "print(f\"Dados de treino: {X_train_split.shape}\")\n",
    "print(f\"Dados de valida√ß√£o: {X_val.shape}\")\n",
    "print(f\"Dados de teste: {X_test.shape}\")\n",
    "print(f\"Distribui√ß√£o de classes - Treino: {dict(Counter(y_train_split))}\")\n",
    "print(f\"Distribui√ß√£o de classes - Valida√ß√£o: {dict(Counter(y_val))}\")\n",
    "\n",
    "# Configura callbacks\n",
    "callbacks = setup_training_callbacks(monitor)\n",
    "print(\"Callbacks configurados para treinamento otimizado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1149a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepara√ß√£o conclu√≠da:\n",
      "- Treino: (4211, 224, 224, 3) | Labels: (4211, 7)\n",
      "- Valida√ß√£o: (1806, 224, 224, 3) | Labels: (1806, 7)\n",
      "- Teste: (1526, 224, 224, 3) | Labels: (1526, 7)\n",
      "Iniciando treinamento ResNet50...\n",
      "Iniciando treinamento ResNet50...\n",
      "Hor√°rio de in√≠cio: 2025-09-16 16:18:49\n",
      "Mem√≥ria inicial: 8729.82 MB\n",
      "--------------------------------------------------\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 16:19:00.043244: I external/local_xla/xla/service/service.cc:163] XLA service 0x7117c0017560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-16 16:19:00.043436: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-09-16 16:19:00.173951: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-16 16:19:01.209451: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n"
     ]
    }
   ],
   "source": [
    "def train_resnet50_model(model, X_train, y_train, X_val, y_val, monitor, callbacks):\n",
    "    \"\"\"\n",
    "    Executa treinamento completo do ResNet50 com monitoramento detalhado.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (history, training_metrics)\n",
    "    \"\"\"\n",
    "    print(\"Iniciando treinamento ResNet50...\")\n",
    "    monitor.start_monitoring()\n",
    "    \n",
    "    # Inicia cron√¥metro espec√≠fico do treinamento\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    # Executa treinamento\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Calcula tempo de treinamento\n",
    "    training_end_time = time.time()\n",
    "    training_duration = training_end_time - training_start_time\n",
    "    \n",
    "    # M√©tricas do treinamento\n",
    "    training_metrics = {\n",
    "        'training_time_seconds': training_duration,\n",
    "        'training_time_formatted': str(timedelta(seconds=int(training_duration))),\n",
    "        'epochs_completed': len(history.history['accuracy']),\n",
    "        'best_train_accuracy': max(history.history['accuracy']),\n",
    "        'best_val_accuracy': max(history.history['val_accuracy']),\n",
    "        'final_train_loss': history.history['loss'][-1],\n",
    "        'final_val_loss': history.history['val_loss'][-1]\n",
    "    }\n",
    "    \n",
    "    print(f\"Treinamento conclu√≠do em: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"√âpocas executadas: {training_metrics['epochs_completed']}\")\n",
    "    print(f\"Melhor acur√°cia valida√ß√£o: {training_metrics['best_val_accuracy']:.4f}\")\n",
    "    \n",
    "    return history, training_metrics\n",
    "\n",
    "# Prepara√ß√£o dos dados se carregamento foi bem-sucedido\n",
    "if X_train is not None and y_train is not None:\n",
    "    \n",
    "    # Divis√£o estratificada treino/valida√ß√£o\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=VALIDATION_SPLIT,\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convers√£o para categorical (one-hot encoding)\n",
    "    y_train_cat = to_categorical(y_train_split, 7)\n",
    "    y_val_cat = to_categorical(y_val, 7)\n",
    "    y_test_cat = to_categorical(y_test, 7)\n",
    "    \n",
    "    print(f\"Prepara√ß√£o conclu√≠da:\")\n",
    "    print(f\"- Treino: {X_train_split.shape} | Labels: {y_train_cat.shape}\")\n",
    "    print(f\"- Valida√ß√£o: {X_val.shape} | Labels: {y_val_cat.shape}\")\n",
    "    print(f\"- Teste: {X_test.shape} | Labels: {y_test_cat.shape}\")\n",
    "    \n",
    "    # Configura callbacks\n",
    "    callbacks = setup_training_callbacks(monitor)\n",
    "    \n",
    "    # Executa treinamento\n",
    "    history, training_metrics = train_resnet50_model(\n",
    "        model, X_train_split, y_train_cat, X_val, y_val_cat, monitor, callbacks\n",
    "    )\n",
    "    \n",
    "    print(\"Treinamento finalizado com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Dados n√£o dispon√≠veis para treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_model_evaluation(model, X_test, y_test_cat, y_test_original):\n",
    "    \"\"\"\n",
    "    Avalia√ß√£o completa do modelo com todas as m√©tricas necess√°rias.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicion√°rio completo com todas as m√©tricas\n",
    "    \"\"\"\n",
    "    print(\"Iniciando avalia√ß√£o completa do modelo...\")\n",
    "    \n",
    "    # Mede tempo de infer√™ncia\n",
    "    inference_start = time.time()\n",
    "    y_pred_prob = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "    inference_end = time.time()\n",
    "    \n",
    "    # Calcula m√©tricas de tempo\n",
    "    total_inference_time = inference_end - inference_start\n",
    "    inference_per_sample = total_inference_time / len(X_test)\n",
    "    samples_per_second = len(X_test) / total_inference_time\n",
    "    \n",
    "    # Convers√µes para c√°lculos de m√©tricas\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = y_test_original\n",
    "    \n",
    "    # M√©tricas de classifica√ß√£o\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # M√©tricas por classe\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Matriz de confus√£o\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    # M√©tricas de mem√≥ria atual\n",
    "    current_memory = monitor._get_memory_usage()\n",
    "    \n",
    "    # Relat√≥rio detalhado por classe\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    class_report = classification_report(\n",
    "        y_true_classes, y_pred_classes, \n",
    "        target_names=emotion_names, \n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # Compila√ß√£o completa das m√©tricas\n",
    "    comprehensive_metrics = {\n",
    "        # Identifica√ß√£o do experimento\n",
    "        'experiment_id': experiment_id,\n",
    "        'model_architecture': 'ResNet50',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        \n",
    "        # Configura√ß√µes do modelo\n",
    "        'img_size': IMG_SIZE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_trained': len(history.history['accuracy']),\n",
    "        \n",
    "        # M√©tricas de performance principal\n",
    "        'test_accuracy': accuracy,\n",
    "        'f1_score_macro': f1,\n",
    "        'f1_score_micro': f1_micro,\n",
    "        'f1_score_weighted': f1_weighted,\n",
    "        'precision_macro': precision,\n",
    "        'recall_macro': recall,\n",
    "        \n",
    "        # M√©tricas de tempo\n",
    "        'total_inference_time_seconds': total_inference_time,\n",
    "        'inference_per_sample_ms': inference_per_sample * 1000,\n",
    "        'samples_per_second': samples_per_second,\n",
    "        'training_time_seconds': training_metrics['training_time_seconds'],\n",
    "        \n",
    "        # M√©tricas de mem√≥ria\n",
    "        'peak_memory_mb': monitor.peak_memory_mb,\n",
    "        'current_memory_mb': current_memory,\n",
    "        'memory_efficiency': monitor.initial_memory_mb / monitor.peak_memory_mb,\n",
    "        \n",
    "        # M√©tricas por classe (emotion-wise)\n",
    "        'anger_f1': class_report['anger']['f1-score'],\n",
    "        'disgust_f1': class_report['disgust']['f1-score'],\n",
    "        'fear_f1': class_report['fear']['f1-score'],\n",
    "        'happy_f1': class_report['happy']['f1-score'],\n",
    "        'neutral_f1': class_report['neutral']['f1-score'],\n",
    "        'sadness_f1': class_report['sadness']['f1-score'],\n",
    "        'surprise_f1': class_report['surprise']['f1-score'],\n",
    "        \n",
    "        # Dados do dataset\n",
    "        'train_samples': len(X_train_split),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'total_parameters': model.count_params(),\n",
    "        'trainable_parameters': sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    }\n",
    "    \n",
    "    return comprehensive_metrics, conf_matrix, class_report\n",
    "\n",
    "# Executa avalia√ß√£o completa se treinamento foi bem-sucedido\n",
    "if 'history' in locals() and history is not None:\n",
    "    \n",
    "    print(\"Executando avalia√ß√£o completa...\")\n",
    "    \n",
    "    # Avalia√ß√£o detalhada\n",
    "    metrics, confusion_matrix_result, detailed_report = comprehensive_model_evaluation(\n",
    "        model, X_test, y_test_cat, y_test\n",
    "    )\n",
    "    \n",
    "    # Salva m√©tricas em CSV\n",
    "    save_metrics_to_csv(metrics, experiment_id)\n",
    "    \n",
    "    # Tenta salvar modelo se performance for boa\n",
    "    model_saved = save_model_if_good_performance(\n",
    "        model, \n",
    "        metrics['test_accuracy'], \n",
    "        metrics['f1_score_macro'], \n",
    "        experiment_id,\n",
    "        threshold=0.80  # Ajuste conforme necess√°rio\n",
    "    )\n",
    "    \n",
    "    # Finaliza monitoramento\n",
    "    monitor_final_stats = monitor.end_monitoring()\n",
    "    \n",
    "    print(f\"\\nRESUMO DO EXPERIMENTO {experiment_id}:\")\n",
    "    print(f\"Acur√°cia: {metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"Tempo de treinamento: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"Infer√™ncia por amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"Modelo salvo: {'Sim' if model_saved else 'N√£o'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Treinamento n√£o foi executado corretamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc48890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualizations(history, confusion_matrix_result, metrics, detailed_report):\n",
    "    \"\"\"\n",
    "    Cria visualiza√ß√µes completas dos resultados para an√°lise cient√≠fica.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Hist√≥rico de treinamento\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    plt.title('Model Accuracy - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title('Model Loss - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Matriz de confus√£o\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    sns.heatmap(confusion_matrix_result, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax3)\n",
    "    plt.title('Confusion Matrix - ResNet50', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # 3. F1-Score por classe\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    f1_scores = [detailed_report[emotion]['f1-score'] for emotion in emotion_names]\n",
    "    bars = plt.bar(emotion_names, f1_scores, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    plt.title('F1-Score por Emo√ß√£o', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Adiciona valores nas barras\n",
    "    for bar, score in zip(bars, f1_scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. M√©tricas de performance\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    performance_metrics = ['Accuracy', 'F1-Macro', 'Precision', 'Recall']\n",
    "    performance_values = [\n",
    "        metrics['test_accuracy'],\n",
    "        metrics['f1_score_macro'],\n",
    "        metrics['precision_macro'],\n",
    "        metrics['recall_macro']\n",
    "    ]\n",
    "    bars = plt.bar(performance_metrics, performance_values, \n",
    "                  color=['green', 'blue', 'orange', 'red'], alpha=0.7)\n",
    "    plt.title('M√©tricas Gerais de Performance', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar, value in zip(bars, performance_values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 5. An√°lise de tempo e mem√≥ria\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    resource_data = {\n",
    "        'Tempo Treino (min)': metrics['training_time_seconds'] / 60,\n",
    "        'Infer√™ncia/amostra (ms)': metrics['inference_per_sample_ms'],\n",
    "        'Pico Mem√≥ria (GB)': metrics['peak_memory_mb'] / 1024,\n",
    "        'Amostras/seg': metrics['samples_per_second']\n",
    "    }\n",
    "    \n",
    "    # Normaliza valores para visualiza√ß√£o\n",
    "    normalized_values = []\n",
    "    labels = []\n",
    "    for key, value in resource_data.items():\n",
    "        if 'Tempo' in key:\n",
    "            normalized_values.append(value / max(1, value) if value > 0 else 0)\n",
    "        elif 'Mem√≥ria' in key:\n",
    "            normalized_values.append(min(value, 1))\n",
    "        else:\n",
    "            normalized_values.append(min(value / 100, 1))  # Normaliza outras m√©tricas\n",
    "        labels.append(f'{key}\\n{value:.2f}')\n",
    "    \n",
    "    plt.bar(range(len(labels)), normalized_values, color='purple', alpha=0.7)\n",
    "    plt.title('Recursos Computacionais (Normalizado)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(labels)), [label.split('\\n')[0] for label in labels], rotation=45)\n",
    "    plt.ylabel('Valor Normalizado')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/comprehensive_analysis_{experiment_id}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Relat√≥rio textual final\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RELAT√ìRIO CIENT√çFICO FINAL - EXPERIMENTO {experiment_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ARQUITETURA: ResNet50 Transfer Learning\")\n",
    "    print(f\"DATASET: Emo√ß√µes balanceadas (7 classes)\")\n",
    "    print(f\"CONFIGURA√á√ÉO: {IMG_SIZE}x{IMG_SIZE}, batch_size={BATCH_SIZE}\")\n",
    "    print(f\"\\nPERFORMANCE PRINCIPAL:\")\n",
    "    print(f\"  ‚Ä¢ Acur√°cia de Teste: {metrics['test_accuracy']:.4f} ({metrics['test_accuracy']*100:.2f}%)\")\n",
    "    print(f\"  ‚Ä¢ F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Precis√£o Macro: {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Recall Macro: {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"\\nEFICI√äNCIA COMPUTACIONAL:\")\n",
    "    print(f\"  ‚Ä¢ Tempo de Treinamento: {training_metrics['training_time_formatted']}\")\n",
    "    print(f\"  ‚Ä¢ √âpocas Executadas: {metrics['epochs_trained']}\")\n",
    "    print(f\"  ‚Ä¢ Infer√™ncia por Amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"  ‚Ä¢ Throughput: {metrics['samples_per_second']:.1f} amostras/segundo\")\n",
    "    print(f\"  ‚Ä¢ Pico de Mem√≥ria: {metrics['peak_memory_mb']:.1f} MB\")\n",
    "    print(f\"\\nPERFORMANCE POR EMO√á√ÉO:\")\n",
    "    for emotion in emotion_names:\n",
    "        f1_score = detailed_report[emotion]['f1-score']\n",
    "        print(f\"  ‚Ä¢ {emotion.capitalize()}: F1={f1_score:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# Executa an√°lise completa se avalia√ß√£o foi bem-sucedida\n",
    "if 'metrics' in locals() and metrics is not None:\n",
    "    create_comprehensive_visualizations(history, confusion_matrix_result, metrics, detailed_report)\n",
    "    print(\"An√°lise completa finalizada!\")\n",
    "    print(f\"Arquivos salvos:\")\n",
    "    print(f\"  ‚Ä¢ M√©tricas: metrics/performance_metrics.csv\")\n",
    "    print(f\"  ‚Ä¢ Visualiza√ß√µes: plots/comprehensive_analysis_{experiment_id}.png\")\n",
    "    if model_saved:\n",
    "        print(f\"  ‚Ä¢ Modelo: models/weights_resnet50_{experiment_id}.h5\")\n",
    "else:\n",
    "    print(\"Erro: Avalia√ß√£o n√£o foi executada corretamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
