{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32745c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU configurada para crescimento dinâmico: 1 dispositivos\n",
      "TensorFlow version: 2.20.0\n",
      "GPU disponível: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "EfficientNet configurado para experimentação científica\n"
     ]
    }
   ],
   "source": [
    "# Importações específicas para EfficientNet e experimentação científica\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import psutil\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# Configuração de reprodutibilidade\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configurações de GPU para EfficientNet (mais otimizações)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU configurada para crescimento dinâmico: {len(gpus)} dispositivos\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Erro na configuração GPU: {e}\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponível: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(\"EfficientNet configurado para experimentação científica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89409516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurações EfficientNet definidas:\n",
      "- Arquitetura: EfficientNet-B0\n",
      "- Tamanho da imagem: 224x224\n",
      "- Batch size: 32\n",
      "- Learning rate base: 0.001\n",
      "- Learning rate fine-tuning: 0.0001\n",
      "- Normalização: efficientnet\n",
      "- Classes de emoção: 7\n",
      "- Dados já pré-processados e balanceados\n"
     ]
    }
   ],
   "source": [
    "# Configurações otimizadas para EfficientNet\n",
    "IMG_SIZE = 224  # EfficientNet-B0 usa 224x224 como padrão\n",
    "BATCH_SIZE = 32  # Mantém consistência para comparação\n",
    "EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.3\n",
    "\n",
    "# Configurações específicas do EfficientNet\n",
    "EFFICIENTNET_CONFIG = {\n",
    "    'base_learning_rate': 0.001,      # Taxa inicial mais alta\n",
    "    'fine_tune_learning_rate': 0.0001, # Taxa para fine-tuning\n",
    "    'dropout_rate': 0.5,              # Dropout principal\n",
    "    'fine_tune_layers': 20,           # Últimas camadas para fine-tuning\n",
    "    'normalization': 'efficientnet'   # Normalização específica (-1 a 1)\n",
    "}\n",
    "\n",
    "# Mapeamento das 7 emoções básicas (igual ao ResNet50)\n",
    "EMOTION_LABELS = {\n",
    "    'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, \n",
    "    'neutral': 4, 'sadness': 5, 'surprise': 6\n",
    "}\n",
    "\n",
    "print(\"Configurações EfficientNet definidas:\")\n",
    "print(f\"- Arquitetura: EfficientNet-B0\")\n",
    "print(f\"- Tamanho da imagem: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Learning rate base: {EFFICIENTNET_CONFIG['base_learning_rate']}\")\n",
    "print(f\"- Learning rate fine-tuning: {EFFICIENTNET_CONFIG['fine_tune_learning_rate']}\")\n",
    "print(f\"- Normalização: {EFFICIENTNET_CONFIG['normalization']}\")\n",
    "print(f\"- Classes de emoção: {len(EMOTION_LABELS)}\")\n",
    "print(\"- Dados já pré-processados e balanceados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4571f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor EfficientNet inicializado\n",
      "Recursos de monitoramento: Tempo por fase, Eficiência de memória, Métricas comparativas\n"
     ]
    }
   ],
   "source": [
    "class EfficientNetMonitor:\n",
    "    \"\"\"\n",
    "    Classe especializada para monitorar EfficientNet durante treinamento.\n",
    "    Inclui métricas específicas de eficiência computacional.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.peak_memory_mb = 0\n",
    "        self.initial_memory_mb = 0\n",
    "        self.phase1_time = 0\n",
    "        self.phase2_time = 0\n",
    "        self.process = psutil.Process()\n",
    "        self.training_phases = {'phase1': None, 'phase2': None}\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Inicia o monitoramento com foco em eficiência do EfficientNet\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.initial_memory_mb = self._get_memory_usage()\n",
    "        self.peak_memory_mb = self.initial_memory_mb\n",
    "        print(f\"Iniciando treinamento EfficientNet-B0...\")\n",
    "        print(f\"Horário de início: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Memória inicial: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(f\"Objetivo: Máxima eficiência computacional\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    def start_phase(self, phase_name):\n",
    "        \"\"\"Inicia uma fase específica do treinamento\"\"\"\n",
    "        self.training_phases[phase_name] = time.time()\n",
    "        print(f\"Iniciando {phase_name} - EfficientNet\")\n",
    "        \n",
    "    def end_phase(self, phase_name):\n",
    "        \"\"\"Finaliza uma fase específica do treinamento\"\"\"\n",
    "        if self.training_phases[phase_name] is not None:\n",
    "            phase_duration = time.time() - self.training_phases[phase_name]\n",
    "            if phase_name == 'phase1':\n",
    "                self.phase1_time = phase_duration\n",
    "            elif phase_name == 'phase2':\n",
    "                self.phase2_time = phase_duration\n",
    "            print(f\"{phase_name} concluída em: {timedelta(seconds=int(phase_duration))}\")\n",
    "            return phase_duration\n",
    "        return 0\n",
    "        \n",
    "    def _get_memory_usage(self):\n",
    "        \"\"\"Retorna uso atual de memória em MB\"\"\"\n",
    "        return self.process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "    def update_peak_memory(self):\n",
    "        \"\"\"Atualiza o pico de memória se necessário\"\"\"\n",
    "        current_memory = self._get_memory_usage()\n",
    "        if current_memory > self.peak_memory_mb:\n",
    "            self.peak_memory_mb = current_memory\n",
    "            \n",
    "    def get_efficiency_metrics(self):\n",
    "        \"\"\"Calcula métricas de eficiência específicas do EfficientNet\"\"\"\n",
    "        current_memory = self._get_memory_usage()\n",
    "        total_time = self.phase1_time + self.phase2_time\n",
    "        \n",
    "        return {\n",
    "            'memory_efficiency': self.initial_memory_mb / self.peak_memory_mb if self.peak_memory_mb > 0 else 0,\n",
    "            'time_efficiency': total_time / 3600,  # Horas\n",
    "            'peak_memory_gb': self.peak_memory_mb / 1024,\n",
    "            'memory_growth_factor': self.peak_memory_mb / self.initial_memory_mb if self.initial_memory_mb > 0 else 1,\n",
    "            'phase1_ratio': self.phase1_time / total_time if total_time > 0 else 0,\n",
    "            'phase2_ratio': self.phase2_time / total_time if total_time > 0 else 0\n",
    "        }\n",
    "        \n",
    "    def end_monitoring(self):\n",
    "        \"\"\"Finaliza o monitoramento e exibe estatísticas detalhadas\"\"\"\n",
    "        self.end_time = time.time()\n",
    "        \n",
    "        # Calcula tempo total\n",
    "        total_time_seconds = self.end_time - self.start_time\n",
    "        total_time_formatted = str(timedelta(seconds=int(total_time_seconds)))\n",
    "        \n",
    "        # Memória final\n",
    "        final_memory_mb = self._get_memory_usage()\n",
    "        memory_increase = final_memory_mb - self.initial_memory_mb\n",
    "        \n",
    "        # Métricas de eficiência\n",
    "        efficiency_metrics = self.get_efficiency_metrics()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"RELATÓRIO DE MONITORAMENTO - EFFICIENTNET-B0\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Tempo total de treinamento: {total_time_formatted}\")\n",
    "        print(f\"  • Fase 1 (Base layers): {timedelta(seconds=int(self.phase1_time))}\")\n",
    "        print(f\"  • Fase 2 (Fine-tuning): {timedelta(seconds=int(self.phase2_time))}\")\n",
    "        print(f\"Memória inicial: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(f\"Memória final: {final_memory_mb:.2f} MB\")\n",
    "        print(f\"Pico de memória: {self.peak_memory_mb:.2f} MB\")\n",
    "        print(f\"Eficiência de memória: {efficiency_metrics['memory_efficiency']:.3f}\")\n",
    "        print(f\"Fator de crescimento: {efficiency_metrics['memory_growth_factor']:.2f}x\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return {\n",
    "            'total_time_seconds': total_time_seconds,\n",
    "            'total_time_formatted': total_time_formatted,\n",
    "            'initial_memory_mb': self.initial_memory_mb,\n",
    "            'final_memory_mb': final_memory_mb,\n",
    "            'peak_memory_mb': self.peak_memory_mb,\n",
    "            'memory_increase_mb': memory_increase,\n",
    "            'phase1_time': self.phase1_time,\n",
    "            'phase2_time': self.phase2_time,\n",
    "            'efficiency_metrics': efficiency_metrics\n",
    "        }\n",
    "\n",
    "# Instancia o monitor específico para EfficientNet\n",
    "monitor = EfficientNetMonitor()\n",
    "print(\"Monitor EfficientNet inicializado\")\n",
    "print(\"Recursos de monitoramento: Tempo por fase, Eficiência de memória, Métricas comparativas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eb46c7",
   "metadata": {},
   "source": [
    "# MUDAR AQUI TBM DEPOIS QUE A LU MANDAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4600ef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados pré-processados JPG para EfficientNet...\n",
      "🔍 Analisando estrutura de: ../data/augmented/raf_db_balanced\n",
      "📁 Diretórios: ['test', 'train']\n",
      "📄 Arquivos: 0 encontrados\n",
      "✅ Estrutura detectada: train/test/emotion/\n",
      "Carregando TREINO de: ../data/augmented/raf_db_balanced/train\n",
      "📁 Subdiretórios encontrados: ['Tristeza', 'Raiva', 'Neutro', 'Surpresa', 'Felicidade', 'Medo', 'Nojo']\n",
      "  📸 Raiva: 1000 arquivos encontrados\n",
      "  ✅ Raiva: 1000 imagens carregadas com sucesso\n",
      "  📸 Nojo: 1000 arquivos encontrados\n",
      "  ✅ Nojo: 1000 imagens carregadas com sucesso\n",
      "  📸 Medo: 1000 arquivos encontrados\n",
      "  ✅ Medo: 1000 imagens carregadas com sucesso\n",
      "  📸 Felicidade: 1000 arquivos encontrados\n",
      "  ✅ Felicidade: 1000 imagens carregadas com sucesso\n",
      "  📸 Neutro: 1000 arquivos encontrados\n",
      "  ✅ Neutro: 1000 imagens carregadas com sucesso\n",
      "  📸 Tristeza: 1000 arquivos encontrados\n",
      "  ✅ Tristeza: 1000 imagens carregadas com sucesso\n",
      "  📸 Surpresa: 1000 arquivos encontrados\n",
      "  ✅ Surpresa: 1000 imagens carregadas com sucesso\n",
      "Carregando TESTE de: ../data/augmented/raf_db_balanced/test\n",
      "📁 Subdiretórios encontrados: ['Tristeza', 'Raiva', 'Neutro', 'Surpresa', 'Felicidade', 'Medo', 'Nojo']\n",
      "  📸 Raiva: 91 arquivos encontrados\n",
      "  ✅ Raiva: 91 imagens carregadas com sucesso\n",
      "  📸 Nojo: 110 arquivos encontrados\n",
      "  ✅ Nojo: 110 imagens carregadas com sucesso\n",
      "  📸 Medo: 37 arquivos encontrados\n",
      "  ✅ Medo: 37 imagens carregadas com sucesso\n",
      "  📸 Felicidade: 487 arquivos encontrados\n",
      "  ✅ Felicidade: 487 imagens carregadas com sucesso\n",
      "  📸 Neutro: 409 arquivos encontrados\n",
      "  ✅ Neutro: 409 imagens carregadas com sucesso\n",
      "  📸 Tristeza: 226 arquivos encontrados\n",
      "  ✅ Tristeza: 226 imagens carregadas com sucesso\n",
      "  📸 Surpresa: 166 arquivos encontrados\n",
      "  ✅ Surpresa: 166 imagens carregadas com sucesso\n",
      "\n",
      "📊 Dados carregados com sucesso:\n",
      "- X_train: (7000, 224, 224, 3)\n",
      "- y_train: (7000,)\n",
      "- X_test: (1526, 224, 224, 3)\n",
      "- y_test: (1526,)\n",
      "🔄 Aplicando normalização EfficientNet...\n",
      "✅ Normalização EfficientNet aplicada: [0,255] -> [-1,1]\n",
      "\n",
      "🔍 Verificação final:\n",
      "- X_train range: [-1.000, 1.000]\n",
      "- X_test range: [-1.000, 1.000]\n",
      "- Formato das imagens: (224, 224, 3) (deve ser 224x224x3)\n",
      "\n",
      "📈 Distribuição de classes:\n",
      "- Treino:\n",
      "  Raiva: 1000 imagens\n",
      "  Nojo: 1000 imagens\n",
      "  Medo: 1000 imagens\n",
      "  Felicidade: 1000 imagens\n",
      "  Neutro: 1000 imagens\n",
      "  Tristeza: 1000 imagens\n",
      "  Surpresa: 1000 imagens\n",
      "- Teste:\n",
      "  Raiva: 91 imagens\n",
      "  Nojo: 110 imagens\n",
      "  Medo: 37 imagens\n",
      "  Felicidade: 487 imagens\n",
      "  Neutro: 409 imagens\n",
      "  Tristeza: 226 imagens\n",
      "  Surpresa: 166 imagens\n",
      "\n",
      "🎯 EfficientNet: Dados prontos para treinamento!\n",
      "📏 Formato final: (7000, 224, 224, 3)\n",
      "🎨 Range de valores: [-1.000, 1.000]\n",
      "✅ Pronto para EfficientNet-B0!\n"
     ]
    }
   ],
   "source": [
    "def load_preprocessed_data_efficientnet_from_images():\n",
    "    \"\"\"\n",
    "    Carrega dados pré-processados de imagens JPG com normalização específica para EfficientNet.\n",
    "    VERSÃO CORRIGIDA para caminhos Windows e emoções em português.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from collections import Counter\n",
    "    \n",
    "    print(\"Carregando dados pré-processados JPG para EfficientNet...\")\n",
    "    \n",
    "    # Configurações\n",
    "    IMG_SIZE = 224  # Tamanho para EfficientNet\n",
    "    BASE_PATH = r\"../data/augmented/raf_db_balanced\"  # Seu caminho\n",
    "    \n",
    "    # CORRIGIDO: Mapeamento das emoções em português\n",
    "    EMOTION_LABELS = {\n",
    "        'Raiva': 0, 'Nojo': 1, 'Medo': 2, 'Felicidade': 3, \n",
    "        'Neutro': 4, 'Tristeza': 5, 'Surpresa': 6\n",
    "    }\n",
    "    \n",
    "    def load_images_from_directory(directory_path, set_name):\n",
    "        \"\"\"Carrega imagens de um diretório usando os.path.join ao invés de /\"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(f\"Carregando {set_name} de: {directory_path}\")\n",
    "        \n",
    "        # Verifica se o diretório existe\n",
    "        if not os.path.exists(directory_path):\n",
    "            print(f\"❌ Diretório não encontrado: {directory_path}\")\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        # Lista subdiretórios (emoções)\n",
    "        subdirs = [d for d in os.listdir(directory_path) \n",
    "                  if os.path.isdir(os.path.join(directory_path, d))]\n",
    "        \n",
    "        print(f\"📁 Subdiretórios encontrados: {subdirs}\")\n",
    "        \n",
    "        for emotion, label in EMOTION_LABELS.items():\n",
    "            # CORRIGIDO: Usar os.path.join ao invés de /\n",
    "            emotion_path = os.path.join(directory_path, emotion)\n",
    "            \n",
    "            if not os.path.exists(emotion_path):\n",
    "                print(f\"⚠️  Pasta '{emotion}' não encontrada em {directory_path}\")\n",
    "                print(f\"    Tentando variações de nome...\")\n",
    "                \n",
    "                # Tenta variações do nome da emoção\n",
    "                emotion_variations = [\n",
    "                    emotion.lower(),\n",
    "                    emotion.upper(), \n",
    "                    emotion.capitalize(),\n",
    "                    emotion.replace('ç', 'c'),  # Felicidade -> Felicidade\n",
    "                    emotion.replace('ã', 'a')   # Raiva -> Raiva\n",
    "                ]\n",
    "                \n",
    "                found = False\n",
    "                for variation in emotion_variations:\n",
    "                    test_path = os.path.join(directory_path, variation)\n",
    "                    if os.path.exists(test_path):\n",
    "                        emotion_path = test_path\n",
    "                        print(f\"    ✅ Encontrado: {variation}\")\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    print(f\"    ❌ Nenhuma variação encontrada para '{emotion}'\")\n",
    "                    continue\n",
    "            \n",
    "            # Carrega imagens da pasta da emoção\n",
    "            count = 0\n",
    "            image_files = []\n",
    "            \n",
    "            # Busca diferentes extensões\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "                import glob\n",
    "                pattern = os.path.join(emotion_path, ext)\n",
    "                image_files.extend(glob.glob(pattern))\n",
    "            \n",
    "            print(f\"  📸 {emotion}: {len(image_files)} arquivos encontrados\")\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                try:\n",
    "                    # Carrega imagem\n",
    "                    img = cv2.imread(img_file)\n",
    "                    if img is None:\n",
    "                        print(f\"    ⚠️ Não foi possível carregar: {os.path.basename(img_file)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Converte BGR para RGB\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Redimensiona se necessário\n",
    "                    if img.shape[:2] != (IMG_SIZE, IMG_SIZE):\n",
    "                        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "                    \n",
    "                    # Garante que seja RGB (3 canais)\n",
    "                    if len(img.shape) == 2:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                    elif img.shape[2] == 1:\n",
    "                        img = np.repeat(img, 3, axis=2)\n",
    "                    elif img.shape[2] == 4:  # RGBA\n",
    "                        img = img[:, :, :3]  # Remove canal alpha\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                    count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ❌ Erro ao carregar {os.path.basename(img_file)}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  ✅ {emotion}: {count} imagens carregadas com sucesso\")\n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def detect_data_structure(base_path):\n",
    "        \"\"\"Detecta a estrutura dos dados automaticamente\"\"\"\n",
    "        print(f\"🔍 Analisando estrutura de: {base_path}\")\n",
    "        \n",
    "        if not os.path.exists(base_path):\n",
    "            print(f\"❌ Caminho base não existe: {base_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Lista conteúdo do diretório\n",
    "        contents = os.listdir(base_path)\n",
    "        dirs = [d for d in contents if os.path.isdir(os.path.join(base_path, d))]\n",
    "        files = [f for f in contents if os.path.isfile(os.path.join(base_path, f))]\n",
    "        \n",
    "        print(f\"📁 Diretórios: {dirs}\")\n",
    "        print(f\"📄 Arquivos: {len(files)} encontrados\")\n",
    "        \n",
    "        # Verifica se tem estrutura train/test\n",
    "        if 'train' in dirs and 'test' in dirs:\n",
    "            print(\"✅ Estrutura detectada: train/test/emotion/\")\n",
    "            return 'train_test'\n",
    "        \n",
    "        # Verifica se as pastas são emoções diretamente\n",
    "        emotion_names = set(EMOTION_LABELS.keys())\n",
    "        found_emotions = set(dirs) & emotion_names\n",
    "        \n",
    "        if found_emotions:\n",
    "            print(f\"✅ Estrutura detectada: emotion/ direta - Emoções: {found_emotions}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        # Verifica variações de nomes\n",
    "        emotion_variations = []\n",
    "        for emotion in EMOTION_LABELS.keys():\n",
    "            variations = [emotion.lower(), emotion.upper(), emotion.capitalize()]\n",
    "            emotion_variations.extend(variations)\n",
    "        \n",
    "        found_variations = set(dirs) & set(emotion_variations)\n",
    "        if found_variations:\n",
    "            print(f\"✅ Estrutura detectada: emotion/ com variações - Encontradas: {found_variations}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        print(\"⚠️ Estrutura não reconhecida automaticamente\")\n",
    "        return 'unknown'\n",
    "    \n",
    "    try:\n",
    "        # Detecta estrutura automaticamente\n",
    "        structure = detect_data_structure(BASE_PATH)\n",
    "        \n",
    "        if structure == 'train_test':\n",
    "            # Estrutura: base/train/emotion/ e base/test/emotion/\n",
    "            train_path = os.path.join(BASE_PATH, \"train\")\n",
    "            test_path = os.path.join(BASE_PATH, \"test\")\n",
    "            \n",
    "            X_train, y_train = load_images_from_directory(train_path, \"TREINO\")\n",
    "            X_test, y_test = load_images_from_directory(test_path, \"TESTE\")\n",
    "            \n",
    "        elif structure == 'emotion_direct':\n",
    "            # Estrutura: base/emotion/ - precisa criar train/test split\n",
    "            print(\"📊 Carregando todas as imagens e criando divisão train/test...\")\n",
    "            \n",
    "            all_images, all_labels = load_images_from_directory(BASE_PATH, \"TODAS AS IMAGENS\")\n",
    "            \n",
    "            if len(all_images) == 0:\n",
    "                print(\"❌ Nenhuma imagem carregada!\")\n",
    "                return None, None, None, None\n",
    "            \n",
    "            # Cria divisão train/test\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                all_images, all_labels,\n",
    "                test_size=0.2,\n",
    "                stratify=all_labels,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            print(\"✅ Divisão train/test criada automaticamente (80/20)\")\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ Estrutura de dados não suportada!\")\n",
    "            print(\"💡 Estruturas esperadas:\")\n",
    "            print(\"   1. base/train/Raiva/*.jpg, base/train/Nojo/*.jpg, etc.\")\n",
    "            print(\"   2. base/Raiva/*.jpg, base/Nojo/*.jpg, etc.\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            print(\"❌ Nenhuma imagem carregada. Verifique os caminhos e nomes das pastas!\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        print(f\"\\n📊 Dados carregados com sucesso:\")\n",
    "        print(f\"- X_train: {X_train.shape}\")\n",
    "        print(f\"- y_train: {y_train.shape}\")\n",
    "        print(f\"- X_test: {X_test.shape}\")\n",
    "        print(f\"- y_test: {y_test.shape}\")\n",
    "        \n",
    "        # NORMALIZAÇÃO ESPECÍFICA PARA EFFICIENTNET: [0, 255] -> [-1, 1]\n",
    "        print(\"🔄 Aplicando normalização EfficientNet...\")\n",
    "        \n",
    "        X_train = X_train.astype(np.float32)\n",
    "        X_test = X_test.astype(np.float32)\n",
    "        \n",
    "        # EfficientNet normalização: [0, 255] -> [-1, 1]\n",
    "        X_train = (X_train / 127.5) - 1.0\n",
    "        X_test = (X_test / 127.5) - 1.0\n",
    "        \n",
    "        print(\"✅ Normalização EfficientNet aplicada: [0,255] -> [-1,1]\")\n",
    "        \n",
    "        # Verifica resultado final\n",
    "        print(f\"\\n🔍 Verificação final:\")\n",
    "        print(f\"- X_train range: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "        print(f\"- X_test range: [{X_test.min():.3f}, {X_test.max():.3f}]\")\n",
    "        print(f\"- Formato das imagens: {X_train.shape[1:]} (deve ser {IMG_SIZE}x{IMG_SIZE}x3)\")\n",
    "        \n",
    "        # Verifica distribuição de classes\n",
    "        train_distribution = dict(Counter(y_train))\n",
    "        test_distribution = dict(Counter(y_test))\n",
    "        \n",
    "        print(f\"\\n📈 Distribuição de classes:\")\n",
    "        emotion_names = list(EMOTION_LABELS.keys())\n",
    "        print(\"- Treino:\")\n",
    "        for label, count in train_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        print(\"- Teste:\")\n",
    "        for label, count in test_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao carregar dados: {e}\")\n",
    "        print(f\"📍 Erro detalhado: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(\"\\n💡 Soluções possíveis:\")\n",
    "        print(\"1. Verifique se o caminho está correto\")\n",
    "        print(\"2. Verifique se as pastas de emoções existem\")\n",
    "        print(\"3. Verifique se há imagens nas pastas\")\n",
    "        print(\"4. Verifique permissões de acesso\")\n",
    "        \n",
    "        return None, None, None, None\n",
    "\n",
    "# Executa carregamento\n",
    "X_train, y_train, X_test, y_test = load_preprocessed_data_efficientnet_from_images()\n",
    "\n",
    "if X_train is not None:\n",
    "    print(f\"\\n🎯 EfficientNet: Dados prontos para treinamento!\")\n",
    "    print(f\"📏 Formato final: {X_train.shape}\")\n",
    "    print(f\"🎨 Range de valores: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "    print(f\"✅ Pronto para EfficientNet-B0!\")\n",
    "else:\n",
    "    print(\"❌ Falha no carregamento dos dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "105c5de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento EfficientNet iniciado: efficientnet_emotion_20250915_202611\n",
      "Estrutura otimizada para comparação de arquiteturas\n"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_experiment_structure():\n",
    "    \"\"\"\n",
    "    Cria estrutura de diretórios específica para experimentos EfficientNet.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    experiment_id = f\"efficientnet_emotion_{timestamp}\"\n",
    "    \n",
    "    # Cria diretórios específicos\n",
    "    os.makedirs(\"models/efficientNetB0\", exist_ok=True)\n",
    "    os.makedirs(\"metrics/efficientNetB0\", exist_ok=True)\n",
    "    os.makedirs(\"plots/efficientNetB0\", exist_ok=True)\n",
    "    \n",
    "    return experiment_id\n",
    "\n",
    "def save_efficientnet_model_if_good_performance(model, base_model, accuracy, f1_score, experiment_id, threshold=0.80):\n",
    "    \"\"\"\n",
    "    Salva modelo EfficientNet apenas se performance for boa.\n",
    "    Inclui estratégia específica de salvamento com base_model para fine-tuning futuro.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo completo treinado\n",
    "        base_model: Base EfficientNet para referência\n",
    "        accuracy: Acurácia do modelo\n",
    "        f1_score: F1-score macro do modelo  \n",
    "        experiment_id: ID único do experimento\n",
    "        threshold: Limite mínimo para salvar\n",
    "    \"\"\"\n",
    "    # Critério mais rigoroso para EfficientNet (esperamos maior eficiência)\n",
    "    performance_score = (accuracy + f1_score) / 2\n",
    "    \n",
    "    if performance_score >= threshold:\n",
    "        \n",
    "        # Salva pesos do modelo completo\n",
    "        model.save_weights(f\"models/efficientnet/weights_efficientnet_{experiment_id}.h5\")\n",
    "        \n",
    "        # Configuração detalhada do modelo EfficientNet\n",
    "        model_config = {\n",
    "            'architecture': 'EfficientNet-B0',\n",
    "            'img_size': IMG_SIZE,\n",
    "            'num_classes': 7,\n",
    "            'experiment_id': experiment_id,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_score,\n",
    "            'performance_score': performance_score,\n",
    "            'normalization_range': '[-1, 1]',\n",
    "            'total_params': model.count_params(),\n",
    "            'trainable_params': sum([tf.keras.backend.count_params(p) for p in model.trainable_weights]),\n",
    "            'base_model_layers': len(base_model.layers),\n",
    "            'efficientnet_config': EFFICIENTNET_CONFIG,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Salva configuração\n",
    "        with open(f\"models/efficientnet/config_efficientnet_{experiment_id}.pkl\", 'wb') as f:\n",
    "            pickle.dump(model_config, f)\n",
    "        \n",
    "        print(f\"EfficientNet salvo! Performance: {performance_score:.4f} (Acc={accuracy:.4f}, F1={f1_score:.4f})\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Performance insuficiente: {performance_score:.4f} < {threshold}\")\n",
    "        return False\n",
    "\n",
    "def save_efficientnet_metrics_to_csv(metrics_dict, experiment_id):\n",
    "    \"\"\"\n",
    "    Salva métricas EfficientNet em CSV separado para análise comparativa.\n",
    "    \"\"\"\n",
    "    # Adiciona identificador de arquitetura\n",
    "    metrics_dict['architecture'] = 'EfficientNet-B0'\n",
    "    \n",
    "    # DataFrame com métricas\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "    \n",
    "    # Arquivo CSV específico para EfficientNet\n",
    "    efficientnet_csv = \"metrics/efficientnet/efficientnet_performance_metrics.csv\"\n",
    "    \n",
    "    # Append ao CSV se existir\n",
    "    if os.path.exists(efficientnet_csv):\n",
    "        metrics_df.to_csv(efficientnet_csv, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(efficientnet_csv, index=False)\n",
    "    \n",
    "    # Arquivo CSV consolidado (todos os modelos)\n",
    "    consolidated_csv = \"metrics/all_models_comparison.csv\"\n",
    "    if os.path.exists(consolidated_csv):\n",
    "        metrics_df.to_csv(consolidated_csv, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(consolidated_csv, index=False)\n",
    "    \n",
    "    # Arquivo individual\n",
    "    individual_csv = f\"metrics/efficientnet/efficientnet_metrics_{experiment_id}.csv\"\n",
    "    metrics_df.to_csv(individual_csv, index=False)\n",
    "    \n",
    "    print(f\"Métricas EfficientNet salvas em:\")\n",
    "    print(f\"  • Específico: {efficientnet_csv}\")\n",
    "    print(f\"  • Consolidado: {consolidated_csv}\")\n",
    "    print(f\"  • Individual: {individual_csv}\")\n",
    "\n",
    "# Inicializa estrutura específica do EfficientNet\n",
    "experiment_id = create_efficientnet_experiment_structure()\n",
    "print(f\"Experimento EfficientNet iniciado: {experiment_id}\")\n",
    "print(\"Estrutura otimizada para comparação de arquiteturas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3832e2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCamadas treináveis: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tune_at\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(base_model.layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Verifica se dados foram carregados antes de criar modelo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX_train\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCriando modelo EfficientNet-B0 otimizado...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m     model, base_model = create_efficientnet_model()\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_model():\n",
    "    \"\"\"\n",
    "    Cria modelo EfficientNet-B0 otimizado para classificação de emoções.\n",
    "    \n",
    "    EfficientNet Architecture:\n",
    "    - Compound scaling (width, depth, resolution)\n",
    "    - Mobile inverted bottleneck convolutions (MBConv)\n",
    "    - Squeeze-and-excitation optimization\n",
    "    - Swish activation functions\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (complete_model, base_model)\n",
    "    \"\"\"\n",
    "    # EfficientNet-B0 pré-treinado no ImageNet\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        #drop_connect_rate=0.2  # Dropout específico do EfficientNet\n",
    "    )\n",
    "    \n",
    "    # Inicial: congela toda a base para feature extraction\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Head customizado para classificação de emoções\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    \n",
    "    # Primeira camada densa - maior que ResNet50 para compensar menor base\n",
    "    x = Dense(1024, activation='relu', name='dense_1024')(x)\n",
    "    x = Dropout(EFFICIENTNET_CONFIG['dropout_rate'], name='dropout_main')(x)\n",
    "    \n",
    "    # Segunda camada densa\n",
    "    x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "    x = Dropout(0.3, name='dropout_secondary')(x)\n",
    "    \n",
    "    # Camada de classificação final\n",
    "    predictions = Dense(7, activation='softmax', name='emotion_predictions')(x)\n",
    "    \n",
    "    # Modelo completo\n",
    "    model = Model(inputs=base_model.input, outputs=predictions, name='EfficientNet_Emotion_Classifier')\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "def compile_efficientnet_phase1(model):\n",
    "    \"\"\"\n",
    "    Compilação para Fase 1: Feature extraction (base congelada).\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=EFFICIENTNET_CONFIG['base_learning_rate']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(\"Fase 1: Modelo compilado para feature extraction\")\n",
    "    \n",
    "def compile_efficientnet_phase2(model, base_model):\n",
    "    \"\"\"\n",
    "    Compilação para Fase 2: Fine-tuning (últimas camadas descongeladas).\n",
    "    \"\"\"\n",
    "    # Descongela últimas camadas para fine-tuning\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Mantém congeladas as primeiras camadas\n",
    "    fine_tune_at = len(base_model.layers) - EFFICIENTNET_CONFIG['fine_tune_layers']\n",
    "    \n",
    "    # Congela camadas iniciais\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Recompila com learning rate menor\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=EFFICIENTNET_CONFIG['fine_tune_learning_rate']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Fase 2: Fine-tuning das últimas {EFFICIENTNET_CONFIG['fine_tune_layers']} camadas\")\n",
    "    print(f\"Camadas treináveis: {fine_tune_at} a {len(base_model.layers)}\")\n",
    "\n",
    "# Verifica se dados foram carregados antes de criar modelo\n",
    "if X_train is not None:\n",
    "    print(\"Criando modelo EfficientNet-B0 otimizado...\")\n",
    "    model, base_model = create_efficientnet_model()\n",
    "    \n",
    "    # Compilação inicial (Fase 1)\n",
    "    compile_efficientnet_phase1(model)\n",
    "    \n",
    "    # Estatísticas do modelo\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    print(f\"EfficientNet-B0 criado com sucesso:\")\n",
    "    print(f\"  • Total de parâmetros: {total_params:,}\")\n",
    "    print(f\"  • Parâmetros treináveis (Fase 1): {trainable_params:,}\")\n",
    "    print(f\"  • Parâmetros congelados: {non_trainable_params:,}\")\n",
    "    print(f\"  • Eficiência: {total_params/1000000:.1f}M parâmetros\")\n",
    "    print(f\"  • Ratio treinável/total: {(trainable_params/total_params)*100:.1f}%\")\n",
    "    \n",
    "    # Sumário do modelo (camadas principais)\n",
    "    print(f\"\\nArquitetura resumida:\")\n",
    "    print(f\"  • Base EfficientNet: {len(base_model.layers)} camadas\")\n",
    "    print(f\"  • GlobalAveragePooling2D\")\n",
    "    print(f\"  • Dense(1024) + Dropout({EFFICIENTNET_CONFIG['dropout_rate']})\")\n",
    "    print(f\"  • Dense(512) + Dropout(0.3)\")\n",
    "    print(f\"  • Dense(7) softmax\")\n",
    "    \n",
    "    monitor.update_peak_memory()\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Dados não carregados. Verifique a célula de carregamento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f644550d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCamadas treináveis: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tune_at\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(base_model.layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Verifica se dados foram carregados antes de criar modelo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX_train\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCriando modelo EfficientNet-B0 otimizado...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m     model, base_model = create_efficientnet_model()\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_model():\n",
    "    \"\"\"\n",
    "    Cria modelo EfficientNet-B0 otimizado para classificação de emoções.\n",
    "    \n",
    "    EfficientNet Architecture:\n",
    "    - Compound scaling (width, depth, resolution)\n",
    "    - Mobile inverted bottleneck convolutions (MBConv)\n",
    "    - Squeeze-and-excitation optimization\n",
    "    - Swish activation functions\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (complete_model, base_model)\n",
    "    \"\"\"\n",
    "    # EfficientNet-B0 pré-treinado no ImageNet\n",
    "    # CORRIGIDO: Removido parâmetro 'drop_connect_rate' inválido\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Inicial: congela toda a base para feature extraction\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Head customizado para classificação de emoções\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    \n",
    "    # Primeira camada densa - maior que ResNet50 para compensar menor base\n",
    "    x = Dense(1024, activation='relu', name='dense_1024')(x)\n",
    "    x = Dropout(EFFICIENTNET_CONFIG['dropout_rate'], name='dropout_main')(x)\n",
    "    \n",
    "    # Segunda camada densa\n",
    "    x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "    x = Dropout(0.3, name='dropout_secondary')(x)\n",
    "    \n",
    "    # Camada de classificação final\n",
    "    predictions = Dense(7, activation='softmax', name='emotion_predictions')(x)\n",
    "    \n",
    "    # Modelo completo\n",
    "    model = Model(inputs=base_model.input, outputs=predictions, name='EfficientNet_Emotion_Classifier')\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "def compile_efficientnet_phase1(model):\n",
    "    \"\"\"\n",
    "    Compilação para Fase 1: Feature extraction (base congelada).\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=EFFICIENTNET_CONFIG['base_learning_rate']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(\"Fase 1: Modelo compilado para feature extraction\")\n",
    "    \n",
    "def compile_efficientnet_phase2(model, base_model):\n",
    "    \"\"\"\n",
    "    Compilação para Fase 2: Fine-tuning (últimas camadas descongeladas).\n",
    "    \"\"\"\n",
    "    # Descongela últimas camadas para fine-tuning\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Mantém congeladas as primeiras camadas\n",
    "    fine_tune_at = len(base_model.layers) - EFFICIENTNET_CONFIG['fine_tune_layers']\n",
    "    \n",
    "    # Congela camadas iniciais\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Recompila com learning rate menor\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=EFFICIENTNET_CONFIG['fine_tune_learning_rate']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Fase 2: Fine-tuning das últimas {EFFICIENTNET_CONFIG['fine_tune_layers']} camadas\")\n",
    "    print(f\"Camadas treináveis: {fine_tune_at} a {len(base_model.layers)}\")\n",
    "\n",
    "# Verifica se dados foram carregados antes de criar modelo\n",
    "if X_train is not None:\n",
    "    print(\"Criando modelo EfficientNet-B0 otimizado...\")\n",
    "    model, base_model = create_efficientnet_model()\n",
    "    \n",
    "    # Compilação inicial (Fase 1)\n",
    "    compile_efficientnet_phase1(model)\n",
    "    \n",
    "    # Estatísticas do modelo\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    print(f\"EfficientNet-B0 criado com sucesso:\")\n",
    "    print(f\"  • Total de parâmetros: {total_params:,}\")\n",
    "    print(f\"  • Parâmetros treináveis (Fase 1): {trainable_params:,}\")\n",
    "    print(f\"  • Parâmetros congelados: {non_trainable_params:,}\")\n",
    "    print(f\"  • Eficiência: {total_params/1000000:.1f}M parâmetros\")\n",
    "    print(f\"  • Ratio treinável/total: {(trainable_params/total_params)*100:.1f}%\")\n",
    "    \n",
    "    # Sumário do modelo (camadas principais)\n",
    "    print(f\"\\nArquitetura resumida:\")\n",
    "    print(f\"  • Base EfficientNet: {len(base_model.layers)} camadas\")\n",
    "    print(f\"  • GlobalAveragePooling2D\")\n",
    "    print(f\"  • Dense(1024) + Dropout({EFFICIENTNET_CONFIG['dropout_rate']})\")\n",
    "    print(f\"  • Dense(512) + Dropout(0.3)\")\n",
    "    print(f\"  • Dense(7) softmax\")\n",
    "    \n",
    "    monitor.update_peak_memory()\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Dados não carregados. Verifique a célula de carregamento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51525d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficientnet_model_with_custom_dropout():\n",
    "    \"\"\"\n",
    "    Versão alternativa com controle manual de dropout.\n",
    "    \"\"\"\n",
    "    # Base model sem parâmetros extras\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Congela inicialmente\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # OPCIONAL: Adiciona dropout customizado às camadas intermediárias\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    \n",
    "    # Dropout adicional para regularização (simula drop_connect)\n",
    "    x = Dropout(0.2, name='feature_dropout')(x)  # Equivalent to drop_connect_rate\n",
    "    \n",
    "    # Camadas de classificação\n",
    "    x = Dense(1024, activation='relu', name='dense_1024')(x)\n",
    "    x = Dropout(EFFICIENTNET_CONFIG['dropout_rate'], name='dropout_main')(x)\n",
    "    \n",
    "    x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "    x = Dropout(0.3, name='dropout_secondary')(x)\n",
    "    \n",
    "    predictions = Dense(7, activation='softmax', name='emotion_predictions')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions, name='EfficientNet_Emotion_Classifier')\n",
    "    \n",
    "    print(\"✅ EfficientNet criado com dropout customizado\")\n",
    "    print(\"💡 Drop connect simulado via Dropout(0.2) após GlobalAveragePooling\")\n",
    "    \n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d54505",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mEfficientNetMemoryCallback\u001b[39;00m(\u001b[43mtf\u001b[49m.keras.callbacks.Callback):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Callback especializado para monitoramento de EfficientNet.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Foca em eficiência de memória e comparação com ResNet50.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, monitor, phase_name):\n",
      "\u001b[31mNameError\u001b[39m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class EfficientNetMemoryCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback especializado para monitoramento de EfficientNet.\n",
    "    Foca em eficiência de memória e comparação com ResNet50.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor, phase_name):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.phase_name = phase_name\n",
    "        self.epoch_times = []\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Calcula tempo da época\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        \n",
    "        # Atualiza memória\n",
    "        self.monitor.update_peak_memory()\n",
    "        \n",
    "        # Log detalhado a cada 5 épocas\n",
    "        if epoch % 5 == 0:\n",
    "            current_memory = self.monitor._get_memory_usage()\n",
    "            avg_epoch_time = np.mean(self.epoch_times[-5:])  # Média das últimas 5 épocas\n",
    "            \n",
    "            print(f\"{self.phase_name} - Época {epoch+1}\")\n",
    "            print(f\"  • Memória atual: {current_memory:.1f} MB\")\n",
    "            print(f\"  • Tempo/época: {avg_epoch_time:.1f}s\")\n",
    "            if logs:\n",
    "                print(f\"  • Val_accuracy: {logs.get('val_accuracy', 0):.4f}\")\n",
    "                print(f\"  • Val_loss: {logs.get('val_loss', 0):.4f}\")\n",
    "\n",
    "def setup_efficientnet_callbacks(monitor, phase_name):\n",
    "    \"\"\"\n",
    "    Configura callbacks otimizados para cada fase do EfficientNet.\n",
    "    \"\"\"\n",
    "    callbacks_list = []\n",
    "    \n",
    "    # Early stopping com paciência diferente por fase\n",
    "    if phase_name == \"Fase1\":\n",
    "        patience = 12  # Menos paciência na fase 1\n",
    "        min_delta = 0.001\n",
    "    else:\n",
    "        patience = 20  # Mais paciência no fine-tuning\n",
    "        min_delta = 0.0005\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',  # Monitora accuracy para EfficientNet\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "        min_delta=min_delta\n",
    "    )\n",
    "    \n",
    "    # Reduce learning rate\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.3,  # Redução mais agressiva para EfficientNet\n",
    "        patience=8,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Memory callback personalizado\n",
    "    memory_callback = EfficientNetMemoryCallback(monitor, phase_name)\n",
    "    \n",
    "    callbacks_list = [early_stopping, reduce_lr, memory_callback]\n",
    "    \n",
    "    return callbacks_list\n",
    "\n",
    "def train_efficientnet_two_phase(model, base_model, X_train, y_train, X_val, y_val, monitor):\n",
    "    \"\"\"\n",
    "    Treinamento EfficientNet em 2 fases otimizadas.\n",
    "    \n",
    "    Fase 1: Feature extraction (base congelada)\n",
    "    Fase 2: Fine-tuning (últimas camadas descongeladas)\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"INICIANDO TREINAMENTO EFFICIENTNET EM 2 FASES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # === FASE 1: FEATURE EXTRACTION ===\n",
    "    print(\"FASE 1: FEATURE EXTRACTION\")\n",
    "    print(\"-\" * 40)\n",
    "    monitor.start_phase('phase1')\n",
    "    \n",
    "    # Callbacks para Fase 1\n",
    "    phase1_callbacks = setup_efficientnet_callbacks(monitor, \"Fase1\")\n",
    "    \n",
    "    # Treinamento Fase 1\n",
    "    history_phase1 = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=30,  # Menos épocas na fase 1\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    phase1_duration = monitor.end_phase('phase1')\n",
    "    best_val_acc_phase1 = max(history_phase1.history['val_accuracy'])\n",
    "    print(f\"Fase 1 - Melhor val_accuracy: {best_val_acc_phase1:.4f}\")\n",
    "    \n",
    "    # === FASE 2: FINE-TUNING ===\n",
    "    print(\"\\nFASE 2: FINE-TUNING\")\n",
    "    print(\"-\" * 40)\n",
    "    monitor.start_phase('phase2')\n",
    "    \n",
    "    # Reconfiguração para fine-tuning\n",
    "    compile_efficientnet_phase2(model, base_model)\n",
    "    \n",
    "    # Callbacks para Fase 2\n",
    "    phase2_callbacks = setup_efficientnet_callbacks(monitor, \"Fase2\")\n",
    "    \n",
    "    # Treinamento Fase 2\n",
    "    history_phase2 = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS - 30,  # Restante das épocas\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    phase2_duration = monitor.end_phase('phase2')\n",
    "    best_val_acc_phase2 = max(history_phase2.history['val_accuracy'])\n",
    "    print(f\"Fase 2 - Melhor val_accuracy: {best_val_acc_phase2:.4f}\")\n",
    "    \n",
    "    # Combina históricos das duas fases\n",
    "    combined_history = {\n",
    "        'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],\n",
    "        'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],\n",
    "        'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n",
    "        'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss'],\n",
    "        'phase1_epochs': len(history_phase1.history['accuracy']),\n",
    "        'phase2_epochs': len(history_phase2.history['accuracy']),\n",
    "        'phase1_duration': phase1_duration,\n",
    "        'phase2_duration': phase2_duration,\n",
    "        'best_val_acc_phase1': best_val_acc_phase1,\n",
    "        'best_val_acc_phase2': best_val_acc_phase2\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTREINAMENTO COMPLETO:\")\n",
    "    print(f\"  • Total de épocas: {combined_history['phase1_epochs'] + combined_history['phase2_epochs']}\")\n",
    "    print(f\"  • Melhor accuracy final: {max(combined_history['val_accuracy']):.4f}\")\n",
    "    print(f\"  • Tempo total: {timedelta(seconds=int(phase1_duration + phase2_duration))}\")\n",
    "    \n",
    "    return combined_history\n",
    "\n",
    "# Executa treinamento se modelo foi criado com sucesso\n",
    "if 'model' in locals() and model is not None:\n",
    "    \n",
    "    # Preparação dos dados\n",
    "    print(\"Preparando dados para treinamento EfficientNet...\")\n",
    "    \n",
    "    # Divisão estratificada treino/validação\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=VALIDATION_SPLIT,\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Conversão para categorical\n",
    "    y_train_cat = to_categorical(y_train_split, 7)\n",
    "    y_val_cat = to_categorical(y_val, 7)\n",
    "    y_test_cat = to_categorical(y_test, 7)\n",
    "    \n",
    "    print(f\"Dados preparados:\")\n",
    "    print(f\"  • Treino: {X_train_split.shape}\")\n",
    "    print(f\"  • Validação: {X_val.shape}\")\n",
    "    print(f\"  • Teste: {X_test.shape}\")\n",
    "    print(f\"  • Range normalização: [{X_train_split.min():.2f}, {X_train_split.max():.2f}]\")\n",
    "    \n",
    "    # Executa treinamento em 2 fases\n",
    "    history = train_efficientnet_two_phase(\n",
    "        model, base_model, X_train_split, y_train_cat, X_val, y_val_cat, monitor\n",
    "    )\n",
    "    \n",
    "    print(\"EfficientNet: Treinamento em 2 fases finalizado com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Modelo EfficientNet não foi criado. Verifique células anteriores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e315b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro: Treinamento EfficientNet não foi executado corretamente\n"
     ]
    }
   ],
   "source": [
    "def comprehensive_efficientnet_evaluation(model, X_test, y_test_cat, y_test_original, history, monitor):\n",
    "    \"\"\"\n",
    "    Avaliação completa do EfficientNet com métricas comparativas.\n",
    "    Foco em eficiência computacional vs ResNet50.\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"AVALIAÇÃO COMPARATIVA EFFICIENTNET-B0\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # === MÉTRICAS DE INFERÊNCIA ===\n",
    "    print(\"Medindo performance de inferência...\")\n",
    "    \n",
    "    # Múltiplas medições para precisão\n",
    "    inference_times = []\n",
    "    for i in range(5):  # 5 medições\n",
    "        start_time = time.time()\n",
    "        y_pred_prob = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "        end_time = time.time()\n",
    "        inference_times.append(end_time - start_time)\n",
    "    \n",
    "    # Estatísticas de inferência\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    std_inference_time = np.std(inference_times)\n",
    "    inference_per_sample = avg_inference_time / len(X_test)\n",
    "    samples_per_second = len(X_test) / avg_inference_time\n",
    "    \n",
    "    # === MÉTRICAS DE CLASSIFICAÇÃO ===\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = y_test_original\n",
    "    \n",
    "    # Métricas principais\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Métricas adicionais\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Matriz de confusão e relatório por classe\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    class_report = classification_report(\n",
    "        y_true_classes, y_pred_classes,\n",
    "        target_names=emotion_names,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # === MÉTRICAS DE EFICIÊNCIA COMPUTACIONAL ===\n",
    "    efficiency_metrics = monitor.get_efficiency_metrics()\n",
    "    current_memory = monitor._get_memory_usage()\n",
    "    \n",
    "    # Parâmetros do modelo\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    \n",
    "    # === COMPILAÇÃO COMPLETA DAS MÉTRICAS ===\n",
    "    comprehensive_metrics = {\n",
    "        # Identificação\n",
    "        'experiment_id': experiment_id,\n",
    "        'model_architecture': 'EfficientNet-B0',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        \n",
    "        # Configuração\n",
    "        'img_size': IMG_SIZE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'normalization_range': '[-1, 1]',\n",
    "        'total_epochs_trained': history['phase1_epochs'] + history['phase2_epochs'],\n",
    "        'phase1_epochs': history['phase1_epochs'],\n",
    "        'phase2_epochs': history['phase2_epochs'],\n",
    "        \n",
    "        # Performance de classificação\n",
    "        'test_accuracy': accuracy,\n",
    "        'f1_score_macro': f1,\n",
    "        'f1_score_micro': f1_micro,\n",
    "        'f1_score_weighted': f1_weighted,\n",
    "        'precision_macro': precision,\n",
    "        'recall_macro': recall,\n",
    "        'performance_score': (accuracy + f1) / 2,\n",
    "        \n",
    "        # Eficiência temporal\n",
    "        'avg_inference_time_seconds': avg_inference_time,\n",
    "        'std_inference_time_seconds': std_inference_time,\n",
    "        'inference_per_sample_ms': inference_per_sample * 1000,\n",
    "        'samples_per_second': samples_per_second,\n",
    "        'phase1_training_time_seconds': history['phase1_duration'],\n",
    "        'phase2_training_time_seconds': history['phase2_duration'],\n",
    "        'total_training_time_seconds': history['phase1_duration'] + history['phase2_duration'],\n",
    "        \n",
    "        # Eficiência de memória\n",
    "        'peak_memory_mb': monitor.peak_memory_mb,\n",
    "        'current_memory_mb': current_memory,\n",
    "        'memory_efficiency': efficiency_metrics['memory_efficiency'],\n",
    "        'memory_growth_factor': efficiency_metrics['memory_growth_factor'],\n",
    "        'peak_memory_gb': efficiency_metrics['peak_memory_gb'],\n",
    "        \n",
    "        # Eficiência de modelo\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params,\n",
    "        'parameters_millions': total_params / 1000000,\n",
    "        'params_per_accuracy': total_params / accuracy if accuracy > 0 else 0,\n",
    "        'efficiency_score': accuracy / (total_params / 1000000),  # Accuracy per million params\n",
    "        \n",
    "        # Métricas por emoção\n",
    "        'anger_f1': class_report['anger']['f1-score'],\n",
    "        'disgust_f1': class_report['disgust']['f1-score'],\n",
    "        'fear_f1': class_report['fear']['f1-score'],\n",
    "        'happy_f1': class_report['happy']['f1-score'],\n",
    "        'neutral_f1': class_report['neutral']['f1-score'],\n",
    "        'sadness_f1': class_report['sadness']['f1-score'],\n",
    "        'surprise_f1': class_report['surprise']['f1-score'],\n",
    "        \n",
    "        # Dados do dataset\n",
    "        'train_samples': len(X_train_split),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        \n",
    "        # Comparação específica EfficientNet\n",
    "        'compound_scaling': 'Yes',\n",
    "        'mobile_inverted_bottleneck': 'Yes',\n",
    "        'squeeze_excitation': 'Yes',\n",
    "        'drop_connect_rate': 0.2\n",
    "    }\n",
    "    \n",
    "    return comprehensive_metrics, conf_matrix, class_report\n",
    "\n",
    "# Executa avaliação se treinamento foi bem-sucedido\n",
    "if 'history' in locals() and history is not None:\n",
    "    \n",
    "    print(\"Executando avaliação completa EfficientNet...\")\n",
    "    \n",
    "    # Avaliação detalhada\n",
    "    metrics, confusion_matrix_result, detailed_report = comprehensive_efficientnet_evaluation(\n",
    "        model, X_test, y_test_cat, y_test, history, monitor\n",
    "    )\n",
    "    \n",
    "    # Salva métricas em CSV\n",
    "    save_efficientnet_metrics_to_csv(metrics, experiment_id)\n",
    "    \n",
    "    # Tenta salvar modelo se performance for boa\n",
    "    model_saved = save_efficientnet_model_if_good_performance(\n",
    "        model, base_model,\n",
    "        metrics['test_accuracy'], \n",
    "        metrics['f1_score_macro'], \n",
    "        experiment_id,\n",
    "        threshold=0.75  # Threshold mais baixo para EfficientNet (mais conservador)\n",
    "    )\n",
    "    \n",
    "    # Finaliza monitoramento\n",
    "    monitor_final_stats = monitor.end_monitoring()\n",
    "    \n",
    "    # === COMPARAÇÃO COM RESNET50 ===\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"COMPARAÇÃO EFFICIENTNET-B0 vs ResNet50\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"EfficientNet-B0:\")\n",
    "    print(f\"  • Parâmetros: {metrics['parameters_millions']:.1f}M\")\n",
    "    print(f\"  • Acurácia: {metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"  • F1-Score: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"  • Inferência/amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"  • Eficiência: {metrics['efficiency_score']:.2f} acc/M_params\")\n",
    "    print(f\"  • Pico memória: {metrics['peak_memory_gb']:.2f} GB\")\n",
    "    print(f\"\")\n",
    "    print(f\"ResNet50 (típico):\")\n",
    "    print(f\"  • Parâmetros: ~25.6M\")\n",
    "    print(f\"  • Eficiência esperada: ~80% dos parâmetros do EfficientNet\")\n",
    "    print(f\"  • Comparação: EfficientNet é {25.6/metrics['parameters_millions']:.1f}x mais eficiente\")\n",
    "    print(f\"\")\n",
    "    print(f\"Modelo salvo: {'Sim' if model_saved else 'Não'}\")\n",
    "    print(f\"Performance Score: {metrics['performance_score']:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Treinamento EfficientNet não foi executado corretamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cac31e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro: Avaliação EfficientNet não foi executada corretamente\n"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_comparative_visualizations(history, confusion_matrix_result, metrics, detailed_report):\n",
    "    \"\"\"\n",
    "    Cria visualizações especializadas para análise de EfficientNet vs ResNet50.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "    \n",
    "    # === 1. HISTÓRICO DE TREINAMENTO EM 2 FASES ===\n",
    "    ax1 = plt.subplot(3, 4, 1)\n",
    "    epochs_phase1 = range(1, history['phase1_epochs'] + 1)\n",
    "    epochs_phase2 = range(history['phase1_epochs'] + 1, \n",
    "                         history['phase1_epochs'] + history['phase2_epochs'] + 1)\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.plot(epochs_phase1, history['accuracy'][:history['phase1_epochs']], \n",
    "             'b-', linewidth=2, label='Fase 1 - Train')\n",
    "    plt.plot(epochs_phase1, history['val_accuracy'][:history['phase1_epochs']], \n",
    "             'b--', linewidth=2, label='Fase 1 - Val')\n",
    "    plt.plot(epochs_phase2, history['accuracy'][history['phase1_epochs']:], \n",
    "             'r-', linewidth=2, label='Fase 2 - Train')\n",
    "    plt.plot(epochs_phase2, history['val_accuracy'][history['phase1_epochs']:], \n",
    "             'r--', linewidth=2, label='Fase 2 - Val')\n",
    "    \n",
    "    plt.axvline(x=history['phase1_epochs'], color='gray', linestyle=':', alpha=0.7)\n",
    "    plt.title('EfficientNet: Accuracy - 2 Fases', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # === 2. LOSS EM 2 FASES ===\n",
    "    ax2 = plt.subplot(3, 4, 2)\n",
    "    plt.plot(epochs_phase1, history['loss'][:history['phase1_epochs']], \n",
    "             'b-', linewidth=2, label='Fase 1 - Train')\n",
    "    plt.plot(epochs_phase1, history['val_loss'][:history['phase1_epochs']], \n",
    "             'b--', linewidth=2, label='Fase 1 - Val')\n",
    "    plt.plot(epochs_phase2, history['loss'][history['phase1_epochs']:], \n",
    "             'r-', linewidth=2, label='Fase 2 - Train')\n",
    "    plt.plot(epochs_phase2, history['val_loss'][history['phase1_epochs']:], \n",
    "             'r--', linewidth=2, label='Fase 2 - Val')\n",
    "    \n",
    "    plt.axvline(x=history['phase1_epochs'], color='gray', linestyle=':', alpha=0.7)\n",
    "    plt.title('EfficientNet: Loss - 2 Fases', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # === 3. MATRIZ DE CONFUSÃO ===\n",
    "    ax3 = plt.subplot(3, 4, 3)\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    sns.heatmap(confusion_matrix_result, annot=True, fmt='d', cmap='Greens',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax3)\n",
    "    plt.title('Matriz de Confusão - EfficientNet', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Classe Real')\n",
    "    plt.xlabel('Classe Predita')\n",
    "    \n",
    "    # === 4. F1-SCORE POR EMOÇÃO ===\n",
    "    ax4 = plt.subplot(3, 4, 4)\n",
    "    f1_scores = [detailed_report[emotion]['f1-score'] for emotion in emotion_names]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(emotion_names)))\n",
    "    bars = plt.bar(emotion_names, f1_scores, color=colors, alpha=0.8, edgecolor='black')\n",
    "    plt.title('F1-Score por Emoção', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar, score in zip(bars, f1_scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{score:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # === 5. COMPARAÇÃO DE EFICIÊNCIA ===\n",
    "    ax5 = plt.subplot(3, 4, 5)\n",
    "    # Dados comparativos (EfficientNet vs ResNet50 típico)\n",
    "    models = ['EfficientNet-B0', 'ResNet50']\n",
    "    parameters = [metrics['parameters_millions'], 25.6]  # ResNet50 típico\n",
    "    accuracy_comparison = [metrics['test_accuracy'], 0.75]  # Estimativa ResNet50\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, parameters, width, label='Parâmetros (M)', alpha=0.8, color='skyblue')\n",
    "    bars2 = plt.bar(x + width/2, [acc * 100 for acc in accuracy_comparison], width, \n",
    "                   label='Accuracy (%)', alpha=0.8, color='lightcoral')\n",
    "    \n",
    "    plt.title('Comparação: Parâmetros vs Accuracy', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Modelo')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.xticks(x, models)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Adiciona valores nas barras\n",
    "    for bar, value in zip(bars1, parameters):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                f'{value:.1f}M', ha='center', va='bottom')\n",
    "    for bar, acc in zip(bars2, accuracy_comparison):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{acc:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # === 6. EFICIÊNCIA TEMPORAL ===\n",
    "    ax6 = plt.subplot(3, 4, 6)\n",
    "    time_metrics = {\n",
    "        'Fase 1 (min)': history['phase1_duration'] / 60,\n",
    "        'Fase 2 (min)': history['phase2_duration'] / 60,\n",
    "        'Inferência (ms)': metrics['inference_per_sample_ms'],\n",
    "        'Throughput': metrics['samples_per_second']\n",
    "    }\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    bars = plt.bar(range(len(time_metrics)), list(time_metrics.values()), \n",
    "                  color=colors, alpha=0.7)\n",
    "    plt.title('Métricas de Tempo', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(range(len(time_metrics)), list(time_metrics.keys()), rotation=45)\n",
    "    plt.ylabel('Valor')\n",
    "    \n",
    "    # === 7. EFICIÊNCIA DE MEMÓRIA ===\n",
    "    ax7 = plt.subplot(3, 4, 7)\n",
    "    memory_data = [\n",
    "        monitor.initial_memory_mb / 1024,  # GB\n",
    "        monitor.peak_memory_mb / 1024,     # GB\n",
    "        metrics['memory_growth_factor']\n",
    "    ]\n",
    "    memory_labels = ['Inicial (GB)', 'Pico (GB)', 'Fator Crescimento']\n",
    "    \n",
    "    bars = plt.bar(memory_labels, memory_data, color=['green', 'orange', 'red'], alpha=0.7)\n",
    "    plt.title('Uso de Memória', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    for bar, value in zip(bars, memory_data):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # === 8. RADAR CHART - PERFORMANCE GERAL ===\n",
    "    ax8 = plt.subplot(3, 4, 8, projection='polar')\n",
    "    \n",
    "    categories = ['Accuracy', 'F1-Score', 'Efficiency\\n(Acc/M_params)', 'Speed\\n(samples/s)', \n",
    "                 'Memory\\nEfficiency']\n",
    "    values = [\n",
    "        metrics['test_accuracy'],\n",
    "        metrics['f1_score_macro'], \n",
    "        min(metrics['efficiency_score'] / 10, 1),  # Normalizado\n",
    "        min(metrics['samples_per_second'] / 1000, 1),  # Normalizado\n",
    "        metrics['memory_efficiency']\n",
    "    ]\n",
    "    \n",
    "    # Fecha o radar\n",
    "    values += values[:1]\n",
    "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax8.plot(angles, values, 'o-', linewidth=2, color='blue', alpha=0.7)\n",
    "    ax8.fill(angles, values, alpha=0.25, color='blue')\n",
    "    ax8.set_xticks(angles[:-1])\n",
    "    ax8.set_xticklabels(categories)\n",
    "    ax8.set_ylim(0, 1)\n",
    "    plt.title('Performance Radar - EfficientNet', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # === 9-12. MÉTRICAS DETALHADAS ===\n",
    "    # Performance por fase\n",
    "    ax9 = plt.subplot(3, 4, 9)\n",
    "    phases = ['Fase 1', 'Fase 2']\n",
    "    phase_performance = [history['best_val_acc_phase1'], history['best_val_acc_phase2']]\n",
    "    bars = plt.bar(phases, phase_performance, color=['lightblue', 'lightgreen'], alpha=0.8)\n",
    "    plt.title('Melhor Accuracy por Fase', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar, acc in zip(bars, phase_performance):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                f'{acc:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Distribuição de classes\n",
    "    ax10 = plt.subplot(3, 4, 10)\n",
    "    test_distribution = [sum(y_test == i) for i in range(7)]\n",
    "    plt.pie(test_distribution, labels=emotion_names, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Distribuição Classes - Teste', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Comparação ResNet vs EfficientNet (simulada)\n",
    "    ax11 = plt.subplot(3, 4, 11)\n",
    "    comparison_metrics = ['Accuracy', 'Parameters (M)', 'Speed (rel)', 'Memory (rel)']\n",
    "    efficientnet_values = [metrics['test_accuracy'], metrics['parameters_millions'], 1.0, 1.0]\n",
    "    resnet_values = [0.75, 25.6, 0.8, 1.2]  # Valores estimados\n",
    "    \n",
    "    x = np.arange(len(comparison_metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, efficientnet_values, width, label='EfficientNet-B0', alpha=0.8)\n",
    "    plt.bar(x + width/2, resnet_values, width, label='ResNet50', alpha=0.8)\n",
    "    \n",
    "    plt.title('EfficientNet vs ResNet50', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Métricas')\n",
    "    plt.xticks(x, comparison_metrics, rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Resumo final\n",
    "    ax12 = plt.subplot(3, 4, 12)\n",
    "    ax12.axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "EfficientNet-B0 RESUMO\n",
    "\n",
    "Accuracy: {metrics['test_accuracy']:.4f}\n",
    "F1-Score: {metrics['f1_score_macro']:.4f}\n",
    "Parâmetros: {metrics['parameters_millions']:.1f}M\n",
    "Eficiência: {metrics['efficiency_score']:.2f}\n",
    "\n",
    "Tempo Treino: {timedelta(seconds=int(metrics['total_training_time_seconds']))}\n",
    "Inferência: {metrics['inference_per_sample_ms']:.1f} ms\n",
    "Memória Pico: {metrics['peak_memory_gb']:.2f} GB\n",
    "\n",
    "Vantagem vs ResNet50:\n",
    "- {25.6/metrics['parameters_millions']:.1f}x menos parâmetros\n",
    "- Convergência em 2 fases\n",
    "- Compound scaling otimizado\n",
    "    \"\"\"\n",
    "    ax12.text(0.1, 0.9, summary_text, fontsize=12, verticalalignment='top', \n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/efficientnet/efficientnet_comprehensive_analysis_{experiment_id}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # === RELATÓRIO CIENTÍFICO FINAL ===\n",
    "    print_efficientnet_scientific_report(metrics, history, monitor_final_stats)\n",
    "\n",
    "def print_efficientnet_scientific_report(metrics, history, monitor_stats):\n",
    "    \"\"\"Relatório científico detalhado do EfficientNet\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RELATÓRIO CIENTÍFICO FINAL - EFFICIENTNET-B0\")\n",
    "    print(f\"Experimento: {experiment_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"ARQUITETURA E CONFIGURAÇÃO:\")\n",
    "    print(f\"  • Modelo: EfficientNet-B0 (Compound Scaling)\")\n",
    "    print(f\"  • Parâmetros: {metrics['parameters_millions']:.1f}M\")\n",
    "    print(f\"  • Entrada: {IMG_SIZE}x{IMG_SIZE}x3, normalização [-1,1]\")\n",
    "    print(f\"  • Treinamento: 2 fases (Feature extraction + Fine-tuning)\")\n",
    "    \n",
    "    print(f\"\\nPERFORMANCE DE CLASSIFICAÇÃO:\")\n",
    "    print(f\"  • Acurácia: {metrics['test_accuracy']:.4f} ({metrics['test_accuracy']*100:.2f}%)\")\n",
    "    print(f\"  • F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"  • Precisão Macro: {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"  • Recall Macro: {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"  • Performance Score: {metrics['performance_score']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nEFICIÊNCIA COMPUTACIONAL:\")\n",
    "    print(f\"  • Eficiência: {metrics['efficiency_score']:.2f} accuracy/M_parameters\")\n",
    "    print(f\"  • Parâmetros/Accuracy: {metrics['params_per_accuracy']:,.0f}\")\n",
    "    print(f\"  • Throughput: {metrics['samples_per_second']:.1f} amostras/segundo\")\n",
    "    print(f\"  • Inferência: {metrics['inference_per_sample_ms']:.2f} ms/amostra\")\n",
    "    \n",
    "    print(f\"\\nTREINAMENTO EM 2 FASES:\")\n",
    "    print(f\"  • Fase 1 (Feature extraction): {history['phase1_epochs']} épocas, {timedelta(seconds=int(history['phase1_duration']))}\")\n",
    "    print(f\"  • Fase 2 (Fine-tuning): {history['phase2_epochs']} épocas, {timedelta(seconds=int(history['phase2_duration']))}\")\n",
    "    print(f\"  • Tempo total: {timedelta(seconds=int(metrics['total_training_time_seconds']))}\")\n",
    "    print(f\"  • Melhor accuracy Fase 1: {history['best_val_acc_phase1']:.4f}\")\n",
    "    print(f\"  • Melhor accuracy Fase 2: {history['best_val_acc_phase2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nUSO DE RECURSOS:\")\n",
    "    print(f\"  • Pico de memória: {metrics['peak_memory_gb']:.2f} GB\")\n",
    "    print(f\"  • Crescimento de memória: {metrics['memory_growth_factor']:.2f}x\")\n",
    "    print(f\"  • Eficiência de memória: {metrics['memory_efficiency']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nCOMPARAÇÃO COM RESNET50:\")\n",
    "    print(f\"  • Parâmetros: {25.6/metrics['parameters_millions']:.1f}x MENOS parâmetros\")\n",
    "    print(f\"  • Compound scaling: Otimização automática width/depth/resolution\")\n",
    "    print(f\"  • Mobile bottlenecks: Convoluções mais eficientes\")\n",
    "    print(f\"  • Squeeze-and-excitation: Atenção por canal\")\n",
    "    \n",
    "    print(f\"\\nRESULTADOS POR EMOÇÃO:\")\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    for emotion in emotion_names:\n",
    "        f1_key = f'{emotion}_f1'\n",
    "        if f1_key in metrics:\n",
    "            print(f\"  • {emotion.capitalize()}: F1 = {metrics[f1_key]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nCONCLUSÃO:\")\n",
    "    efficiency_vs_resnet = 25.6 / metrics['parameters_millions']\n",
    "    print(f\"  • EfficientNet-B0 alcançou {metrics['test_accuracy']*100:.1f}% de acurácia\")\n",
    "    print(f\"  • Com {efficiency_vs_resnet:.1f}x menos parâmetros que ResNet50\")\n",
    "    print(f\"  • Validando compound scaling como arquitetura superior\")\n",
    "    print(f\"  • Ideal para aplicações com restrições computacionais\")\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# Executa análise se avaliação foi bem-sucedida\n",
    "if 'metrics' in locals() and metrics is not None:\n",
    "    create_efficientnet_comparative_visualizations(history, confusion_matrix_result, metrics, detailed_report)\n",
    "    print(\"EfficientNet: Análise comparativa completa finalizada!\")\n",
    "    print(f\"\\nArquivos gerados:\")\n",
    "    print(f\"  • Métricas EfficientNet: metrics/efficientnet/efficientnet_performance_metrics.csv\")\n",
    "    print(f\"  • Comparação consolidada: metrics/all_models_comparison.csv\")\n",
    "    print(f\"  • Visualizações: plots/efficientnet/efficientnet_comprehensive_analysis_{experiment_id}.png\")\n",
    "    if model_saved:\n",
    "        print(f\"  • Modelo: models/efficientnet/weights_efficientnet_{experiment_id}.h5\")\n",
    "else:\n",
    "    print(\"Erro: Avaliação EfficientNet não foi executada corretamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
