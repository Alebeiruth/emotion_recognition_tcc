{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32745c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU configurada para crescimento din√¢mico: 1 dispositivos\n",
      "TensorFlow version: 2.20.0\n",
      "GPU dispon√≠vel: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "EfficientNet configurado para experimenta√ß√£o cient√≠fica\n"
     ]
    }
   ],
   "source": [
    "# Importa√ß√µes espec√≠ficas para EfficientNet e experimenta√ß√£o cient√≠fica\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import psutil\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# Configura√ß√£o de reprodutibilidade\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configura√ß√µes de GPU para EfficientNet (mais otimiza√ß√µes)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU configurada para crescimento din√¢mico: {len(gpus)} dispositivos\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Erro na configura√ß√£o GPU: {e}\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU dispon√≠vel: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(\"EfficientNet configurado para experimenta√ß√£o cient√≠fica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89409516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configura√ß√µes EfficientNet definidas:\n",
      "- Arquitetura: EfficientNet-B0\n",
      "- Tamanho da imagem: 224x224\n",
      "- Batch size: 32\n",
      "- Learning rate base: 0.001\n",
      "- Learning rate fine-tuning: 0.0001\n",
      "- Normaliza√ß√£o: efficientnet\n",
      "- Classes de emo√ß√£o: 7\n",
      "- Dados j√° pr√©-processados e balanceados\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes otimizadas para EfficientNet\n",
    "IMG_SIZE = 224  # EfficientNet-B0 usa 224x224 como padr√£o\n",
    "BATCH_SIZE = 32  # Mant√©m consist√™ncia para compara√ß√£o\n",
    "EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.3\n",
    "\n",
    "# Configura√ß√µes espec√≠ficas do EfficientNet\n",
    "EFFICIENTNET_CONFIG = {\n",
    "    'base_learning_rate': 0.001,      # Taxa inicial mais alta\n",
    "    'fine_tune_learning_rate': 0.0001, # Taxa para fine-tuning\n",
    "    'dropout_rate': 0.5,              # Dropout principal\n",
    "    'fine_tune_layers': 20,           # √öltimas camadas para fine-tuning\n",
    "    'normalization': 'efficientnet'   # Normaliza√ß√£o espec√≠fica (-1 a 1)\n",
    "}\n",
    "\n",
    "# Mapeamento das 7 emo√ß√µes b√°sicas (igual ao ResNet50)\n",
    "EMOTION_LABELS = {\n",
    "    'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, \n",
    "    'neutral': 4, 'sadness': 5, 'surprise': 6\n",
    "}\n",
    "\n",
    "print(\"Configura√ß√µes EfficientNet definidas:\")\n",
    "print(f\"- Arquitetura: EfficientNet-B0\")\n",
    "print(f\"- Tamanho da imagem: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Learning rate base: {EFFICIENTNET_CONFIG['base_learning_rate']}\")\n",
    "print(f\"- Learning rate fine-tuning: {EFFICIENTNET_CONFIG['fine_tune_learning_rate']}\")\n",
    "print(f\"- Normaliza√ß√£o: {EFFICIENTNET_CONFIG['normalization']}\")\n",
    "print(f\"- Classes de emo√ß√£o: {len(EMOTION_LABELS)}\")\n",
    "print(\"- Dados j√° pr√©-processados e balanceados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4571f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor EfficientNet inicializado\n",
      "Recursos de monitoramento: Tempo por fase, Efici√™ncia de mem√≥ria, M√©tricas comparativas\n"
     ]
    }
   ],
   "source": [
    "class EfficientNetMonitor:\n",
    "    \"\"\"\n",
    "    Classe especializada para monitorar EfficientNet durante treinamento.\n",
    "    Inclui m√©tricas espec√≠ficas de efici√™ncia computacional.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.peak_memory_mb = 0\n",
    "        self.initial_memory_mb = 0\n",
    "        self.phase1_time = 0\n",
    "        self.phase2_time = 0\n",
    "        self.process = psutil.Process()\n",
    "        self.training_phases = {'phase1': None, 'phase2': None}\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"Inicia o monitoramento com foco em efici√™ncia do EfficientNet\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.initial_memory_mb = self._get_memory_usage()\n",
    "        self.peak_memory_mb = self.initial_memory_mb\n",
    "        print(f\"Iniciando treinamento EfficientNet-B0...\")\n",
    "        print(f\"Hor√°rio de in√≠cio: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Mem√≥ria inicial: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(f\"Objetivo: M√°xima efici√™ncia computacional\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    def start_phase(self, phase_name):\n",
    "        \"\"\"Inicia uma fase espec√≠fica do treinamento\"\"\"\n",
    "        self.training_phases[phase_name] = time.time()\n",
    "        print(f\"Iniciando {phase_name} - EfficientNet\")\n",
    "        \n",
    "    def end_phase(self, phase_name):\n",
    "        \"\"\"Finaliza uma fase espec√≠fica do treinamento\"\"\"\n",
    "        if self.training_phases[phase_name] is not None:\n",
    "            phase_duration = time.time() - self.training_phases[phase_name]\n",
    "            if phase_name == 'phase1':\n",
    "                self.phase1_time = phase_duration\n",
    "            elif phase_name == 'phase2':\n",
    "                self.phase2_time = phase_duration\n",
    "            print(f\"{phase_name} conclu√≠da em: {timedelta(seconds=int(phase_duration))}\")\n",
    "            return phase_duration\n",
    "        return 0\n",
    "        \n",
    "    def _get_memory_usage(self):\n",
    "        \"\"\"Retorna uso atual de mem√≥ria em MB\"\"\"\n",
    "        return self.process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "    def update_peak_memory(self):\n",
    "        \"\"\"Atualiza o pico de mem√≥ria se necess√°rio\"\"\"\n",
    "        current_memory = self._get_memory_usage()\n",
    "        if current_memory > self.peak_memory_mb:\n",
    "            self.peak_memory_mb = current_memory\n",
    "            \n",
    "    def get_efficiency_metrics(self):\n",
    "        \"\"\"Calcula m√©tricas de efici√™ncia espec√≠ficas do EfficientNet\"\"\"\n",
    "        current_memory = self._get_memory_usage()\n",
    "        total_time = self.phase1_time + self.phase2_time\n",
    "        \n",
    "        return {\n",
    "            'memory_efficiency': self.initial_memory_mb / self.peak_memory_mb if self.peak_memory_mb > 0 else 0,\n",
    "            'time_efficiency': total_time / 3600,  # Horas\n",
    "            'peak_memory_gb': self.peak_memory_mb / 1024,\n",
    "            'memory_growth_factor': self.peak_memory_mb / self.initial_memory_mb if self.initial_memory_mb > 0 else 1,\n",
    "            'phase1_ratio': self.phase1_time / total_time if total_time > 0 else 0,\n",
    "            'phase2_ratio': self.phase2_time / total_time if total_time > 0 else 0\n",
    "        }\n",
    "        \n",
    "    def end_monitoring(self):\n",
    "        \"\"\"Finaliza o monitoramento e exibe estat√≠sticas detalhadas\"\"\"\n",
    "        self.end_time = time.time()\n",
    "        \n",
    "        # Calcula tempo total\n",
    "        total_time_seconds = self.end_time - self.start_time\n",
    "        total_time_formatted = str(timedelta(seconds=int(total_time_seconds)))\n",
    "        \n",
    "        # Mem√≥ria final\n",
    "        final_memory_mb = self._get_memory_usage()\n",
    "        memory_increase = final_memory_mb - self.initial_memory_mb\n",
    "        \n",
    "        # M√©tricas de efici√™ncia\n",
    "        efficiency_metrics = self.get_efficiency_metrics()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"RELAT√ìRIO DE MONITORAMENTO - EFFICIENTNET-B0\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Tempo total de treinamento: {total_time_formatted}\")\n",
    "        print(f\"  ‚Ä¢ Fase 1 (Base layers): {timedelta(seconds=int(self.phase1_time))}\")\n",
    "        print(f\"  ‚Ä¢ Fase 2 (Fine-tuning): {timedelta(seconds=int(self.phase2_time))}\")\n",
    "        print(f\"Mem√≥ria inicial: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(f\"Mem√≥ria final: {final_memory_mb:.2f} MB\")\n",
    "        print(f\"Pico de mem√≥ria: {self.peak_memory_mb:.2f} MB\")\n",
    "        print(f\"Efici√™ncia de mem√≥ria: {efficiency_metrics['memory_efficiency']:.3f}\")\n",
    "        print(f\"Fator de crescimento: {efficiency_metrics['memory_growth_factor']:.2f}x\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return {\n",
    "            'total_time_seconds': total_time_seconds,\n",
    "            'total_time_formatted': total_time_formatted,\n",
    "            'initial_memory_mb': self.initial_memory_mb,\n",
    "            'final_memory_mb': final_memory_mb,\n",
    "            'peak_memory_mb': self.peak_memory_mb,\n",
    "            'memory_increase_mb': memory_increase,\n",
    "            'phase1_time': self.phase1_time,\n",
    "            'phase2_time': self.phase2_time,\n",
    "            'efficiency_metrics': efficiency_metrics\n",
    "        }\n",
    "\n",
    "# Instancia o monitor espec√≠fico para EfficientNet\n",
    "monitor = EfficientNetMonitor()\n",
    "print(\"Monitor EfficientNet inicializado\")\n",
    "print(\"Recursos de monitoramento: Tempo por fase, Efici√™ncia de mem√≥ria, M√©tricas comparativas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eb46c7",
   "metadata": {},
   "source": [
    "# MUDAR AQUI TBM DEPOIS QUE A LU MANDAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4600ef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados pr√©-processados JPG para EfficientNet...\n",
      "üîç Analisando estrutura de: ../data/augmented/raf_db_balanced\n",
      "üìÅ Diret√≥rios: ['test', 'train']\n",
      "üìÑ Arquivos: 0 encontrados\n",
      "‚úÖ Estrutura detectada: train/test/emotion/\n",
      "Carregando TREINO de: ../data/augmented/raf_db_balanced/train\n",
      "üìÅ Subdiret√≥rios encontrados: ['Tristeza', 'Raiva', 'Neutro', 'Surpresa', 'Felicidade', 'Medo', 'Nojo']\n",
      "  üì∏ Raiva: 1000 arquivos encontrados\n",
      "  ‚úÖ Raiva: 1000 imagens carregadas com sucesso\n",
      "  üì∏ Nojo: 1000 arquivos encontrados\n",
      "  ‚úÖ Nojo: 1000 imagens carregadas com sucesso\n",
      "  üì∏ Medo: 1000 arquivos encontrados\n",
      "  ‚úÖ Medo: 1000 imagens carregadas com sucesso\n",
      "  üì∏ Felicidade: 1000 arquivos encontrados\n",
      "  ‚úÖ Felicidade: 1000 imagens carregadas com sucesso\n",
      "  üì∏ Neutro: 1000 arquivos encontrados\n",
      "  ‚úÖ Neutro: 1000 imagens carregadas com sucesso\n",
      "  üì∏ Tristeza: 1000 arquivos encontrados\n",
      "  ‚úÖ Tristeza: 1000 imagens carregadas com sucesso\n",
      "  üì∏ Surpresa: 1000 arquivos encontrados\n",
      "  ‚úÖ Surpresa: 1000 imagens carregadas com sucesso\n",
      "Carregando TESTE de: ../data/augmented/raf_db_balanced/test\n",
      "üìÅ Subdiret√≥rios encontrados: ['Tristeza', 'Raiva', 'Neutro', 'Surpresa', 'Felicidade', 'Medo', 'Nojo']\n",
      "  üì∏ Raiva: 91 arquivos encontrados\n",
      "  ‚úÖ Raiva: 91 imagens carregadas com sucesso\n",
      "  üì∏ Nojo: 110 arquivos encontrados\n",
      "  ‚úÖ Nojo: 110 imagens carregadas com sucesso\n",
      "  üì∏ Medo: 37 arquivos encontrados\n",
      "  ‚úÖ Medo: 37 imagens carregadas com sucesso\n",
      "  üì∏ Felicidade: 487 arquivos encontrados\n",
      "  ‚úÖ Felicidade: 487 imagens carregadas com sucesso\n",
      "  üì∏ Neutro: 409 arquivos encontrados\n",
      "  ‚úÖ Neutro: 409 imagens carregadas com sucesso\n",
      "  üì∏ Tristeza: 226 arquivos encontrados\n",
      "  ‚úÖ Tristeza: 226 imagens carregadas com sucesso\n",
      "  üì∏ Surpresa: 166 arquivos encontrados\n",
      "  ‚úÖ Surpresa: 166 imagens carregadas com sucesso\n",
      "\n",
      "üìä Dados carregados com sucesso:\n",
      "- X_train: (7000, 224, 224, 3)\n",
      "- y_train: (7000,)\n",
      "- X_test: (1526, 224, 224, 3)\n",
      "- y_test: (1526,)\n",
      "üîÑ Aplicando normaliza√ß√£o EfficientNet...\n",
      "‚úÖ Normaliza√ß√£o EfficientNet aplicada: [0,255] -> [-1,1]\n",
      "\n",
      "üîç Verifica√ß√£o final:\n",
      "- X_train range: [-1.000, 1.000]\n",
      "- X_test range: [-1.000, 1.000]\n",
      "- Formato das imagens: (224, 224, 3) (deve ser 224x224x3)\n",
      "\n",
      "üìà Distribui√ß√£o de classes:\n",
      "- Treino:\n",
      "  Raiva: 1000 imagens\n",
      "  Nojo: 1000 imagens\n",
      "  Medo: 1000 imagens\n",
      "  Felicidade: 1000 imagens\n",
      "  Neutro: 1000 imagens\n",
      "  Tristeza: 1000 imagens\n",
      "  Surpresa: 1000 imagens\n",
      "- Teste:\n",
      "  Raiva: 91 imagens\n",
      "  Nojo: 110 imagens\n",
      "  Medo: 37 imagens\n",
      "  Felicidade: 487 imagens\n",
      "  Neutro: 409 imagens\n",
      "  Tristeza: 226 imagens\n",
      "  Surpresa: 166 imagens\n",
      "\n",
      "üéØ EfficientNet: Dados prontos para treinamento!\n",
      "üìè Formato final: (7000, 224, 224, 3)\n",
      "üé® Range de valores: [-1.000, 1.000]\n",
      "‚úÖ Pronto para EfficientNet-B0!\n"
     ]
    }
   ],
   "source": [
    "def load_preprocessed_data_efficientnet_from_images():\n",
    "    \"\"\"\n",
    "    Carrega dados pr√©-processados de imagens JPG com normaliza√ß√£o espec√≠fica para EfficientNet.\n",
    "    VERS√ÉO CORRIGIDA para caminhos Windows e emo√ß√µes em portugu√™s.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from collections import Counter\n",
    "    \n",
    "    print(\"Carregando dados pr√©-processados JPG para EfficientNet...\")\n",
    "    \n",
    "    # Configura√ß√µes\n",
    "    IMG_SIZE = 224  # Tamanho para EfficientNet\n",
    "    BASE_PATH = r\"../data/augmented/raf_db_balanced\"  # Seu caminho\n",
    "    \n",
    "    # CORRIGIDO: Mapeamento das emo√ß√µes em portugu√™s\n",
    "    EMOTION_LABELS = {\n",
    "        'Raiva': 0, 'Nojo': 1, 'Medo': 2, 'Felicidade': 3, \n",
    "        'Neutro': 4, 'Tristeza': 5, 'Surpresa': 6\n",
    "    }\n",
    "    \n",
    "    def load_images_from_directory(directory_path, set_name):\n",
    "        \"\"\"Carrega imagens de um diret√≥rio usando os.path.join ao inv√©s de /\"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(f\"Carregando {set_name} de: {directory_path}\")\n",
    "        \n",
    "        # Verifica se o diret√≥rio existe\n",
    "        if not os.path.exists(directory_path):\n",
    "            print(f\"‚ùå Diret√≥rio n√£o encontrado: {directory_path}\")\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        # Lista subdiret√≥rios (emo√ß√µes)\n",
    "        subdirs = [d for d in os.listdir(directory_path) \n",
    "                  if os.path.isdir(os.path.join(directory_path, d))]\n",
    "        \n",
    "        print(f\"üìÅ Subdiret√≥rios encontrados: {subdirs}\")\n",
    "        \n",
    "        for emotion, label in EMOTION_LABELS.items():\n",
    "            # CORRIGIDO: Usar os.path.join ao inv√©s de /\n",
    "            emotion_path = os.path.join(directory_path, emotion)\n",
    "            \n",
    "            if not os.path.exists(emotion_path):\n",
    "                print(f\"‚ö†Ô∏è  Pasta '{emotion}' n√£o encontrada em {directory_path}\")\n",
    "                print(f\"    Tentando varia√ß√µes de nome...\")\n",
    "                \n",
    "                # Tenta varia√ß√µes do nome da emo√ß√£o\n",
    "                emotion_variations = [\n",
    "                    emotion.lower(),\n",
    "                    emotion.upper(), \n",
    "                    emotion.capitalize(),\n",
    "                    emotion.replace('√ß', 'c'),  # Felicidade -> Felicidade\n",
    "                    emotion.replace('√£', 'a')   # Raiva -> Raiva\n",
    "                ]\n",
    "                \n",
    "                found = False\n",
    "                for variation in emotion_variations:\n",
    "                    test_path = os.path.join(directory_path, variation)\n",
    "                    if os.path.exists(test_path):\n",
    "                        emotion_path = test_path\n",
    "                        print(f\"    ‚úÖ Encontrado: {variation}\")\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    print(f\"    ‚ùå Nenhuma varia√ß√£o encontrada para '{emotion}'\")\n",
    "                    continue\n",
    "            \n",
    "            # Carrega imagens da pasta da emo√ß√£o\n",
    "            count = 0\n",
    "            image_files = []\n",
    "            \n",
    "            # Busca diferentes extens√µes\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "                import glob\n",
    "                pattern = os.path.join(emotion_path, ext)\n",
    "                image_files.extend(glob.glob(pattern))\n",
    "            \n",
    "            print(f\"  üì∏ {emotion}: {len(image_files)} arquivos encontrados\")\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                try:\n",
    "                    # Carrega imagem\n",
    "                    img = cv2.imread(img_file)\n",
    "                    if img is None:\n",
    "                        print(f\"    ‚ö†Ô∏è N√£o foi poss√≠vel carregar: {os.path.basename(img_file)}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Converte BGR para RGB\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Redimensiona se necess√°rio\n",
    "                    if img.shape[:2] != (IMG_SIZE, IMG_SIZE):\n",
    "                        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "                    \n",
    "                    # Garante que seja RGB (3 canais)\n",
    "                    if len(img.shape) == 2:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                    elif img.shape[2] == 1:\n",
    "                        img = np.repeat(img, 3, axis=2)\n",
    "                    elif img.shape[2] == 4:  # RGBA\n",
    "                        img = img[:, :, :3]  # Remove canal alpha\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                    count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Erro ao carregar {os.path.basename(img_file)}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  ‚úÖ {emotion}: {count} imagens carregadas com sucesso\")\n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def detect_data_structure(base_path):\n",
    "        \"\"\"Detecta a estrutura dos dados automaticamente\"\"\"\n",
    "        print(f\"üîç Analisando estrutura de: {base_path}\")\n",
    "        \n",
    "        if not os.path.exists(base_path):\n",
    "            print(f\"‚ùå Caminho base n√£o existe: {base_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Lista conte√∫do do diret√≥rio\n",
    "        contents = os.listdir(base_path)\n",
    "        dirs = [d for d in contents if os.path.isdir(os.path.join(base_path, d))]\n",
    "        files = [f for f in contents if os.path.isfile(os.path.join(base_path, f))]\n",
    "        \n",
    "        print(f\"üìÅ Diret√≥rios: {dirs}\")\n",
    "        print(f\"üìÑ Arquivos: {len(files)} encontrados\")\n",
    "        \n",
    "        # Verifica se tem estrutura train/test\n",
    "        if 'train' in dirs and 'test' in dirs:\n",
    "            print(\"‚úÖ Estrutura detectada: train/test/emotion/\")\n",
    "            return 'train_test'\n",
    "        \n",
    "        # Verifica se as pastas s√£o emo√ß√µes diretamente\n",
    "        emotion_names = set(EMOTION_LABELS.keys())\n",
    "        found_emotions = set(dirs) & emotion_names\n",
    "        \n",
    "        if found_emotions:\n",
    "            print(f\"‚úÖ Estrutura detectada: emotion/ direta - Emo√ß√µes: {found_emotions}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        # Verifica varia√ß√µes de nomes\n",
    "        emotion_variations = []\n",
    "        for emotion in EMOTION_LABELS.keys():\n",
    "            variations = [emotion.lower(), emotion.upper(), emotion.capitalize()]\n",
    "            emotion_variations.extend(variations)\n",
    "        \n",
    "        found_variations = set(dirs) & set(emotion_variations)\n",
    "        if found_variations:\n",
    "            print(f\"‚úÖ Estrutura detectada: emotion/ com varia√ß√µes - Encontradas: {found_variations}\")\n",
    "            return 'emotion_direct'\n",
    "        \n",
    "        print(\"‚ö†Ô∏è Estrutura n√£o reconhecida automaticamente\")\n",
    "        return 'unknown'\n",
    "    \n",
    "    try:\n",
    "        # Detecta estrutura automaticamente\n",
    "        structure = detect_data_structure(BASE_PATH)\n",
    "        \n",
    "        if structure == 'train_test':\n",
    "            # Estrutura: base/train/emotion/ e base/test/emotion/\n",
    "            train_path = os.path.join(BASE_PATH, \"train\")\n",
    "            test_path = os.path.join(BASE_PATH, \"test\")\n",
    "            \n",
    "            X_train, y_train = load_images_from_directory(train_path, \"TREINO\")\n",
    "            X_test, y_test = load_images_from_directory(test_path, \"TESTE\")\n",
    "            \n",
    "        elif structure == 'emotion_direct':\n",
    "            # Estrutura: base/emotion/ - precisa criar train/test split\n",
    "            print(\"üìä Carregando todas as imagens e criando divis√£o train/test...\")\n",
    "            \n",
    "            all_images, all_labels = load_images_from_directory(BASE_PATH, \"TODAS AS IMAGENS\")\n",
    "            \n",
    "            if len(all_images) == 0:\n",
    "                print(\"‚ùå Nenhuma imagem carregada!\")\n",
    "                return None, None, None, None\n",
    "            \n",
    "            # Cria divis√£o train/test\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                all_images, all_labels,\n",
    "                test_size=0.2,\n",
    "                stratify=all_labels,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            print(\"‚úÖ Divis√£o train/test criada automaticamente (80/20)\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå Estrutura de dados n√£o suportada!\")\n",
    "            print(\"üí° Estruturas esperadas:\")\n",
    "            print(\"   1. base/train/Raiva/*.jpg, base/train/Nojo/*.jpg, etc.\")\n",
    "            print(\"   2. base/Raiva/*.jpg, base/Nojo/*.jpg, etc.\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_test) == 0:\n",
    "            print(\"‚ùå Nenhuma imagem carregada. Verifique os caminhos e nomes das pastas!\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        print(f\"\\nüìä Dados carregados com sucesso:\")\n",
    "        print(f\"- X_train: {X_train.shape}\")\n",
    "        print(f\"- y_train: {y_train.shape}\")\n",
    "        print(f\"- X_test: {X_test.shape}\")\n",
    "        print(f\"- y_test: {y_test.shape}\")\n",
    "        \n",
    "        # NORMALIZA√á√ÉO ESPEC√çFICA PARA EFFICIENTNET: [0, 255] -> [-1, 1]\n",
    "        print(\"üîÑ Aplicando normaliza√ß√£o EfficientNet...\")\n",
    "        \n",
    "        X_train = X_train.astype(np.float32)\n",
    "        X_test = X_test.astype(np.float32)\n",
    "        \n",
    "        # EfficientNet normaliza√ß√£o: [0, 255] -> [-1, 1]\n",
    "        X_train = (X_train / 127.5) - 1.0\n",
    "        X_test = (X_test / 127.5) - 1.0\n",
    "        \n",
    "        print(\"‚úÖ Normaliza√ß√£o EfficientNet aplicada: [0,255] -> [-1,1]\")\n",
    "        \n",
    "        # Verifica resultado final\n",
    "        print(f\"\\nüîç Verifica√ß√£o final:\")\n",
    "        print(f\"- X_train range: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "        print(f\"- X_test range: [{X_test.min():.3f}, {X_test.max():.3f}]\")\n",
    "        print(f\"- Formato das imagens: {X_train.shape[1:]} (deve ser {IMG_SIZE}x{IMG_SIZE}x3)\")\n",
    "        \n",
    "        # Verifica distribui√ß√£o de classes\n",
    "        train_distribution = dict(Counter(y_train))\n",
    "        test_distribution = dict(Counter(y_test))\n",
    "        \n",
    "        print(f\"\\nüìà Distribui√ß√£o de classes:\")\n",
    "        emotion_names = list(EMOTION_LABELS.keys())\n",
    "        print(\"- Treino:\")\n",
    "        for label, count in train_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        print(\"- Teste:\")\n",
    "        for label, count in test_distribution.items():\n",
    "            emotion_name = emotion_names[label]\n",
    "            print(f\"  {emotion_name}: {count} imagens\")\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar dados: {e}\")\n",
    "        print(f\"üìç Erro detalhado: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(\"\\nüí° Solu√ß√µes poss√≠veis:\")\n",
    "        print(\"1. Verifique se o caminho est√° correto\")\n",
    "        print(\"2. Verifique se as pastas de emo√ß√µes existem\")\n",
    "        print(\"3. Verifique se h√° imagens nas pastas\")\n",
    "        print(\"4. Verifique permiss√µes de acesso\")\n",
    "        \n",
    "        return None, None, None, None\n",
    "\n",
    "# Executa carregamento\n",
    "X_train, y_train, X_test, y_test = load_preprocessed_data_efficientnet_from_images()\n",
    "\n",
    "if X_train is not None:\n",
    "    print(f\"\\nüéØ EfficientNet: Dados prontos para treinamento!\")\n",
    "    print(f\"üìè Formato final: {X_train.shape}\")\n",
    "    print(f\"üé® Range de valores: [{X_train.min():.3f}, {X_train.max():.3f}]\")\n",
    "    print(f\"‚úÖ Pronto para EfficientNet-B0!\")\n",
    "else:\n",
    "    print(\"‚ùå Falha no carregamento dos dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "105c5de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento EfficientNet iniciado: efficientnet_emotion_20250915_202611\n",
      "Estrutura otimizada para compara√ß√£o de arquiteturas\n"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_experiment_structure():\n",
    "    \"\"\"\n",
    "    Cria estrutura de diret√≥rios espec√≠fica para experimentos EfficientNet.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    experiment_id = f\"efficientnet_emotion_{timestamp}\"\n",
    "    \n",
    "    # Cria diret√≥rios espec√≠ficos\n",
    "    os.makedirs(\"models/efficientNetB0\", exist_ok=True)\n",
    "    os.makedirs(\"metrics/efficientNetB0\", exist_ok=True)\n",
    "    os.makedirs(\"plots/efficientNetB0\", exist_ok=True)\n",
    "    \n",
    "    return experiment_id\n",
    "\n",
    "def save_efficientnet_model_if_good_performance(model, base_model, accuracy, f1_score, experiment_id, threshold=0.80):\n",
    "    \"\"\"\n",
    "    Salva modelo EfficientNet apenas se performance for boa.\n",
    "    Inclui estrat√©gia espec√≠fica de salvamento com base_model para fine-tuning futuro.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo completo treinado\n",
    "        base_model: Base EfficientNet para refer√™ncia\n",
    "        accuracy: Acur√°cia do modelo\n",
    "        f1_score: F1-score macro do modelo  \n",
    "        experiment_id: ID √∫nico do experimento\n",
    "        threshold: Limite m√≠nimo para salvar\n",
    "    \"\"\"\n",
    "    # Crit√©rio mais rigoroso para EfficientNet (esperamos maior efici√™ncia)\n",
    "    performance_score = (accuracy + f1_score) / 2\n",
    "    \n",
    "    if performance_score >= threshold:\n",
    "        \n",
    "        # Salva pesos do modelo completo\n",
    "        model.save_weights(f\"models/efficientnet/weights_efficientnet_{experiment_id}.h5\")\n",
    "        \n",
    "        # Configura√ß√£o detalhada do modelo EfficientNet\n",
    "        model_config = {\n",
    "            'architecture': 'EfficientNet-B0',\n",
    "            'img_size': IMG_SIZE,\n",
    "            'num_classes': 7,\n",
    "            'experiment_id': experiment_id,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1_score,\n",
    "            'performance_score': performance_score,\n",
    "            'normalization_range': '[-1, 1]',\n",
    "            'total_params': model.count_params(),\n",
    "            'trainable_params': sum([tf.keras.backend.count_params(p) for p in model.trainable_weights]),\n",
    "            'base_model_layers': len(base_model.layers),\n",
    "            'efficientnet_config': EFFICIENTNET_CONFIG,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Salva configura√ß√£o\n",
    "        with open(f\"models/efficientnet/config_efficientnet_{experiment_id}.pkl\", 'wb') as f:\n",
    "            pickle.dump(model_config, f)\n",
    "        \n",
    "        print(f\"EfficientNet salvo! Performance: {performance_score:.4f} (Acc={accuracy:.4f}, F1={f1_score:.4f})\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Performance insuficiente: {performance_score:.4f} < {threshold}\")\n",
    "        return False\n",
    "\n",
    "def save_efficientnet_metrics_to_csv(metrics_dict, experiment_id):\n",
    "    \"\"\"\n",
    "    Salva m√©tricas EfficientNet em CSV separado para an√°lise comparativa.\n",
    "    \"\"\"\n",
    "    # Adiciona identificador de arquitetura\n",
    "    metrics_dict['architecture'] = 'EfficientNet-B0'\n",
    "    \n",
    "    # DataFrame com m√©tricas\n",
    "    metrics_df = pd.DataFrame([metrics_dict])\n",
    "    \n",
    "    # Arquivo CSV espec√≠fico para EfficientNet\n",
    "    efficientnet_csv = \"metrics/efficientnet/efficientnet_performance_metrics.csv\"\n",
    "    \n",
    "    # Append ao CSV se existir\n",
    "    if os.path.exists(efficientnet_csv):\n",
    "        metrics_df.to_csv(efficientnet_csv, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(efficientnet_csv, index=False)\n",
    "    \n",
    "    # Arquivo CSV consolidado (todos os modelos)\n",
    "    consolidated_csv = \"metrics/all_models_comparison.csv\"\n",
    "    if os.path.exists(consolidated_csv):\n",
    "        metrics_df.to_csv(consolidated_csv, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(consolidated_csv, index=False)\n",
    "    \n",
    "    # Arquivo individual\n",
    "    individual_csv = f\"metrics/efficientnet/efficientnet_metrics_{experiment_id}.csv\"\n",
    "    metrics_df.to_csv(individual_csv, index=False)\n",
    "    \n",
    "    print(f\"M√©tricas EfficientNet salvas em:\")\n",
    "    print(f\"  ‚Ä¢ Espec√≠fico: {efficientnet_csv}\")\n",
    "    print(f\"  ‚Ä¢ Consolidado: {consolidated_csv}\")\n",
    "    print(f\"  ‚Ä¢ Individual: {individual_csv}\")\n",
    "\n",
    "# Inicializa estrutura espec√≠fica do EfficientNet\n",
    "experiment_id = create_efficientnet_experiment_structure()\n",
    "print(f\"Experimento EfficientNet iniciado: {experiment_id}\")\n",
    "print(\"Estrutura otimizada para compara√ß√£o de arquiteturas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3832e2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCamadas trein√°veis: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tune_at\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(base_model.layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Verifica se dados foram carregados antes de criar modelo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX_train\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCriando modelo EfficientNet-B0 otimizado...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m     model, base_model = create_efficientnet_model()\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_model():\n",
    "    \"\"\"\n",
    "    Cria modelo EfficientNet-B0 otimizado para classifica√ß√£o de emo√ß√µes.\n",
    "    \n",
    "    EfficientNet Architecture:\n",
    "    - Compound scaling (width, depth, resolution)\n",
    "    - Mobile inverted bottleneck convolutions (MBConv)\n",
    "    - Squeeze-and-excitation optimization\n",
    "    - Swish activation functions\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (complete_model, base_model)\n",
    "    \"\"\"\n",
    "    # EfficientNet-B0 pr√©-treinado no ImageNet\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        #drop_connect_rate=0.2  # Dropout espec√≠fico do EfficientNet\n",
    "    )\n",
    "    \n",
    "    # Inicial: congela toda a base para feature extraction\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Head customizado para classifica√ß√£o de emo√ß√µes\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    \n",
    "    # Primeira camada densa - maior que ResNet50 para compensar menor base\n",
    "    x = Dense(1024, activation='relu', name='dense_1024')(x)\n",
    "    x = Dropout(EFFICIENTNET_CONFIG['dropout_rate'], name='dropout_main')(x)\n",
    "    \n",
    "    # Segunda camada densa\n",
    "    x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "    x = Dropout(0.3, name='dropout_secondary')(x)\n",
    "    \n",
    "    # Camada de classifica√ß√£o final\n",
    "    predictions = Dense(7, activation='softmax', name='emotion_predictions')(x)\n",
    "    \n",
    "    # Modelo completo\n",
    "    model = Model(inputs=base_model.input, outputs=predictions, name='EfficientNet_Emotion_Classifier')\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "def compile_efficientnet_phase1(model):\n",
    "    \"\"\"\n",
    "    Compila√ß√£o para Fase 1: Feature extraction (base congelada).\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=EFFICIENTNET_CONFIG['base_learning_rate']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(\"Fase 1: Modelo compilado para feature extraction\")\n",
    "    \n",
    "def compile_efficientnet_phase2(model, base_model):\n",
    "    \"\"\"\n",
    "    Compila√ß√£o para Fase 2: Fine-tuning (√∫ltimas camadas descongeladas).\n",
    "    \"\"\"\n",
    "    # Descongela √∫ltimas camadas para fine-tuning\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Mant√©m congeladas as primeiras camadas\n",
    "    fine_tune_at = len(base_model.layers) - EFFICIENTNET_CONFIG['fine_tune_layers']\n",
    "    \n",
    "    # Congela camadas iniciais\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Recompila com learning rate menor\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=EFFICIENTNET_CONFIG['fine_tune_learning_rate']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Fase 2: Fine-tuning das √∫ltimas {EFFICIENTNET_CONFIG['fine_tune_layers']} camadas\")\n",
    "    print(f\"Camadas trein√°veis: {fine_tune_at} a {len(base_model.layers)}\")\n",
    "\n",
    "# Verifica se dados foram carregados antes de criar modelo\n",
    "if X_train is not None:\n",
    "    print(\"Criando modelo EfficientNet-B0 otimizado...\")\n",
    "    model, base_model = create_efficientnet_model()\n",
    "    \n",
    "    # Compila√ß√£o inicial (Fase 1)\n",
    "    compile_efficientnet_phase1(model)\n",
    "    \n",
    "    # Estat√≠sticas do modelo\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    print(f\"EfficientNet-B0 criado com sucesso:\")\n",
    "    print(f\"  ‚Ä¢ Total de par√¢metros: {total_params:,}\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros trein√°veis (Fase 1): {trainable_params:,}\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros congelados: {non_trainable_params:,}\")\n",
    "    print(f\"  ‚Ä¢ Efici√™ncia: {total_params/1000000:.1f}M par√¢metros\")\n",
    "    print(f\"  ‚Ä¢ Ratio trein√°vel/total: {(trainable_params/total_params)*100:.1f}%\")\n",
    "    \n",
    "    # Sum√°rio do modelo (camadas principais)\n",
    "    print(f\"\\nArquitetura resumida:\")\n",
    "    print(f\"  ‚Ä¢ Base EfficientNet: {len(base_model.layers)} camadas\")\n",
    "    print(f\"  ‚Ä¢ GlobalAveragePooling2D\")\n",
    "    print(f\"  ‚Ä¢ Dense(1024) + Dropout({EFFICIENTNET_CONFIG['dropout_rate']})\")\n",
    "    print(f\"  ‚Ä¢ Dense(512) + Dropout(0.3)\")\n",
    "    print(f\"  ‚Ä¢ Dense(7) softmax\")\n",
    "    \n",
    "    monitor.update_peak_memory()\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Dados n√£o carregados. Verifique a c√©lula de carregamento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f644550d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCamadas trein√°veis: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tune_at\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(base_model.layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Verifica se dados foram carregados antes de criar modelo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX_train\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCriando modelo EfficientNet-B0 otimizado...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m     model, base_model = create_efficientnet_model()\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_model():\n",
    "    \"\"\"\n",
    "    Cria modelo EfficientNet-B0 otimizado para classifica√ß√£o de emo√ß√µes.\n",
    "    \n",
    "    EfficientNet Architecture:\n",
    "    - Compound scaling (width, depth, resolution)\n",
    "    - Mobile inverted bottleneck convolutions (MBConv)\n",
    "    - Squeeze-and-excitation optimization\n",
    "    - Swish activation functions\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (complete_model, base_model)\n",
    "    \"\"\"\n",
    "    # EfficientNet-B0 pr√©-treinado no ImageNet\n",
    "    # CORRIGIDO: Removido par√¢metro 'drop_connect_rate' inv√°lido\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Inicial: congela toda a base para feature extraction\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Head customizado para classifica√ß√£o de emo√ß√µes\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    \n",
    "    # Primeira camada densa - maior que ResNet50 para compensar menor base\n",
    "    x = Dense(1024, activation='relu', name='dense_1024')(x)\n",
    "    x = Dropout(EFFICIENTNET_CONFIG['dropout_rate'], name='dropout_main')(x)\n",
    "    \n",
    "    # Segunda camada densa\n",
    "    x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "    x = Dropout(0.3, name='dropout_secondary')(x)\n",
    "    \n",
    "    # Camada de classifica√ß√£o final\n",
    "    predictions = Dense(7, activation='softmax', name='emotion_predictions')(x)\n",
    "    \n",
    "    # Modelo completo\n",
    "    model = Model(inputs=base_model.input, outputs=predictions, name='EfficientNet_Emotion_Classifier')\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "def compile_efficientnet_phase1(model):\n",
    "    \"\"\"\n",
    "    Compila√ß√£o para Fase 1: Feature extraction (base congelada).\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=EFFICIENTNET_CONFIG['base_learning_rate']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(\"Fase 1: Modelo compilado para feature extraction\")\n",
    "    \n",
    "def compile_efficientnet_phase2(model, base_model):\n",
    "    \"\"\"\n",
    "    Compila√ß√£o para Fase 2: Fine-tuning (√∫ltimas camadas descongeladas).\n",
    "    \"\"\"\n",
    "    # Descongela √∫ltimas camadas para fine-tuning\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Mant√©m congeladas as primeiras camadas\n",
    "    fine_tune_at = len(base_model.layers) - EFFICIENTNET_CONFIG['fine_tune_layers']\n",
    "    \n",
    "    # Congela camadas iniciais\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Recompila com learning rate menor\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=EFFICIENTNET_CONFIG['fine_tune_learning_rate']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Fase 2: Fine-tuning das √∫ltimas {EFFICIENTNET_CONFIG['fine_tune_layers']} camadas\")\n",
    "    print(f\"Camadas trein√°veis: {fine_tune_at} a {len(base_model.layers)}\")\n",
    "\n",
    "# Verifica se dados foram carregados antes de criar modelo\n",
    "if X_train is not None:\n",
    "    print(\"Criando modelo EfficientNet-B0 otimizado...\")\n",
    "    model, base_model = create_efficientnet_model()\n",
    "    \n",
    "    # Compila√ß√£o inicial (Fase 1)\n",
    "    compile_efficientnet_phase1(model)\n",
    "    \n",
    "    # Estat√≠sticas do modelo\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    print(f\"EfficientNet-B0 criado com sucesso:\")\n",
    "    print(f\"  ‚Ä¢ Total de par√¢metros: {total_params:,}\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros trein√°veis (Fase 1): {trainable_params:,}\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros congelados: {non_trainable_params:,}\")\n",
    "    print(f\"  ‚Ä¢ Efici√™ncia: {total_params/1000000:.1f}M par√¢metros\")\n",
    "    print(f\"  ‚Ä¢ Ratio trein√°vel/total: {(trainable_params/total_params)*100:.1f}%\")\n",
    "    \n",
    "    # Sum√°rio do modelo (camadas principais)\n",
    "    print(f\"\\nArquitetura resumida:\")\n",
    "    print(f\"  ‚Ä¢ Base EfficientNet: {len(base_model.layers)} camadas\")\n",
    "    print(f\"  ‚Ä¢ GlobalAveragePooling2D\")\n",
    "    print(f\"  ‚Ä¢ Dense(1024) + Dropout({EFFICIENTNET_CONFIG['dropout_rate']})\")\n",
    "    print(f\"  ‚Ä¢ Dense(512) + Dropout(0.3)\")\n",
    "    print(f\"  ‚Ä¢ Dense(7) softmax\")\n",
    "    \n",
    "    monitor.update_peak_memory()\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Dados n√£o carregados. Verifique a c√©lula de carregamento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51525d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficientnet_model_with_custom_dropout():\n",
    "    \"\"\"\n",
    "    Vers√£o alternativa com controle manual de dropout.\n",
    "    \"\"\"\n",
    "    # Base model sem par√¢metros extras\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Congela inicialmente\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # OPCIONAL: Adiciona dropout customizado √†s camadas intermedi√°rias\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    \n",
    "    # Dropout adicional para regulariza√ß√£o (simula drop_connect)\n",
    "    x = Dropout(0.2, name='feature_dropout')(x)  # Equivalent to drop_connect_rate\n",
    "    \n",
    "    # Camadas de classifica√ß√£o\n",
    "    x = Dense(1024, activation='relu', name='dense_1024')(x)\n",
    "    x = Dropout(EFFICIENTNET_CONFIG['dropout_rate'], name='dropout_main')(x)\n",
    "    \n",
    "    x = Dense(512, activation='relu', name='dense_512')(x)\n",
    "    x = Dropout(0.3, name='dropout_secondary')(x)\n",
    "    \n",
    "    predictions = Dense(7, activation='softmax', name='emotion_predictions')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions, name='EfficientNet_Emotion_Classifier')\n",
    "    \n",
    "    print(\"‚úÖ EfficientNet criado com dropout customizado\")\n",
    "    print(\"üí° Drop connect simulado via Dropout(0.2) ap√≥s GlobalAveragePooling\")\n",
    "    \n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d54505",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mEfficientNetMemoryCallback\u001b[39;00m(\u001b[43mtf\u001b[49m.keras.callbacks.Callback):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Callback especializado para monitoramento de EfficientNet.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Foca em efici√™ncia de mem√≥ria e compara√ß√£o com ResNet50.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, monitor, phase_name):\n",
      "\u001b[31mNameError\u001b[39m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class EfficientNetMemoryCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback especializado para monitoramento de EfficientNet.\n",
    "    Foca em efici√™ncia de mem√≥ria e compara√ß√£o com ResNet50.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, monitor, phase_name):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.phase_name = phase_name\n",
    "        self.epoch_times = []\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Calcula tempo da √©poca\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        \n",
    "        # Atualiza mem√≥ria\n",
    "        self.monitor.update_peak_memory()\n",
    "        \n",
    "        # Log detalhado a cada 5 √©pocas\n",
    "        if epoch % 5 == 0:\n",
    "            current_memory = self.monitor._get_memory_usage()\n",
    "            avg_epoch_time = np.mean(self.epoch_times[-5:])  # M√©dia das √∫ltimas 5 √©pocas\n",
    "            \n",
    "            print(f\"{self.phase_name} - √âpoca {epoch+1}\")\n",
    "            print(f\"  ‚Ä¢ Mem√≥ria atual: {current_memory:.1f} MB\")\n",
    "            print(f\"  ‚Ä¢ Tempo/√©poca: {avg_epoch_time:.1f}s\")\n",
    "            if logs:\n",
    "                print(f\"  ‚Ä¢ Val_accuracy: {logs.get('val_accuracy', 0):.4f}\")\n",
    "                print(f\"  ‚Ä¢ Val_loss: {logs.get('val_loss', 0):.4f}\")\n",
    "\n",
    "def setup_efficientnet_callbacks(monitor, phase_name):\n",
    "    \"\"\"\n",
    "    Configura callbacks otimizados para cada fase do EfficientNet.\n",
    "    \"\"\"\n",
    "    callbacks_list = []\n",
    "    \n",
    "    # Early stopping com paci√™ncia diferente por fase\n",
    "    if phase_name == \"Fase1\":\n",
    "        patience = 12  # Menos paci√™ncia na fase 1\n",
    "        min_delta = 0.001\n",
    "    else:\n",
    "        patience = 20  # Mais paci√™ncia no fine-tuning\n",
    "        min_delta = 0.0005\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',  # Monitora accuracy para EfficientNet\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "        min_delta=min_delta\n",
    "    )\n",
    "    \n",
    "    # Reduce learning rate\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.3,  # Redu√ß√£o mais agressiva para EfficientNet\n",
    "        patience=8,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Memory callback personalizado\n",
    "    memory_callback = EfficientNetMemoryCallback(monitor, phase_name)\n",
    "    \n",
    "    callbacks_list = [early_stopping, reduce_lr, memory_callback]\n",
    "    \n",
    "    return callbacks_list\n",
    "\n",
    "def train_efficientnet_two_phase(model, base_model, X_train, y_train, X_val, y_val, monitor):\n",
    "    \"\"\"\n",
    "    Treinamento EfficientNet em 2 fases otimizadas.\n",
    "    \n",
    "    Fase 1: Feature extraction (base congelada)\n",
    "    Fase 2: Fine-tuning (√∫ltimas camadas descongeladas)\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"INICIANDO TREINAMENTO EFFICIENTNET EM 2 FASES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # === FASE 1: FEATURE EXTRACTION ===\n",
    "    print(\"FASE 1: FEATURE EXTRACTION\")\n",
    "    print(\"-\" * 40)\n",
    "    monitor.start_phase('phase1')\n",
    "    \n",
    "    # Callbacks para Fase 1\n",
    "    phase1_callbacks = setup_efficientnet_callbacks(monitor, \"Fase1\")\n",
    "    \n",
    "    # Treinamento Fase 1\n",
    "    history_phase1 = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=30,  # Menos √©pocas na fase 1\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=phase1_callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    phase1_duration = monitor.end_phase('phase1')\n",
    "    best_val_acc_phase1 = max(history_phase1.history['val_accuracy'])\n",
    "    print(f\"Fase 1 - Melhor val_accuracy: {best_val_acc_phase1:.4f}\")\n",
    "    \n",
    "    # === FASE 2: FINE-TUNING ===\n",
    "    print(\"\\nFASE 2: FINE-TUNING\")\n",
    "    print(\"-\" * 40)\n",
    "    monitor.start_phase('phase2')\n",
    "    \n",
    "    # Reconfigura√ß√£o para fine-tuning\n",
    "    compile_efficientnet_phase2(model, base_model)\n",
    "    \n",
    "    # Callbacks para Fase 2\n",
    "    phase2_callbacks = setup_efficientnet_callbacks(monitor, \"Fase2\")\n",
    "    \n",
    "    # Treinamento Fase 2\n",
    "    history_phase2 = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS - 30,  # Restante das √©pocas\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=phase2_callbacks,\n",
    "        verbose=1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    phase2_duration = monitor.end_phase('phase2')\n",
    "    best_val_acc_phase2 = max(history_phase2.history['val_accuracy'])\n",
    "    print(f\"Fase 2 - Melhor val_accuracy: {best_val_acc_phase2:.4f}\")\n",
    "    \n",
    "    # Combina hist√≥ricos das duas fases\n",
    "    combined_history = {\n",
    "        'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],\n",
    "        'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],\n",
    "        'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n",
    "        'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss'],\n",
    "        'phase1_epochs': len(history_phase1.history['accuracy']),\n",
    "        'phase2_epochs': len(history_phase2.history['accuracy']),\n",
    "        'phase1_duration': phase1_duration,\n",
    "        'phase2_duration': phase2_duration,\n",
    "        'best_val_acc_phase1': best_val_acc_phase1,\n",
    "        'best_val_acc_phase2': best_val_acc_phase2\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTREINAMENTO COMPLETO:\")\n",
    "    print(f\"  ‚Ä¢ Total de √©pocas: {combined_history['phase1_epochs'] + combined_history['phase2_epochs']}\")\n",
    "    print(f\"  ‚Ä¢ Melhor accuracy final: {max(combined_history['val_accuracy']):.4f}\")\n",
    "    print(f\"  ‚Ä¢ Tempo total: {timedelta(seconds=int(phase1_duration + phase2_duration))}\")\n",
    "    \n",
    "    return combined_history\n",
    "\n",
    "# Executa treinamento se modelo foi criado com sucesso\n",
    "if 'model' in locals() and model is not None:\n",
    "    \n",
    "    # Prepara√ß√£o dos dados\n",
    "    print(\"Preparando dados para treinamento EfficientNet...\")\n",
    "    \n",
    "    # Divis√£o estratificada treino/valida√ß√£o\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=VALIDATION_SPLIT,\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convers√£o para categorical\n",
    "    y_train_cat = to_categorical(y_train_split, 7)\n",
    "    y_val_cat = to_categorical(y_val, 7)\n",
    "    y_test_cat = to_categorical(y_test, 7)\n",
    "    \n",
    "    print(f\"Dados preparados:\")\n",
    "    print(f\"  ‚Ä¢ Treino: {X_train_split.shape}\")\n",
    "    print(f\"  ‚Ä¢ Valida√ß√£o: {X_val.shape}\")\n",
    "    print(f\"  ‚Ä¢ Teste: {X_test.shape}\")\n",
    "    print(f\"  ‚Ä¢ Range normaliza√ß√£o: [{X_train_split.min():.2f}, {X_train_split.max():.2f}]\")\n",
    "    \n",
    "    # Executa treinamento em 2 fases\n",
    "    history = train_efficientnet_two_phase(\n",
    "        model, base_model, X_train_split, y_train_cat, X_val, y_val_cat, monitor\n",
    "    )\n",
    "    \n",
    "    print(\"EfficientNet: Treinamento em 2 fases finalizado com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Modelo EfficientNet n√£o foi criado. Verifique c√©lulas anteriores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e315b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro: Treinamento EfficientNet n√£o foi executado corretamente\n"
     ]
    }
   ],
   "source": [
    "def comprehensive_efficientnet_evaluation(model, X_test, y_test_cat, y_test_original, history, monitor):\n",
    "    \"\"\"\n",
    "    Avalia√ß√£o completa do EfficientNet com m√©tricas comparativas.\n",
    "    Foco em efici√™ncia computacional vs ResNet50.\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"AVALIA√á√ÉO COMPARATIVA EFFICIENTNET-B0\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # === M√âTRICAS DE INFER√äNCIA ===\n",
    "    print(\"Medindo performance de infer√™ncia...\")\n",
    "    \n",
    "    # M√∫ltiplas medi√ß√µes para precis√£o\n",
    "    inference_times = []\n",
    "    for i in range(5):  # 5 medi√ß√µes\n",
    "        start_time = time.time()\n",
    "        y_pred_prob = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "        end_time = time.time()\n",
    "        inference_times.append(end_time - start_time)\n",
    "    \n",
    "    # Estat√≠sticas de infer√™ncia\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    std_inference_time = np.std(inference_times)\n",
    "    inference_per_sample = avg_inference_time / len(X_test)\n",
    "    samples_per_second = len(X_test) / avg_inference_time\n",
    "    \n",
    "    # === M√âTRICAS DE CLASSIFICA√á√ÉO ===\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = y_test_original\n",
    "    \n",
    "    # M√©tricas principais\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # M√©tricas adicionais\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true_classes, y_pred_classes, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Matriz de confus√£o e relat√≥rio por classe\n",
    "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    class_report = classification_report(\n",
    "        y_true_classes, y_pred_classes,\n",
    "        target_names=emotion_names,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # === M√âTRICAS DE EFICI√äNCIA COMPUTACIONAL ===\n",
    "    efficiency_metrics = monitor.get_efficiency_metrics()\n",
    "    current_memory = monitor._get_memory_usage()\n",
    "    \n",
    "    # Par√¢metros do modelo\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(p) for p in model.trainable_weights])\n",
    "    \n",
    "    # === COMPILA√á√ÉO COMPLETA DAS M√âTRICAS ===\n",
    "    comprehensive_metrics = {\n",
    "        # Identifica√ß√£o\n",
    "        'experiment_id': experiment_id,\n",
    "        'model_architecture': 'EfficientNet-B0',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        \n",
    "        # Configura√ß√£o\n",
    "        'img_size': IMG_SIZE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'normalization_range': '[-1, 1]',\n",
    "        'total_epochs_trained': history['phase1_epochs'] + history['phase2_epochs'],\n",
    "        'phase1_epochs': history['phase1_epochs'],\n",
    "        'phase2_epochs': history['phase2_epochs'],\n",
    "        \n",
    "        # Performance de classifica√ß√£o\n",
    "        'test_accuracy': accuracy,\n",
    "        'f1_score_macro': f1,\n",
    "        'f1_score_micro': f1_micro,\n",
    "        'f1_score_weighted': f1_weighted,\n",
    "        'precision_macro': precision,\n",
    "        'recall_macro': recall,\n",
    "        'performance_score': (accuracy + f1) / 2,\n",
    "        \n",
    "        # Efici√™ncia temporal\n",
    "        'avg_inference_time_seconds': avg_inference_time,\n",
    "        'std_inference_time_seconds': std_inference_time,\n",
    "        'inference_per_sample_ms': inference_per_sample * 1000,\n",
    "        'samples_per_second': samples_per_second,\n",
    "        'phase1_training_time_seconds': history['phase1_duration'],\n",
    "        'phase2_training_time_seconds': history['phase2_duration'],\n",
    "        'total_training_time_seconds': history['phase1_duration'] + history['phase2_duration'],\n",
    "        \n",
    "        # Efici√™ncia de mem√≥ria\n",
    "        'peak_memory_mb': monitor.peak_memory_mb,\n",
    "        'current_memory_mb': current_memory,\n",
    "        'memory_efficiency': efficiency_metrics['memory_efficiency'],\n",
    "        'memory_growth_factor': efficiency_metrics['memory_growth_factor'],\n",
    "        'peak_memory_gb': efficiency_metrics['peak_memory_gb'],\n",
    "        \n",
    "        # Efici√™ncia de modelo\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params,\n",
    "        'parameters_millions': total_params / 1000000,\n",
    "        'params_per_accuracy': total_params / accuracy if accuracy > 0 else 0,\n",
    "        'efficiency_score': accuracy / (total_params / 1000000),  # Accuracy per million params\n",
    "        \n",
    "        # M√©tricas por emo√ß√£o\n",
    "        'anger_f1': class_report['anger']['f1-score'],\n",
    "        'disgust_f1': class_report['disgust']['f1-score'],\n",
    "        'fear_f1': class_report['fear']['f1-score'],\n",
    "        'happy_f1': class_report['happy']['f1-score'],\n",
    "        'neutral_f1': class_report['neutral']['f1-score'],\n",
    "        'sadness_f1': class_report['sadness']['f1-score'],\n",
    "        'surprise_f1': class_report['surprise']['f1-score'],\n",
    "        \n",
    "        # Dados do dataset\n",
    "        'train_samples': len(X_train_split),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        \n",
    "        # Compara√ß√£o espec√≠fica EfficientNet\n",
    "        'compound_scaling': 'Yes',\n",
    "        'mobile_inverted_bottleneck': 'Yes',\n",
    "        'squeeze_excitation': 'Yes',\n",
    "        'drop_connect_rate': 0.2\n",
    "    }\n",
    "    \n",
    "    return comprehensive_metrics, conf_matrix, class_report\n",
    "\n",
    "# Executa avalia√ß√£o se treinamento foi bem-sucedido\n",
    "if 'history' in locals() and history is not None:\n",
    "    \n",
    "    print(\"Executando avalia√ß√£o completa EfficientNet...\")\n",
    "    \n",
    "    # Avalia√ß√£o detalhada\n",
    "    metrics, confusion_matrix_result, detailed_report = comprehensive_efficientnet_evaluation(\n",
    "        model, X_test, y_test_cat, y_test, history, monitor\n",
    "    )\n",
    "    \n",
    "    # Salva m√©tricas em CSV\n",
    "    save_efficientnet_metrics_to_csv(metrics, experiment_id)\n",
    "    \n",
    "    # Tenta salvar modelo se performance for boa\n",
    "    model_saved = save_efficientnet_model_if_good_performance(\n",
    "        model, base_model,\n",
    "        metrics['test_accuracy'], \n",
    "        metrics['f1_score_macro'], \n",
    "        experiment_id,\n",
    "        threshold=0.75  # Threshold mais baixo para EfficientNet (mais conservador)\n",
    "    )\n",
    "    \n",
    "    # Finaliza monitoramento\n",
    "    monitor_final_stats = monitor.end_monitoring()\n",
    "    \n",
    "    # === COMPARA√á√ÉO COM RESNET50 ===\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"COMPARA√á√ÉO EFFICIENTNET-B0 vs ResNet50\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"EfficientNet-B0:\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros: {metrics['parameters_millions']:.1f}M\")\n",
    "    print(f\"  ‚Ä¢ Acur√°cia: {metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ F1-Score: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Infer√™ncia/amostra: {metrics['inference_per_sample_ms']:.2f} ms\")\n",
    "    print(f\"  ‚Ä¢ Efici√™ncia: {metrics['efficiency_score']:.2f} acc/M_params\")\n",
    "    print(f\"  ‚Ä¢ Pico mem√≥ria: {metrics['peak_memory_gb']:.2f} GB\")\n",
    "    print(f\"\")\n",
    "    print(f\"ResNet50 (t√≠pico):\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros: ~25.6M\")\n",
    "    print(f\"  ‚Ä¢ Efici√™ncia esperada: ~80% dos par√¢metros do EfficientNet\")\n",
    "    print(f\"  ‚Ä¢ Compara√ß√£o: EfficientNet √© {25.6/metrics['parameters_millions']:.1f}x mais eficiente\")\n",
    "    print(f\"\")\n",
    "    print(f\"Modelo salvo: {'Sim' if model_saved else 'N√£o'}\")\n",
    "    print(f\"Performance Score: {metrics['performance_score']:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Erro: Treinamento EfficientNet n√£o foi executado corretamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cac31e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro: Avalia√ß√£o EfficientNet n√£o foi executada corretamente\n"
     ]
    }
   ],
   "source": [
    "def create_efficientnet_comparative_visualizations(history, confusion_matrix_result, metrics, detailed_report):\n",
    "    \"\"\"\n",
    "    Cria visualiza√ß√µes especializadas para an√°lise de EfficientNet vs ResNet50.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "    \n",
    "    # === 1. HIST√ìRICO DE TREINAMENTO EM 2 FASES ===\n",
    "    ax1 = plt.subplot(3, 4, 1)\n",
    "    epochs_phase1 = range(1, history['phase1_epochs'] + 1)\n",
    "    epochs_phase2 = range(history['phase1_epochs'] + 1, \n",
    "                         history['phase1_epochs'] + history['phase2_epochs'] + 1)\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.plot(epochs_phase1, history['accuracy'][:history['phase1_epochs']], \n",
    "             'b-', linewidth=2, label='Fase 1 - Train')\n",
    "    plt.plot(epochs_phase1, history['val_accuracy'][:history['phase1_epochs']], \n",
    "             'b--', linewidth=2, label='Fase 1 - Val')\n",
    "    plt.plot(epochs_phase2, history['accuracy'][history['phase1_epochs']:], \n",
    "             'r-', linewidth=2, label='Fase 2 - Train')\n",
    "    plt.plot(epochs_phase2, history['val_accuracy'][history['phase1_epochs']:], \n",
    "             'r--', linewidth=2, label='Fase 2 - Val')\n",
    "    \n",
    "    plt.axvline(x=history['phase1_epochs'], color='gray', linestyle=':', alpha=0.7)\n",
    "    plt.title('EfficientNet: Accuracy - 2 Fases', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('√âpoca')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # === 2. LOSS EM 2 FASES ===\n",
    "    ax2 = plt.subplot(3, 4, 2)\n",
    "    plt.plot(epochs_phase1, history['loss'][:history['phase1_epochs']], \n",
    "             'b-', linewidth=2, label='Fase 1 - Train')\n",
    "    plt.plot(epochs_phase1, history['val_loss'][:history['phase1_epochs']], \n",
    "             'b--', linewidth=2, label='Fase 1 - Val')\n",
    "    plt.plot(epochs_phase2, history['loss'][history['phase1_epochs']:], \n",
    "             'r-', linewidth=2, label='Fase 2 - Train')\n",
    "    plt.plot(epochs_phase2, history['val_loss'][history['phase1_epochs']:], \n",
    "             'r--', linewidth=2, label='Fase 2 - Val')\n",
    "    \n",
    "    plt.axvline(x=history['phase1_epochs'], color='gray', linestyle=':', alpha=0.7)\n",
    "    plt.title('EfficientNet: Loss - 2 Fases', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('√âpoca')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # === 3. MATRIZ DE CONFUS√ÉO ===\n",
    "    ax3 = plt.subplot(3, 4, 3)\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    sns.heatmap(confusion_matrix_result, annot=True, fmt='d', cmap='Greens',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax3)\n",
    "    plt.title('Matriz de Confus√£o - EfficientNet', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Classe Real')\n",
    "    plt.xlabel('Classe Predita')\n",
    "    \n",
    "    # === 4. F1-SCORE POR EMO√á√ÉO ===\n",
    "    ax4 = plt.subplot(3, 4, 4)\n",
    "    f1_scores = [detailed_report[emotion]['f1-score'] for emotion in emotion_names]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(emotion_names)))\n",
    "    bars = plt.bar(emotion_names, f1_scores, color=colors, alpha=0.8, edgecolor='black')\n",
    "    plt.title('F1-Score por Emo√ß√£o', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar, score in zip(bars, f1_scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{score:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # === 5. COMPARA√á√ÉO DE EFICI√äNCIA ===\n",
    "    ax5 = plt.subplot(3, 4, 5)\n",
    "    # Dados comparativos (EfficientNet vs ResNet50 t√≠pico)\n",
    "    models = ['EfficientNet-B0', 'ResNet50']\n",
    "    parameters = [metrics['parameters_millions'], 25.6]  # ResNet50 t√≠pico\n",
    "    accuracy_comparison = [metrics['test_accuracy'], 0.75]  # Estimativa ResNet50\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, parameters, width, label='Par√¢metros (M)', alpha=0.8, color='skyblue')\n",
    "    bars2 = plt.bar(x + width/2, [acc * 100 for acc in accuracy_comparison], width, \n",
    "                   label='Accuracy (%)', alpha=0.8, color='lightcoral')\n",
    "    \n",
    "    plt.title('Compara√ß√£o: Par√¢metros vs Accuracy', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Modelo')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.xticks(x, models)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Adiciona valores nas barras\n",
    "    for bar, value in zip(bars1, parameters):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                f'{value:.1f}M', ha='center', va='bottom')\n",
    "    for bar, acc in zip(bars2, accuracy_comparison):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{acc:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # === 6. EFICI√äNCIA TEMPORAL ===\n",
    "    ax6 = plt.subplot(3, 4, 6)\n",
    "    time_metrics = {\n",
    "        'Fase 1 (min)': history['phase1_duration'] / 60,\n",
    "        'Fase 2 (min)': history['phase2_duration'] / 60,\n",
    "        'Infer√™ncia (ms)': metrics['inference_per_sample_ms'],\n",
    "        'Throughput': metrics['samples_per_second']\n",
    "    }\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    bars = plt.bar(range(len(time_metrics)), list(time_metrics.values()), \n",
    "                  color=colors, alpha=0.7)\n",
    "    plt.title('M√©tricas de Tempo', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(range(len(time_metrics)), list(time_metrics.keys()), rotation=45)\n",
    "    plt.ylabel('Valor')\n",
    "    \n",
    "    # === 7. EFICI√äNCIA DE MEM√ìRIA ===\n",
    "    ax7 = plt.subplot(3, 4, 7)\n",
    "    memory_data = [\n",
    "        monitor.initial_memory_mb / 1024,  # GB\n",
    "        monitor.peak_memory_mb / 1024,     # GB\n",
    "        metrics['memory_growth_factor']\n",
    "    ]\n",
    "    memory_labels = ['Inicial (GB)', 'Pico (GB)', 'Fator Crescimento']\n",
    "    \n",
    "    bars = plt.bar(memory_labels, memory_data, color=['green', 'orange', 'red'], alpha=0.7)\n",
    "    plt.title('Uso de Mem√≥ria', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    for bar, value in zip(bars, memory_data):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # === 8. RADAR CHART - PERFORMANCE GERAL ===\n",
    "    ax8 = plt.subplot(3, 4, 8, projection='polar')\n",
    "    \n",
    "    categories = ['Accuracy', 'F1-Score', 'Efficiency\\n(Acc/M_params)', 'Speed\\n(samples/s)', \n",
    "                 'Memory\\nEfficiency']\n",
    "    values = [\n",
    "        metrics['test_accuracy'],\n",
    "        metrics['f1_score_macro'], \n",
    "        min(metrics['efficiency_score'] / 10, 1),  # Normalizado\n",
    "        min(metrics['samples_per_second'] / 1000, 1),  # Normalizado\n",
    "        metrics['memory_efficiency']\n",
    "    ]\n",
    "    \n",
    "    # Fecha o radar\n",
    "    values += values[:1]\n",
    "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax8.plot(angles, values, 'o-', linewidth=2, color='blue', alpha=0.7)\n",
    "    ax8.fill(angles, values, alpha=0.25, color='blue')\n",
    "    ax8.set_xticks(angles[:-1])\n",
    "    ax8.set_xticklabels(categories)\n",
    "    ax8.set_ylim(0, 1)\n",
    "    plt.title('Performance Radar - EfficientNet', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # === 9-12. M√âTRICAS DETALHADAS ===\n",
    "    # Performance por fase\n",
    "    ax9 = plt.subplot(3, 4, 9)\n",
    "    phases = ['Fase 1', 'Fase 2']\n",
    "    phase_performance = [history['best_val_acc_phase1'], history['best_val_acc_phase2']]\n",
    "    bars = plt.bar(phases, phase_performance, color=['lightblue', 'lightgreen'], alpha=0.8)\n",
    "    plt.title('Melhor Accuracy por Fase', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    for bar, acc in zip(bars, phase_performance):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                f'{acc:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Distribui√ß√£o de classes\n",
    "    ax10 = plt.subplot(3, 4, 10)\n",
    "    test_distribution = [sum(y_test == i) for i in range(7)]\n",
    "    plt.pie(test_distribution, labels=emotion_names, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Distribui√ß√£o Classes - Teste', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Compara√ß√£o ResNet vs EfficientNet (simulada)\n",
    "    ax11 = plt.subplot(3, 4, 11)\n",
    "    comparison_metrics = ['Accuracy', 'Parameters (M)', 'Speed (rel)', 'Memory (rel)']\n",
    "    efficientnet_values = [metrics['test_accuracy'], metrics['parameters_millions'], 1.0, 1.0]\n",
    "    resnet_values = [0.75, 25.6, 0.8, 1.2]  # Valores estimados\n",
    "    \n",
    "    x = np.arange(len(comparison_metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, efficientnet_values, width, label='EfficientNet-B0', alpha=0.8)\n",
    "    plt.bar(x + width/2, resnet_values, width, label='ResNet50', alpha=0.8)\n",
    "    \n",
    "    plt.title('EfficientNet vs ResNet50', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('M√©tricas')\n",
    "    plt.xticks(x, comparison_metrics, rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Resumo final\n",
    "    ax12 = plt.subplot(3, 4, 12)\n",
    "    ax12.axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "EfficientNet-B0 RESUMO\n",
    "\n",
    "Accuracy: {metrics['test_accuracy']:.4f}\n",
    "F1-Score: {metrics['f1_score_macro']:.4f}\n",
    "Par√¢metros: {metrics['parameters_millions']:.1f}M\n",
    "Efici√™ncia: {metrics['efficiency_score']:.2f}\n",
    "\n",
    "Tempo Treino: {timedelta(seconds=int(metrics['total_training_time_seconds']))}\n",
    "Infer√™ncia: {metrics['inference_per_sample_ms']:.1f} ms\n",
    "Mem√≥ria Pico: {metrics['peak_memory_gb']:.2f} GB\n",
    "\n",
    "Vantagem vs ResNet50:\n",
    "- {25.6/metrics['parameters_millions']:.1f}x menos par√¢metros\n",
    "- Converg√™ncia em 2 fases\n",
    "- Compound scaling otimizado\n",
    "    \"\"\"\n",
    "    ax12.text(0.1, 0.9, summary_text, fontsize=12, verticalalignment='top', \n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/efficientnet/efficientnet_comprehensive_analysis_{experiment_id}.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # === RELAT√ìRIO CIENT√çFICO FINAL ===\n",
    "    print_efficientnet_scientific_report(metrics, history, monitor_final_stats)\n",
    "\n",
    "def print_efficientnet_scientific_report(metrics, history, monitor_stats):\n",
    "    \"\"\"Relat√≥rio cient√≠fico detalhado do EfficientNet\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RELAT√ìRIO CIENT√çFICO FINAL - EFFICIENTNET-B0\")\n",
    "    print(f\"Experimento: {experiment_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"ARQUITETURA E CONFIGURA√á√ÉO:\")\n",
    "    print(f\"  ‚Ä¢ Modelo: EfficientNet-B0 (Compound Scaling)\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros: {metrics['parameters_millions']:.1f}M\")\n",
    "    print(f\"  ‚Ä¢ Entrada: {IMG_SIZE}x{IMG_SIZE}x3, normaliza√ß√£o [-1,1]\")\n",
    "    print(f\"  ‚Ä¢ Treinamento: 2 fases (Feature extraction + Fine-tuning)\")\n",
    "    \n",
    "    print(f\"\\nPERFORMANCE DE CLASSIFICA√á√ÉO:\")\n",
    "    print(f\"  ‚Ä¢ Acur√°cia: {metrics['test_accuracy']:.4f} ({metrics['test_accuracy']*100:.2f}%)\")\n",
    "    print(f\"  ‚Ä¢ F1-Score Macro: {metrics['f1_score_macro']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Precis√£o Macro: {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Recall Macro: {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Performance Score: {metrics['performance_score']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nEFICI√äNCIA COMPUTACIONAL:\")\n",
    "    print(f\"  ‚Ä¢ Efici√™ncia: {metrics['efficiency_score']:.2f} accuracy/M_parameters\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros/Accuracy: {metrics['params_per_accuracy']:,.0f}\")\n",
    "    print(f\"  ‚Ä¢ Throughput: {metrics['samples_per_second']:.1f} amostras/segundo\")\n",
    "    print(f\"  ‚Ä¢ Infer√™ncia: {metrics['inference_per_sample_ms']:.2f} ms/amostra\")\n",
    "    \n",
    "    print(f\"\\nTREINAMENTO EM 2 FASES:\")\n",
    "    print(f\"  ‚Ä¢ Fase 1 (Feature extraction): {history['phase1_epochs']} √©pocas, {timedelta(seconds=int(history['phase1_duration']))}\")\n",
    "    print(f\"  ‚Ä¢ Fase 2 (Fine-tuning): {history['phase2_epochs']} √©pocas, {timedelta(seconds=int(history['phase2_duration']))}\")\n",
    "    print(f\"  ‚Ä¢ Tempo total: {timedelta(seconds=int(metrics['total_training_time_seconds']))}\")\n",
    "    print(f\"  ‚Ä¢ Melhor accuracy Fase 1: {history['best_val_acc_phase1']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Melhor accuracy Fase 2: {history['best_val_acc_phase2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nUSO DE RECURSOS:\")\n",
    "    print(f\"  ‚Ä¢ Pico de mem√≥ria: {metrics['peak_memory_gb']:.2f} GB\")\n",
    "    print(f\"  ‚Ä¢ Crescimento de mem√≥ria: {metrics['memory_growth_factor']:.2f}x\")\n",
    "    print(f\"  ‚Ä¢ Efici√™ncia de mem√≥ria: {metrics['memory_efficiency']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nCOMPARA√á√ÉO COM RESNET50:\")\n",
    "    print(f\"  ‚Ä¢ Par√¢metros: {25.6/metrics['parameters_millions']:.1f}x MENOS par√¢metros\")\n",
    "    print(f\"  ‚Ä¢ Compound scaling: Otimiza√ß√£o autom√°tica width/depth/resolution\")\n",
    "    print(f\"  ‚Ä¢ Mobile bottlenecks: Convolu√ß√µes mais eficientes\")\n",
    "    print(f\"  ‚Ä¢ Squeeze-and-excitation: Aten√ß√£o por canal\")\n",
    "    \n",
    "    print(f\"\\nRESULTADOS POR EMO√á√ÉO:\")\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    for emotion in emotion_names:\n",
    "        f1_key = f'{emotion}_f1'\n",
    "        if f1_key in metrics:\n",
    "            print(f\"  ‚Ä¢ {emotion.capitalize()}: F1 = {metrics[f1_key]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nCONCLUS√ÉO:\")\n",
    "    efficiency_vs_resnet = 25.6 / metrics['parameters_millions']\n",
    "    print(f\"  ‚Ä¢ EfficientNet-B0 alcan√ßou {metrics['test_accuracy']*100:.1f}% de acur√°cia\")\n",
    "    print(f\"  ‚Ä¢ Com {efficiency_vs_resnet:.1f}x menos par√¢metros que ResNet50\")\n",
    "    print(f\"  ‚Ä¢ Validando compound scaling como arquitetura superior\")\n",
    "    print(f\"  ‚Ä¢ Ideal para aplica√ß√µes com restri√ß√µes computacionais\")\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "# Executa an√°lise se avalia√ß√£o foi bem-sucedida\n",
    "if 'metrics' in locals() and metrics is not None:\n",
    "    create_efficientnet_comparative_visualizations(history, confusion_matrix_result, metrics, detailed_report)\n",
    "    print(\"EfficientNet: An√°lise comparativa completa finalizada!\")\n",
    "    print(f\"\\nArquivos gerados:\")\n",
    "    print(f\"  ‚Ä¢ M√©tricas EfficientNet: metrics/efficientnet/efficientnet_performance_metrics.csv\")\n",
    "    print(f\"  ‚Ä¢ Compara√ß√£o consolidada: metrics/all_models_comparison.csv\")\n",
    "    print(f\"  ‚Ä¢ Visualiza√ß√µes: plots/efficientnet/efficientnet_comprehensive_analysis_{experiment_id}.png\")\n",
    "    if model_saved:\n",
    "        print(f\"  ‚Ä¢ Modelo: models/efficientnet/weights_efficientnet_{experiment_id}.h5\")\n",
    "else:\n",
    "    print(\"Erro: Avalia√ß√£o EfficientNet n√£o foi executada corretamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
