{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a83eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pipeline completo para executar 3 modelos treinados sequencialmente\n",
    "com visualiza√ß√µes, m√©tricas e salvamento de resultados em pasta 'results'\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import psutil\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, precision_recall_fscore_support\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76140e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURA√á√ïES\n",
    "# ============================================================================\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# CAMINHOS - ADAPTAR CONFORME NECESS√ÅRIO\n",
    "MODELS_PATH = \"../results/augmented_online/EXPW/models/\"\n",
    "RESULTS_PATH = \"../results/cross_data/expw_for_raf_processed\"\n",
    "DATASET_PATH = \"../data/processed/RAF-DB\"  # ‚Üê Dataset base para experimento\n",
    "\n",
    "# Criar diret√≥rios de sa√≠da\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_PATH, \"metrics\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_PATH, \"plots\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_PATH, \"models\"), exist_ok=True)\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    'Raiva': 0, 'Nojo': 1, 'Medo': 2, 'Felicidade': 3,\n",
    "    'Neutro': 4, 'Tristeza': 5, 'Surpresa': 6\n",
    "}\n",
    "\n",
    "# 3 modelos a executar\n",
    "MODELS_TO_LOAD = [\n",
    "    'resnet50_best.pth',\n",
    "    'efficientnet_b0_best.pth',\n",
    "    'vit_b_16_best.pth'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d23408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CLASSES E FUN√á√ïES\n",
    "# ============================================================================\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"Custom dataset para emotion classification com dados PR√â-PROCESSADOS em escala de cinza\"\"\"\n",
    "    \n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images  # [N, 224, 224] - escala de cinza\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]  # [224, 224] - cinza\n",
    "        label = self.labels[idx]  # ‚Üê IMPORTANTE: pegar o label!\n",
    "        \n",
    "       # Manter 1 canal (n√£o converter)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            from PIL import Image\n",
    "            image = Image.fromarray(image, mode='L')  # ‚Üê 'L' = escala de cinza\n",
    "            image = transforms.ToTensor()(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def create_model(model_name):\n",
    "    \"\"\"\n",
    "    Cria modelo base adaptado para entrada em ESCALA DE CINZA (1 canal).\n",
    "    Usa classificadores SIMPLES compat√≠veis com checkpoints salvos.\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        \n",
    "        # Adaptar primeira camada para 1 canal\n",
    "        original_conv1 = model.conv1\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model.conv1.weight.data = original_conv1.weight.data.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        # Classificador simples (compat√≠vel com checkpoint)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, 7)\n",
    "        \n",
    "    elif model_name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Adaptar primeira camada para 1 canal\n",
    "        original_conv = model.features[0][0]\n",
    "        model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        model.features[0][0].weight.data = original_conv.weight.data.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        # Classificador simples (compat√≠vel com checkpoint)\n",
    "        # Apenas substituir a √∫ltima camada do classifier\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_features, 7)\n",
    "        \n",
    "    elif model_name == 'vit_b_16':\n",
    "        model = models.vision_transformer.vit_b_16(\n",
    "            weights=models.ViT_B_16_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "        \n",
    "        # Adaptar primeira camada para 1 canal\n",
    "        original_conv = model.conv_proj\n",
    "        model.conv_proj = nn.Conv2d(1, 768, kernel_size=16, stride=16)\n",
    "        model.conv_proj.weight.data = original_conv.weight.data.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        # Classificador simples (compat√≠vel com checkpoint)\n",
    "        num_features = model.heads.head.in_features\n",
    "        model.heads.head = nn.Linear(num_features, 7)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_checkpoint(model_name, checkpoint_path):\n",
    "    \"\"\"Carrega modelo do checkpoint\"\"\"\n",
    "    print(f\"\\nüîÑ Carregando modelo: {model_name}\")\n",
    "    \n",
    "    model = create_model(model_name)\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"‚ùå Arquivo n√£o encontrado: {checkpoint_path}\")\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    \n",
    "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        metadata = checkpoint.get('metrics', {})\n",
    "        print(f\"‚úì Checkpoint completo carregado\")\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "        metadata = {}\n",
    "        print(f\"‚úì State dict carregado\")\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, metadata\n",
    "\n",
    "\n",
    "def load_dataset_from_folder(directory_path, subset='test'):\n",
    "    \"\"\"\n",
    "    Carrega dataset PR√â-PROCESSADO (j√° em 224x224, escala de cinza).\n",
    "    \n",
    "    Estrutura esperada:\n",
    "    - Simples: dataset/Emo√ß√£o/imagem.jpg\n",
    "    - Split: dataset/train/Emo√ß√£o/imagem.jpg ou dataset/test/Emo√ß√£o/imagem.jpg\n",
    "    \n",
    "    Args:\n",
    "        directory_path: Caminho para dataset\n",
    "        subset: 'test' ou 'train' (usado se houver subdivis√£o)\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    \n",
    "    print(f\"\\nüìÇ Carregando dataset PR√â-PROCESSADO: {directory_path}\")\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"‚ùå Diret√≥rio n√£o encontrado: {directory_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # ===== DETEC√á√ÉO AUTOM√ÅTICA DE ESTRUTURA =====\n",
    "    try:\n",
    "        subdirs = [d for d in os.listdir(directory_path) \n",
    "                   if os.path.isdir(os.path.join(directory_path, d))]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao listar diret√≥rio: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"  Subdiret√≥rios encontrados: {subdirs}\")\n",
    "    \n",
    "    # Verificar se tem train/test\n",
    "    has_train = 'train' in subdirs\n",
    "    has_test = 'test' in subdirs\n",
    "    has_split = has_train or has_test\n",
    "    \n",
    "    if has_split:\n",
    "        print(f\"‚úì Estrutura com split detectada (train={has_train}, test={has_test})\")\n",
    "        base_path = os.path.join(directory_path, subset)\n",
    "        print(f\"  ‚Üí Usando subset: {subset}\")\n",
    "        print(f\"  ‚Üí Caminho base: {base_path}\")\n",
    "        \n",
    "        if not os.path.exists(base_path):\n",
    "            print(f\"‚ùå Subset '{subset}' n√£o encontrado em {directory_path}\")\n",
    "            print(f\"  Caminho esperado: {base_path}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Listar emo√ß√µes dispon√≠veis\n",
    "        emotion_subdirs = [d for d in os.listdir(base_path) \n",
    "                          if os.path.isdir(os.path.join(base_path, d))]\n",
    "        print(f\"  Emo√ß√µes em {subset}: {emotion_subdirs}\")\n",
    "    else:\n",
    "        print(f\"‚úì Estrutura simples detectada (emo√ß√µes diretamente no diret√≥rio)\")\n",
    "        base_path = directory_path\n",
    "        emotion_subdirs = subdirs\n",
    "        print(f\"  Emo√ß√µes encontradas: {emotion_subdirs}\")\n",
    "    \n",
    "    # ===== CARREGAMENTO DE IMAGENS =====\n",
    "    print(f\"\\n  Iniciando carregamento de dados PR√â-PROCESSADOS...\")\n",
    "    \n",
    "    for emotion, label in EMOTION_LABELS.items():\n",
    "        emotion_path = os.path.join(base_path, emotion)\n",
    "        \n",
    "        if not os.path.exists(emotion_path):\n",
    "            print(f\"  ‚ö†  '{emotion}' n√£o encontrado em {emotion_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Buscar imagens\n",
    "        image_files = []\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "            pattern = os.path.join(emotion_path, ext)\n",
    "            image_files.extend(glob.glob(pattern))\n",
    "        \n",
    "        if len(image_files) == 0:\n",
    "            print(f\"  ‚ö†  Nenhuma imagem em {emotion_path}\")\n",
    "            continue\n",
    "        \n",
    "        count = 0\n",
    "        for img_file in image_files:\n",
    "            try:\n",
    "                # 1Ô∏è‚É£ Carregar como ESCALA DE CINZA (1 canal)\n",
    "                img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                # 2Ô∏è‚É£ Garantir dimens√£o correta (224, 224)\n",
    "                if img.shape != (224, 224):\n",
    "                    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "                \n",
    "                # 3Ô∏è‚É£ Converter para float [0, 1] ANTES de adicionar √† lista\n",
    "                img = img.astype(np.float32) / 255.0\n",
    "                \n",
    "                # 4Ô∏è‚É£ Adicionar √† lista\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "                count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        print(f\"  ‚úì {emotion:15s}: {count:4d} imagens carregadas\")\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        print(\"\\n‚ùå Nenhuma imagem carregada!\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"\\n‚úì Total: {len(images)} imagens carregadas com sucesso\")\n",
    "    print(f\"  Formato: [N, 224, 224] - Escala de cinza (1 canal)\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Retorna transforma√ß√µes para imagens PR√â-PROCESSADAS\"\"\"\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        # N√ÉO REDIMENSIONA - j√° est√° 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "    ])\n",
    "    return val_transform\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Avalia modelo e retorna m√©tricas\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    inference_times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            start = time.time()\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            inference_times.append(time.time() - start)\n",
    "            \n",
    "            _, predicted = output.max(1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    f1_macro = f1_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(all_targets, all_preds, average='weighted', zero_division=0)\n",
    "    precision = precision_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_targets, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "    \n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    class_report = classification_report(\n",
    "        all_targets, all_preds,\n",
    "        target_names=emotion_names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'class_report': class_report,\n",
    "        'y_true': np.array(all_targets),\n",
    "        'y_pred': np.array(all_preds),\n",
    "        'avg_inference_time': np.mean(inference_times)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931e83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_plots(model_name, metrics, experiment_id):\n",
    "    \"\"\"\n",
    "    Cria 12 visualiza√ß√µes completas com plots, mem√≥ria, tempo e matriz normalizada\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìä Gerando visualiza√ß√µes para {model_name}...\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(24, 18))\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    \n",
    "    # ===== 1. MATRIZ DE CONFUS√ÉO RAW =====\n",
    "    ax1 = plt.subplot(3, 4, 1)\n",
    "    sns.heatmap(metrics['conf_matrix'], annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax1,\n",
    "                cbar_kws={'label': 'Amostras'})\n",
    "    ax1.set_title(f'{model_name}: Matriz de Confus√£o (Raw)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Classe Verdadeira')\n",
    "    ax1.set_xlabel('Classe Predita')\n",
    "    plt.setp(ax1.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # ===== 2. MATRIZ NORMALIZADA =====\n",
    "    ax2 = plt.subplot(3, 4, 2)\n",
    "    conf_norm = metrics['conf_matrix'].astype('float') / metrics['conf_matrix'].sum(axis=1)[:, np.newaxis]\n",
    "    conf_norm = np.nan_to_num(conf_norm)\n",
    "    sns.heatmap(conf_norm, annot=True, fmt='.3f', cmap='Greens',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax2,\n",
    "                cbar_kws={'label': 'Propor√ß√£o'})\n",
    "    ax2.set_title(f'{model_name}: Matriz Normalizada (Recall)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Classe Verdadeira')\n",
    "    ax2.set_xlabel('Classe Predita')\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # ===== 3. F1-SCORE POR CLASSE =====\n",
    "    ax3 = plt.subplot(3, 4, 3)\n",
    "    f1_scores = [metrics['class_report'][emotion]['f1-score'] for emotion in emotion_names]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(emotion_names)))\n",
    "    bars = ax3.bar(emotion_names, f1_scores, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax3.set_title(f'{model_name}: F1-Score por Emo√ß√£o', fontsize=12, fontweight='bold')\n",
    "    ax3.set_ylabel('F1-Score')\n",
    "    ax3.set_ylim(0, 1)\n",
    "    plt.setp(ax3.get_xticklabels(), rotation=45)\n",
    "    for bar, score in zip(bars, f1_scores):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # ===== 4. PRECISION, RECALL, F1 =====\n",
    "    ax4 = plt.subplot(3, 4, 4)\n",
    "    precision_scores = [metrics['class_report'][emotion]['precision'] for emotion in emotion_names]\n",
    "    recall_scores = [metrics['class_report'][emotion]['recall'] for emotion in emotion_names]\n",
    "    x = np.arange(len(emotion_names))\n",
    "    width = 0.25\n",
    "    ax4.bar(x - width, precision_scores, width, label='Precision', alpha=0.8, color='lightcoral')\n",
    "    ax4.bar(x, recall_scores, width, label='Recall', alpha=0.8, color='lightblue')\n",
    "    ax4.bar(x + width, f1_scores, width, label='F1-Score', alpha=0.8, color='lightgreen')\n",
    "    ax4.set_title(f'{model_name}: M√©tricas por Classe', fontsize=12, fontweight='bold')\n",
    "    ax4.set_ylabel('Score')\n",
    "    ax4.set_xticks(x)\n",
    "    ax4.set_xticklabels(emotion_names, rotation=45)\n",
    "    ax4.legend()\n",
    "    ax4.set_ylim(0, 1)\n",
    "    \n",
    "    # ===== 5. DISTRIBUI√á√ÉO DE CLASSES (TESTE) =====\n",
    "    ax5 = plt.subplot(3, 4, 5)\n",
    "    unique, counts = np.unique(metrics['y_true'], return_counts=True)\n",
    "    class_dist = dict(zip(unique, counts))\n",
    "    test_counts = [class_dist.get(i, 0) for i in range(len(emotion_names))]\n",
    "    colors_dist = plt.cm.Set3(np.linspace(0, 1, len(emotion_names)))\n",
    "    bars = ax5.bar(emotion_names, test_counts, color=colors_dist, alpha=0.8, edgecolor='black')\n",
    "    ax5.set_title(f'{model_name}: Distribui√ß√£o de Classes (Teste)', fontsize=12, fontweight='bold')\n",
    "    ax5.set_ylabel('N√∫mero de Amostras')\n",
    "    plt.setp(ax5.get_xticklabels(), rotation=45)\n",
    "    mean_samples = np.mean(test_counts)\n",
    "    ax5.axhline(y=mean_samples, color='red', linestyle='--', alpha=0.7, label=f'M√©dia: {mean_samples:.0f}')\n",
    "    ax5.legend()\n",
    "    for bar, count in zip(bars, test_counts):\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(test_counts)*0.02,\n",
    "                f'{count}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # ===== 6. CORRELA√á√ÉO AMOSTRAS vs F1 =====\n",
    "    ax6 = plt.subplot(3, 4, 6)\n",
    "    support_counts = [metrics['class_report'][emotion]['support'] for emotion in emotion_names]\n",
    "    ax6.scatter(support_counts, f1_scores, c=support_counts, cmap='viridis', s=100, alpha=0.7, edgecolors='black')\n",
    "    for i, emotion in enumerate(emotion_names):\n",
    "        ax6.annotate(emotion, (support_counts[i], f1_scores[i]), xytext=(5, 5), \n",
    "                    textcoords='offset points', fontsize=8)\n",
    "    z = np.polyfit(support_counts, f1_scores, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax6.plot(support_counts, p(support_counts), \"r--\", alpha=0.8)\n",
    "    correlation = np.corrcoef(support_counts, f1_scores)[0, 1]\n",
    "    ax6.set_title(f'{model_name}: Amostras vs Performance', fontsize=12, fontweight='bold')\n",
    "    ax6.set_xlabel('Suporte (Test)')\n",
    "    ax6.set_ylabel('F1-Score')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    ax6.text(0.05, 0.95, f'Correla√ß√£o: {correlation:.3f}', transform=ax6.transAxes,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), verticalalignment='top')\n",
    "    \n",
    "    # ===== 7. HEATMAP DE ERROS =====\n",
    "    ax7 = plt.subplot(3, 4, 7)\n",
    "    error_matrix = metrics['conf_matrix'].copy()\n",
    "    np.fill_diagonal(error_matrix, 0)\n",
    "    error_norm = error_matrix.astype('float') / metrics['conf_matrix'].sum(axis=1)[:, np.newaxis]\n",
    "    error_norm = np.nan_to_num(error_norm)\n",
    "    sns.heatmap(error_norm, annot=True, fmt='.3f', cmap='Reds',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax7,\n",
    "                cbar_kws={'label': 'Taxa de Erro'})\n",
    "    ax7.set_title(f'{model_name}: Heatmap de Erros', fontsize=12, fontweight='bold')\n",
    "    ax7.set_ylabel('Classe Verdadeira')\n",
    "    ax7.set_xlabel('Classe Predita (Erro)')\n",
    "    plt.setp(ax7.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # ===== 8. MACRO vs WEIGHTED =====\n",
    "    ax8 = plt.subplot(3, 4, 8)\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        metrics['y_true'], metrics['y_pred'], average='weighted', zero_division=0\n",
    "    )\n",
    "    metrics_comparison = {\n",
    "        'Precision': [metrics['precision'], precision_weighted],\n",
    "        'Recall': [metrics['recall'], recall_weighted],\n",
    "        'F1-Score': [metrics['f1_macro'], metrics['f1_weighted']]\n",
    "    }\n",
    "    x = np.arange(len(metrics_comparison))\n",
    "    width = 0.35\n",
    "    macro_vals = [metrics_comparison[m][0] for m in metrics_comparison]\n",
    "    weighted_vals = [metrics_comparison[m][1] for m in metrics_comparison]\n",
    "    ax8.bar(x - width/2, macro_vals, width, label='Macro (Desbalanceado)', alpha=0.8, color='lightcoral')\n",
    "    ax8.bar(x + width/2, weighted_vals, width, label='Weighted (Balanceado)', alpha=0.8, color='lightblue')\n",
    "    ax8.set_title(f'{model_name}: Macro vs Weighted', fontsize=12, fontweight='bold')\n",
    "    ax8.set_ylabel('Score')\n",
    "    ax8.set_xticks(x)\n",
    "    ax8.set_xticklabels(metrics_comparison.keys())\n",
    "    ax8.legend()\n",
    "    ax8.set_ylim(0, 1)\n",
    "    for bars in [ax8.patches[i::len(metrics_comparison)] for i in range(2)]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax8.text(bar.get_x() + bar.get_width()/2, height + 0.01,\n",
    "                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # ===== 9. TEMPO DE INFER√äNCIA =====\n",
    "    ax9 = plt.subplot(3, 4, 9)\n",
    "    time_data = {\n",
    "        'Tempo M√©dio (ms)': metrics['avg_inference_time'] * 1000,\n",
    "        'Throughput (img/s)': 1.0 / metrics['avg_inference_time'] if metrics['avg_inference_time'] > 0 else 0\n",
    "    }\n",
    "    colors_time = ['#1f77b4', '#ff7f0e']\n",
    "    bars = ax9.bar(range(len(time_data)), list(time_data.values()), color=colors_time, alpha=0.8, edgecolor='black')\n",
    "    ax9.set_title(f'{model_name}: Performance de Infer√™ncia', fontsize=12, fontweight='bold')\n",
    "    ax9.set_xticks(range(len(time_data)))\n",
    "    ax9.set_xticklabels(time_data.keys(), rotation=45)\n",
    "    ax9.set_ylabel('Valor')\n",
    "    for bar, (key, val) in zip(bars, time_data.items()):\n",
    "        ax9.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.02,\n",
    "                f'{val:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # ===== 10. RESUMO DE M√âTRICAS =====\n",
    "    ax10 = plt.subplot(3, 4, 10)\n",
    "    ax10.axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "RESUMO - {model_name.upper()}\n",
    "\n",
    "ACUR√ÅCIA E F1:\n",
    "‚Ä¢ Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\n",
    "‚Ä¢ F1-Macro: {metrics['f1_macro']:.4f}\n",
    "‚Ä¢ F1-Weighted: {metrics['f1_weighted']:.4f}\n",
    "\n",
    "PRECIS√ÉO E RECALL:\n",
    "‚Ä¢ Precision: {metrics['precision']:.4f}\n",
    "‚Ä¢ Recall: {metrics['recall']:.4f}\n",
    "\n",
    "INFER√äNCIA:\n",
    "‚Ä¢ Tempo M√©dio: {metrics['avg_inference_time']*1000:.2f} ms\n",
    "‚Ä¢ Throughput: {1.0/metrics['avg_inference_time']:.1f} img/s\n",
    "    \"\"\"\n",
    "    ax10.text(0.05, 0.95, summary_text, fontsize=11, verticalalignment='top',\n",
    "             transform=ax10.transAxes, family='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # ===== 11. PROCESSO (Placeholder - seria do hist√≥rico de treinamento) =====\n",
    "    ax11 = plt.subplot(3, 4, 11)\n",
    "    ax11.text(0.5, 0.5, f'Modelo: {model_name}\\nData: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n\\nDataset: Teste',\n",
    "             ha='center', va='center', fontsize=12, fontweight='bold',\n",
    "             transform=ax11.transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    ax11.axis('off')\n",
    "    \n",
    "    # ===== 12. INFORMA√á√ïES DE SISTEMA =====\n",
    "    ax12 = plt.subplot(3, 4, 12)\n",
    "    ax12.axis('off')\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    system_text = f\"\"\"\n",
    "RECURSOS COMPUTACIONAIS\n",
    "\n",
    "Dispositivo: {DEVICE}\n",
    "CPU: {os.cpu_count()} cores\n",
    "\n",
    "Mem√≥ria:\n",
    "‚Ä¢ Uso Atual: {memory_info.rss / 1024**3:.2f} GB\n",
    "‚Ä¢ RSS: {memory_info.rss / 1024**2:.1f} MB\n",
    "\n",
    "CUDA (se dispon√≠vel):\n",
    "\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        system_text += f\"\"\"‚Ä¢ GPU: {torch.cuda.get_device_name(0)}\n",
    "‚Ä¢ Mem√≥ria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\n",
    "‚Ä¢ Alocada: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\n",
    "\"\"\"\n",
    "    ax12.text(0.05, 0.95, system_text, fontsize=10, verticalalignment='top',\n",
    "             transform=ax12.transAxes, family='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(RESULTS_PATH, 'plots', f'{model_name}_comprehensive_{experiment_id}.png')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì Plot salvo: {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def run_single_model_evaluation(model_file, X_test, y_test):\n",
    "    \"\"\"Executa avalia√ß√£o completa de um modelo\"\"\"\n",
    "    \n",
    "    # Extrair nome do modelo\n",
    "    model_name = model_file.replace('_best.pth', '')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"EXECUTANDO: {model_name.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Carregar modelo\n",
    "    checkpoint_path = os.path.join(MODELS_PATH, model_file)\n",
    "    result = load_model_checkpoint(model_name, checkpoint_path)\n",
    "    \n",
    "    if result is None:\n",
    "        print(f\"‚ùå Falha ao carregar modelo\")\n",
    "        return None\n",
    "    \n",
    "    model, metadata = result\n",
    "    \n",
    "    # 2. Preparar dataset\n",
    "    transform = get_transforms()\n",
    "    dataset = EmotionDataset(X_test, y_test, transform=transform)\n",
    "    test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # 3. Avaliar modelo\n",
    "    print(f\"\\n‚è±Ô∏è  Avaliando modelo...\")\n",
    "    start_time = time.time()\n",
    "    metrics = evaluate_model(model, test_loader)\n",
    "    evaluation_time = time.time() - start_time\n",
    "    metrics['evaluation_time'] = evaluation_time\n",
    "    \n",
    "    # 4. Exibir resultados\n",
    "    print(f\"\\nüìä RESULTADOS PARA {model_name.upper()}:\")\n",
    "    print(f\"  Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
    "    print(f\"  F1-Macro: {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"  F1-Weighted: {metrics['f1_weighted']:.4f}\")\n",
    "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"  Tempo de Infer√™ncia M√©dio: {metrics['avg_inference_time']*1000:.2f} ms\")\n",
    "    print(f\"  Tempo Total de Avalia√ß√£o: {evaluation_time:.2f} s\")\n",
    "    \n",
    "    # 5. Criar visualiza√ß√µes\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    create_comprehensive_plots(model_name, metrics, timestamp)\n",
    "    \n",
    "    # 6. Salvar m√©tricas em CSV\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'model_name': [model_name],\n",
    "        'accuracy': [metrics['accuracy']],\n",
    "        'f1_macro': [metrics['f1_macro']],\n",
    "        'f1_weighted': [metrics['f1_weighted']],\n",
    "        'precision': [metrics['precision']],\n",
    "        'recall': [metrics['recall']],\n",
    "        'avg_inference_time_ms': [metrics['avg_inference_time'] * 1000],\n",
    "        'evaluation_time_s': [evaluation_time],\n",
    "        'timestamp': [timestamp]\n",
    "    })\n",
    "    \n",
    "    csv_path = os.path.join(RESULTS_PATH, 'metrics', f'{model_name}_metrics_{timestamp}.csv')\n",
    "    metrics_df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n‚úì M√©tricas salvas: {csv_path}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff01cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PIPELINE DE AVALIA√á√ÉO DE 3 MODELOS TREINADOS\n",
      "================================================================================\n",
      "Device: cuda\n",
      "Dataset Path: ../data/processed/RAF-DB\n",
      "Models Path: ../results/augmented_online/EXPW/models/\n",
      "Results Path: ../results/cross_data/expw_for_raf_processed\n",
      "\n",
      "================================================================================\n",
      "CARREGANDO DATASET DE TESTE\n",
      "================================================================================\n",
      "\n",
      "üìÇ Carregando dataset PR√â-PROCESSADO: ../data/processed/RAF-DB\n",
      "  Subdiret√≥rios encontrados: ['test', 'train']\n",
      "‚úì Estrutura com split detectada (train=True, test=True)\n",
      "  ‚Üí Usando subset: test\n",
      "  ‚Üí Caminho base: ../data/processed/RAF-DB/test\n",
      "  Emo√ß√µes em test: ['Tristeza', 'Raiva', 'Neutro', 'Surpresa', 'Felicidade', 'Medo', 'Nojo']\n",
      "\n",
      "  Iniciando carregamento de dados PR√â-PROCESSADOS...\n",
      "  ‚úì Raiva          :  162 imagens carregadas\n",
      "  ‚úì Nojo           :  160 imagens carregadas\n",
      "  ‚úì Medo           :   74 imagens carregadas\n",
      "  ‚úì Felicidade     : 1185 imagens carregadas\n",
      "  ‚úì Neutro         :  680 imagens carregadas\n",
      "  ‚úì Tristeza       :  478 imagens carregadas\n",
      "  ‚úì Surpresa       :  329 imagens carregadas\n",
      "\n",
      "‚úì Total: 3068 imagens carregadas com sucesso\n",
      "  Formato: [N, 224, 224] - Escala de cinza (1 canal)\n",
      "\n",
      "================================================================================\n",
      "EXECUTANDO: RESNET50\n",
      "================================================================================\n",
      "\n",
      "üîÑ Carregando modelo: resnet50\n",
      "‚úì Checkpoint completo carregado\n",
      "\n",
      "‚è±Ô∏è  Avaliando modelo...\n",
      "\n",
      "üìä RESULTADOS PARA RESNET50:\n",
      "  Accuracy: 0.2184 (21.84%)\n",
      "  F1-Macro: 0.1511\n",
      "  F1-Weighted: 0.1795\n",
      "  Precision: 0.2139\n",
      "  Recall: 0.1854\n",
      "  Tempo de Infer√™ncia M√©dio: 9.53 ms\n",
      "  Tempo Total de Avalia√ß√£o: 5.25 s\n",
      "\n",
      "üìä Gerando visualiza√ß√µes para resnet50...\n",
      "‚úì Plot salvo: ../results/cross_data/expw_for_raf_processed/plots/resnet50_comprehensive_20251101_183215.png\n",
      "\n",
      "‚úì M√©tricas salvas: ../results/cross_data/expw_for_raf_processed/metrics/resnet50_metrics_20251101_183215.csv\n",
      "\n",
      "================================================================================\n",
      "EXECUTANDO: EFFICIENTNET_B0\n",
      "================================================================================\n",
      "\n",
      "üîÑ Carregando modelo: efficientnet_b0\n",
      "‚úì Checkpoint completo carregado\n",
      "\n",
      "‚è±Ô∏è  Avaliando modelo...\n",
      "\n",
      "üìä RESULTADOS PARA EFFICIENTNET_B0:\n",
      "  Accuracy: 0.1626 (16.26%)\n",
      "  F1-Macro: 0.1282\n",
      "  F1-Weighted: 0.1755\n",
      "  Precision: 0.1508\n",
      "  Recall: 0.1529\n",
      "  Tempo de Infer√™ncia M√©dio: 9.74 ms\n",
      "  Tempo Total de Avalia√ß√£o: 2.53 s\n",
      "\n",
      "üìä Gerando visualiza√ß√µes para efficientnet_b0...\n",
      "‚úì Plot salvo: ../results/cross_data/expw_for_raf_processed/plots/efficientnet_b0_comprehensive_20251101_183221.png\n",
      "\n",
      "‚úì M√©tricas salvas: ../results/cross_data/expw_for_raf_processed/metrics/efficientnet_b0_metrics_20251101_183221.csv\n",
      "\n",
      "================================================================================\n",
      "EXECUTANDO: VIT_B_16\n",
      "================================================================================\n",
      "\n",
      "üîÑ Carregando modelo: vit_b_16\n",
      "‚úì Checkpoint completo carregado\n",
      "\n",
      "‚è±Ô∏è  Avaliando modelo...\n",
      "\n",
      "üìä RESULTADOS PARA VIT_B_16:\n",
      "  Accuracy: 0.2819 (28.19%)\n",
      "  F1-Macro: 0.2245\n",
      "  F1-Weighted: 0.2686\n",
      "  Precision: 0.2602\n",
      "  Recall: 0.2662\n",
      "  Tempo de Infer√™ncia M√©dio: 6.44 ms\n",
      "  Tempo Total de Avalia√ß√£o: 15.21 s\n",
      "\n",
      "üìä Gerando visualiza√ß√µes para vit_b_16...\n",
      "‚úì Plot salvo: ../results/cross_data/expw_for_raf_processed/plots/vit_b_16_comprehensive_20251101_183241.png\n",
      "\n",
      "‚úì M√©tricas salvas: ../results/cross_data/expw_for_raf_processed/metrics/vit_b_16_metrics_20251101_183241.csv\n",
      "\n",
      "================================================================================\n",
      "COMPARA√á√ÉO FINAL DOS 3 MODELOS\n",
      "================================================================================\n",
      "\n",
      "          model  accuracy  f1_macro  f1_weighted  precision   recall  inference_time_ms\n",
      "       resnet50  0.218383  0.151148     0.179452   0.213931 0.185361           9.527336\n",
      "efficientnet_b0  0.162647  0.128191     0.175486   0.150800 0.152861           9.743810\n",
      "       vit_b_16  0.281943  0.224547     0.268569   0.260228 0.266215           6.443717\n",
      "\n",
      "‚úì Compara√ß√£o salva: ../results/cross_data/expw_for_raf_processed/metrics/comparison_20251101_183244.csv\n",
      "‚úì Gr√°fico comparativo salvo: ../results/cross_data/expw_for_raf_processed/plots/comparison_20251101_183244.png\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PIPELINE COMPLETO!\n",
      "================================================================================\n",
      "üìÅ Resultados salvos em: ../results/cross_data/expw_for_raf_processed\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Pipeline principal\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PIPELINE DE AVALIA√á√ÉO DE 3 MODELOS TREINADOS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Dataset Path: {DATASET_PATH}\")\n",
    "    print(f\"Models Path: {MODELS_PATH}\")\n",
    "    print(f\"Results Path: {RESULTS_PATH}\")\n",
    "    \n",
    "    # 1. Carregar dataset UMA VEZ\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CARREGANDO DATASET DE TESTE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X_test, y_test = load_dataset_from_folder(DATASET_PATH, subset=\"test\")\n",
    "    \n",
    "    if X_test is None:\n",
    "        print(\"‚ùå Falha ao carregar dataset\")\n",
    "        return\n",
    "    \n",
    "    # 2. Executar cada modelo sequencialmente\n",
    "    all_results = []\n",
    "    \n",
    "    for model_file in MODELS_TO_LOAD:\n",
    "        metrics = run_single_model_evaluation(model_file, X_test, y_test)\n",
    "        if metrics is not None:\n",
    "            all_results.append({\n",
    "                'model': model_file.replace('_best.pth', ''),\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'f1_macro': metrics['f1_macro'],\n",
    "                'f1_weighted': metrics['f1_weighted'],\n",
    "                'precision': metrics['precision'],\n",
    "                'recall': metrics['recall'],\n",
    "                'inference_time_ms': metrics['avg_inference_time'] * 1000\n",
    "            })\n",
    "    \n",
    "    # 3. Compara√ß√£o final\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARA√á√ÉO FINAL DOS 3 MODELOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if all_results:\n",
    "        df_comparison = pd.DataFrame(all_results)\n",
    "        print(\"\\n\" + df_comparison.to_string(index=False))\n",
    "        \n",
    "        # Salvar tabela de compara√ß√£o\n",
    "        comparison_path = os.path.join(RESULTS_PATH, 'metrics', f'comparison_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv')\n",
    "        df_comparison.to_csv(comparison_path, index=False)\n",
    "        print(f\"\\n‚úì Compara√ß√£o salva: {comparison_path}\")\n",
    "        \n",
    "        # Criar gr√°fico comparativo\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        \n",
    "        metrics_to_plot = ['accuracy', 'f1_macro', 'f1_weighted', 'precision', 'recall', 'inference_time_ms']\n",
    "        for idx, metric in enumerate(metrics_to_plot):\n",
    "            ax = axes.flatten()[idx]\n",
    "            colors = plt.cm.Set3(np.linspace(0, 1, len(df_comparison)))\n",
    "            bars = ax.bar(df_comparison['model'], df_comparison[metric], color=colors, edgecolor='black', alpha=0.8)\n",
    "            ax.set_title(f'{metric.upper()}', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Valor')\n",
    "            plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "            \n",
    "            # Adicionar valores nas barras\n",
    "            for bar, val in zip(bars, df_comparison[metric]):\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.02,\n",
    "                       f'{val:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        comparison_plot_path = os.path.join(RESULTS_PATH, 'plots', f'comparison_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png')\n",
    "        plt.savefig(comparison_plot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úì Gr√°fico comparativo salvo: {comparison_plot_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ PIPELINE COMPLETO!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìÅ Resultados salvos em: {RESULTS_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
