{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df54d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 1: Imports e Configura√ß√£o\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o\n",
    "BASE_PATH = r'../data/raw/RAF-DB/DATASET'\n",
    "OUTPUT_PATH = r'../data/processed/RAF-DB'\n",
    "TARGET_SIZE = (224, 224)\n",
    "LOG_PATH = r'../data/logs'\n",
    "\n",
    "print(\"üîß Configura√ß√£o do Pr√©-processamento\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìÅ Input:  {BASE_PATH}\")\n",
    "print(f\"üìÅ Output: {OUTPUT_PATH}\")\n",
    "print(f\"üìÅ Logs:   {LOG_PATH}\")\n",
    "print(f\"üìê Target Size: {TARGET_SIZE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 2: Verifica√ß√£o de Ambiente\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Verificar instala√ß√µes necess√°rias\n",
    "required_packages = ['cv2', 'mtcnn', 'tensorflow', 'tqdm', 'matplotlib']\n",
    "\n",
    "print(\"üì¶ Verificando pacotes necess√°rios...\")\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "        print(f\"‚úÖ {package} instalado\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package} n√£o encontrado\")\n",
    "        print(f\"   Execute: pip install {package}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 3: Verifica√ß√£o de Caminhos\n",
    "# Verificar se o caminho base existe\n",
    "if not os.path.exists(BASE_PATH):\n",
    "    print(f\"‚ùå ERRO: Caminho base n√£o encontrado: {BASE_PATH}\")\n",
    "    print(f\"\\nüìÇ Estrutura de diret√≥rios esperada:\")\n",
    "    print(\"\"\"\n",
    "    data/\n",
    "    ‚îî‚îÄ‚îÄ raw/\n",
    "        ‚îî‚îÄ‚îÄ RAF-DB/\n",
    "            ‚îú‚îÄ‚îÄ train/\n",
    "            ‚îÇ   ‚îú‚îÄ‚îÄ anger/\n",
    "            ‚îÇ   ‚îú‚îÄ‚îÄ disgust/\n",
    "            ‚îÇ   ‚îú‚îÄ‚îÄ fear/\n",
    "            ‚îÇ   ‚îú‚îÄ‚îÄ happiness/\n",
    "            ‚îÇ   ‚îú‚îÄ‚îÄ neutral/\n",
    "            ‚îÇ   ‚îú‚îÄ‚îÄ sadness/\n",
    "            ‚îÇ   ‚îî‚îÄ‚îÄ surprise/\n",
    "            ‚îî‚îÄ‚îÄ test/\n",
    "                ‚îú‚îÄ‚îÄ anger/\n",
    "                ‚îú‚îÄ‚îÄ disgust/\n",
    "                ‚îú‚îÄ‚îÄ fear/\n",
    "                ‚îú‚îÄ‚îÄ happiness/\n",
    "                ‚îú‚îÄ‚îÄ neutral/\n",
    "                ‚îú‚îÄ‚îÄ sadness/\n",
    "                ‚îî‚îÄ‚îÄ surprise/\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"\\nüîç Procurando por RAF-DB no diret√≥rio atual...\")\n",
    "    found = False\n",
    "    for root, dirs, files in os.walk('.'):\n",
    "        if 'RAF-DB' in root or 'raf-db' in root.lower():\n",
    "            print(f\"  üìÅ Encontrado: {root}\")\n",
    "            found = True\n",
    "    \n",
    "    if not found:\n",
    "        print(\"  ‚ùå Nenhum diret√≥rio RAF-DB encontrado\")\n",
    "else:\n",
    "    print(f\"‚úÖ Caminho base encontrado: {BASE_PATH}\")\n",
    "    \n",
    "    # Criar pastas necess√°rias\n",
    "    os.makedirs(LOG_PATH, exist_ok=True)\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    print(f\"‚úÖ Pastas de sa√≠da criadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c88ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 4: Inicializa√ß√£o do MTCNN\n",
    "# Inicializar o detector\n",
    "detector = None\n",
    "try:\n",
    "    # Tentar inicializa√ß√£o com par√¢metros completos\n",
    "    try:\n",
    "        detector = MTCNN(\n",
    "            min_face_size=20,\n",
    "            scale_factor=0.709,\n",
    "            steps_threshold=[0.6, 0.7, 0.7]\n",
    "        )\n",
    "        print(\"‚úÖ MTCNN inicializado com sucesso (com par√¢metros)\")\n",
    "    except TypeError:\n",
    "        # Fallback: inicializa√ß√£o padr√£o sem par√¢metros\n",
    "        detector = MTCNN()\n",
    "        print(\"‚úÖ MTCNN inicializado com sucesso (par√¢metros padr√£o)\")\n",
    "    \n",
    "    print(\"\\nDetector MTCNN pronto para uso!\")\n",
    "    print(\"  ‚Ä¢ Biblioteca: mtcnn\")\n",
    "    print(\"  ‚Ä¢ Backend: TensorFlow/Keras\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO ao inicializar MTCNN: {e}\")\n",
    "    print(\"\\nüîß Solu√ß√£o:\")\n",
    "    print(\"  1. Desinstale vers√µes conflitantes:\")\n",
    "    print(\"     pip uninstall mtcnn\")\n",
    "    print(\"  2. Instale a vers√£o correta:\")\n",
    "    print(\"     pip install mtcnn\")\n",
    "    print(\"  3. Verifique se o TensorFlow est√° instalado:\")\n",
    "    print(\"     pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e778e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 5: Estrutura de Logging\n",
    "# Estrutura para logging\n",
    "processing_stats = defaultdict(lambda: {\n",
    "    'total': 0,\n",
    "    'processed': 0,\n",
    "    'failed_read': [],\n",
    "    'no_face_detected': [],\n",
    "    'alignment_failed': [],\n",
    "    'crop_failed': [],\n",
    "    'other_errors': []\n",
    "})\n",
    "\n",
    "print(\"üìä Sistema de logging inicializado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 6: Fun√ß√µes Auxiliares\n",
    "def validate_image(img_path):\n",
    "    \"\"\"\n",
    "    Valida se o arquivo √© uma imagem v√°lida.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return False, None\n",
    "        if img.shape[0] < 10 or img.shape[1] < 10:\n",
    "            return False, None\n",
    "        return True, img\n",
    "    except Exception:\n",
    "        return False, None\n",
    "\n",
    "def safe_crop(image, bbox, padding=0.2):\n",
    "    \"\"\"\n",
    "    Recorta face com padding e tratamento de bordas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x, y, w, h = bbox\n",
    "        \n",
    "        # Validar bbox\n",
    "        if w <= 0 or h <= 0:\n",
    "            return None\n",
    "            \n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        # Adicionar padding\n",
    "        pad_w = int(w * padding)\n",
    "        pad_h = int(h * padding)\n",
    "        \n",
    "        # Calcular nova bbox com padding\n",
    "        x1 = max(0, x - pad_w)\n",
    "        y1 = max(0, y - pad_h)\n",
    "        x2 = min(width, x + w + pad_w)\n",
    "        y2 = min(height, y + h + pad_h)\n",
    "        \n",
    "        # Validar coordenadas\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return None\n",
    "            \n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "        \n",
    "        if cropped.size == 0 or cropped.shape[0] < 10 or cropped.shape[1] < 10:\n",
    "            return None\n",
    "        \n",
    "        return cropped\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no crop: {e}\")\n",
    "        return None\n",
    "\n",
    "def align_face_safe(image, left_eye, right_eye, expand_factor=1.2):\n",
    "    \"\"\"\n",
    "    Alinhamento com expans√£o de canvas para evitar cortes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar coordenadas dos olhos\n",
    "        if left_eye[0] == right_eye[0] and left_eye[1] == right_eye[1]:\n",
    "            return image  # Olhos no mesmo ponto, retornar original\n",
    "            \n",
    "        eye_dx = right_eye[0] - left_eye[0]\n",
    "        eye_dy = right_eye[1] - left_eye[1]\n",
    "        angle = np.degrees(np.arctan2(eye_dy, eye_dx))\n",
    "        \n",
    "        # Se o √¢ngulo √© muito pequeno, n√£o rotacionar\n",
    "        if abs(angle) < 1.0:\n",
    "            return image\n",
    "        \n",
    "        (h, w) = image.shape[:2]\n",
    "        \n",
    "        # Limitar o fator de expans√£o\n",
    "        expand_factor = min(expand_factor, 1.5)\n",
    "        \n",
    "        # Expandir canvas para evitar cortes durante rota√ß√£o\n",
    "        new_h = int(h * expand_factor)\n",
    "        new_w = int(w * expand_factor)\n",
    "        \n",
    "        # Criar imagem expandida\n",
    "        if len(image.shape) == 3:\n",
    "            expanded = np.zeros((new_h, new_w, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            expanded = np.zeros((new_h, new_w), dtype=np.uint8)\n",
    "            \n",
    "        y_offset = (new_h - h) // 2\n",
    "        x_offset = (new_w - w) // 2\n",
    "        expanded[y_offset:y_offset+h, x_offset:x_offset+w] = image\n",
    "        \n",
    "        # Centro da imagem expandida\n",
    "        center = (new_w // 2, new_h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        aligned = cv2.warpAffine(expanded, M, (new_w, new_h), \n",
    "                                 flags=cv2.INTER_CUBIC,\n",
    "                                 borderMode=cv2.BORDER_REPLICATE)\n",
    "        \n",
    "        return aligned\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no alinhamento: {e}\")\n",
    "        return image\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes auxiliares carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad607d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 7: Fun√ß√£o Principal de Processamento\n",
    "def process_with_fallback(img_path, output_path, emotion, split):\n",
    "    \"\"\"\n",
    "    Processa imagem com m√∫ltiplas estrat√©gias de fallback.\n",
    "    \"\"\"\n",
    "    stats_key = f\"{split}/{emotion}\"\n",
    "    stats = processing_stats[stats_key]\n",
    "    stats['total'] += 1\n",
    "    \n",
    "    # Validar e ler imagem\n",
    "    is_valid, img = validate_image(img_path)\n",
    "    if not is_valid:\n",
    "        stats['failed_read'].append(os.path.basename(img_path))\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Estrat√©gia 1: Detec√ß√£o padr√£o\n",
    "        results = detector.detect_faces(img)\n",
    "        \n",
    "        # Estrat√©gia 2: Se falhar, tentar com imagem equalizada\n",
    "        if not results and len(img.shape) == 3:\n",
    "            gray_temp = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            equalized = cv2.equalizeHist(gray_temp)\n",
    "            img_eq = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)\n",
    "            results = detector.detect_faces(img_eq)\n",
    "            if results:\n",
    "                img = img_eq  # Usar imagem equalizada\n",
    "            \n",
    "        # Estrat√©gia 3: Se ainda falhar, tentar com CLAHE\n",
    "        if not results and len(img.shape) == 3:\n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "            l_clahe = clahe.apply(l)\n",
    "            lab_clahe = cv2.merge([l_clahe, a, b])\n",
    "            img_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "            results = detector.detect_faces(img_clahe)\n",
    "            if results:\n",
    "                img = img_clahe\n",
    "        \n",
    "        if not results:\n",
    "            stats['no_face_detected'].append(os.path.basename(img_path))\n",
    "            \n",
    "            # Fallback: salvar crop central\n",
    "            h, w = img.shape[:2]\n",
    "            center_size = min(h, w) // 2\n",
    "            y_start = (h - center_size) // 2\n",
    "            x_start = (w - center_size) // 2\n",
    "            center_crop = img[y_start:y_start+center_size, x_start:x_start+center_size]\n",
    "            \n",
    "            if center_crop.size > 0:\n",
    "                resized = cv2.resize(center_crop, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "                if len(resized.shape) == 3:\n",
    "                    gray_face = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "                else:\n",
    "                    gray_face = resized\n",
    "                cv2.imwrite(output_path, gray_face)\n",
    "                stats['processed'] += 1\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        # Processar com detec√ß√£o bem-sucedida\n",
    "        face_data = results[0]\n",
    "        \n",
    "        # Verificar se tem keypoints para alinhamento\n",
    "        if 'keypoints' in face_data:\n",
    "            keypoints = face_data['keypoints']\n",
    "            if 'left_eye' in keypoints and 'right_eye' in keypoints:\n",
    "                left_eye = keypoints['left_eye']\n",
    "                right_eye = keypoints['right_eye']\n",
    "                \n",
    "                # Alinhamento seguro\n",
    "                aligned_img = align_face_safe(img, left_eye, right_eye)\n",
    "                \n",
    "                # Re-detectar na imagem alinhada\n",
    "                results_aligned = detector.detect_faces(aligned_img)\n",
    "                \n",
    "                if results_aligned:\n",
    "                    face_img = safe_crop(aligned_img, results_aligned[0]['box'])\n",
    "                else:\n",
    "                    face_img = safe_crop(img, face_data['box'])\n",
    "            else:\n",
    "                face_img = safe_crop(img, face_data['box'])\n",
    "        else:\n",
    "            face_img = safe_crop(img, face_data['box'])\n",
    "        \n",
    "        if face_img is None:\n",
    "            stats['crop_failed'].append(os.path.basename(img_path))\n",
    "            return False\n",
    "        \n",
    "        # Redimensionar e converter para escala de cinza\n",
    "        resized = cv2.resize(face_img, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        if len(resized.shape) == 3:\n",
    "            gray_face = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray_face = resized\n",
    "        \n",
    "        # Salvar imagem processada\n",
    "        success = cv2.imwrite(output_path, gray_face)\n",
    "        if success:\n",
    "            stats['processed'] += 1\n",
    "            return True\n",
    "        else:\n",
    "            stats['other_errors'].append({\n",
    "                'file': os.path.basename(img_path),\n",
    "                'error': 'Falha ao salvar imagem'\n",
    "            })\n",
    "            return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        stats['other_errors'].append({\n",
    "            'file': os.path.basename(img_path),\n",
    "            'error': str(e),\n",
    "            'traceback': traceback.format_exc()\n",
    "        })\n",
    "        return False\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de processamento carregada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 8: An√°lise da Estrutura do Dataset\n",
    "print(\"=\"*60)\n",
    "print(\"üìä AN√ÅLISE DA ESTRUTURA DO DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset_info = {}\n",
    "\n",
    "# Verificar estrutura esperada\n",
    "for split in ['train', 'test']:\n",
    "    split_path = os.path.join(BASE_PATH, split)\n",
    "    if os.path.exists(split_path):\n",
    "        emotions = [d for d in os.listdir(split_path) \n",
    "                   if os.path.isdir(os.path.join(split_path, d))]\n",
    "        \n",
    "        dataset_info[split] = {}\n",
    "        print(f\"\\n‚úÖ {split.upper()}: {len(emotions)} emo√ß√µes encontradas\")\n",
    "        \n",
    "        total_split = 0\n",
    "        for emotion in emotions:\n",
    "            emotion_path = os.path.join(split_path, emotion)\n",
    "            n_images = len([f for f in os.listdir(emotion_path) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "            dataset_info[split][emotion] = n_images\n",
    "            total_split += n_images\n",
    "            print(f\"   ‚Ä¢ {emotion:12s}: {n_images:6d} imagens\")\n",
    "        \n",
    "        print(f\"   {'‚îÄ'*30}\")\n",
    "        print(f\"   {'TOTAL':12s}: {total_split:6d} imagens\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå {split.upper()}: pasta n√£o encontrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626fc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 9: Visualiza√ß√£o da Distribui√ß√£o (Opcional)\n",
    "if dataset_info:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(dataset_info), figsize=(14, 6))\n",
    "    if len(dataset_info) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, 7))\n",
    "    \n",
    "    for idx, (split, emotions_data) in enumerate(dataset_info.items()):\n",
    "        ax = axes[idx]\n",
    "        emotions = list(emotions_data.keys())\n",
    "        counts = list(emotions_data.values())\n",
    "        \n",
    "        bars = ax.bar(emotions, counts, color=colors)\n",
    "        ax.set_title(f'{split.upper()} Set Distribution')\n",
    "        ax.set_xlabel('Emotion')\n",
    "        ax.set_ylabel('Number of Images')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for bar, count in zip(bars, counts):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{count}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.suptitle('RAF-DB Dataset Distribution', fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a401dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 10: Processamento Principal\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ INICIANDO PROCESSAMENTO...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not os.path.exists(BASE_PATH):\n",
    "    print(\"‚ö†Ô∏è N√£o √© poss√≠vel processar - caminho base n√£o existe\")\n",
    "else:\n",
    "    # Processar imagens\n",
    "    for split in ['train', 'test']:\n",
    "        input_split_path = os.path.join(BASE_PATH, split)\n",
    "        output_split_path = os.path.join(OUTPUT_PATH, split)\n",
    "        \n",
    "        if not os.path.exists(input_split_path):\n",
    "            print(f\"\\n‚ö†Ô∏è  Pulando {split}: pasta n√£o encontrada\")\n",
    "            continue\n",
    "        \n",
    "        emotions = [d for d in os.listdir(input_split_path) \n",
    "                    if os.path.isdir(os.path.join(input_split_path, d))]\n",
    "        \n",
    "        print(f\"\\nüìÇ Processando {split}...\")\n",
    "        \n",
    "        # Usar tqdm notebook para melhor visualiza√ß√£o\n",
    "        from tqdm.notebook import tqdm as tqdm_notebook\n",
    "        \n",
    "        for emotion in tqdm_notebook(emotions, desc=f\"{split}\"):\n",
    "            input_emotion_path = os.path.join(input_split_path, emotion)\n",
    "            output_emotion_path = os.path.join(output_split_path, emotion)\n",
    "            os.makedirs(output_emotion_path, exist_ok=True)\n",
    "            \n",
    "            images = [f for f in os.listdir(input_emotion_path) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "            \n",
    "            # Processar com sub-progress bar\n",
    "            for image_name in tqdm_notebook(images, desc=f\"  {emotion}\", leave=False):\n",
    "                input_path = os.path.join(input_emotion_path, image_name)\n",
    "                output_path = os.path.join(output_emotion_path, image_name)\n",
    "                \n",
    "                # Pular se j√° foi processada\n",
    "                if os.path.exists(output_path):\n",
    "                    continue\n",
    "                    \n",
    "                process_with_fallback(input_path, output_path, emotion, split)\n",
    "    \n",
    "    print(\"\\n‚úÖ Processamento conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 11: Salvar Estat√≠sticas\n",
    "# Converter defaultdict para dict regular para serializa√ß√£o\n",
    "stats_to_save = {}\n",
    "for key, value in processing_stats.items():\n",
    "    stats_to_save[key] = dict(value)\n",
    "\n",
    "# Salvar estat√≠sticas em JSON\n",
    "stats_file = os.path.join(LOG_PATH, 'raf_db_preprocessing_stats.json')\n",
    "with open(stats_file, 'w') as f:\n",
    "    json.dump(stats_to_save, f, indent=2, default=str)\n",
    "\n",
    "print(f\"üíæ Estat√≠sticas salvas em: {stats_file}\")\n",
    "\n",
    "# Tamb√©m salvar um CSV para an√°lise\n",
    "import pandas as pd\n",
    "\n",
    "stats_summary = []\n",
    "for key, stats in processing_stats.items():\n",
    "    split, emotion = key.split('/')\n",
    "    stats_summary.append({\n",
    "        'split': split,\n",
    "        'emotion': emotion,\n",
    "        'total': stats['total'],\n",
    "        'processed': stats['processed'],\n",
    "        'failed_read': len(stats['failed_read']),\n",
    "        'no_face': len(stats['no_face_detected']),\n",
    "        'crop_failed': len(stats['crop_failed']),\n",
    "        'other_errors': len(stats['other_errors'])\n",
    "    })\n",
    "\n",
    "if stats_summary:\n",
    "    df_stats = pd.DataFrame(stats_summary)\n",
    "    csv_file = os.path.join(LOG_PATH, 'raf_db_preprocessing_summary.csv')\n",
    "    df_stats.to_csv(csv_file, index=False)\n",
    "    print(f\"üìä Sum√°rio salvo em: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 12: Relat√≥rio Final Detalhado\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RELAT√ìRIO DE PROCESSAMENTO DETALHADO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_images = 0\n",
    "total_processed = 0\n",
    "total_failures = defaultdict(int)\n",
    "\n",
    "# Criar DataFrame para visualiza√ß√£o\n",
    "results_data = []\n",
    "\n",
    "for key, stats in processing_stats.items():\n",
    "    if stats['total'] == 0:\n",
    "        continue\n",
    "        \n",
    "    split, emotion = key.split('/')\n",
    "    total = stats['total']\n",
    "    processed = stats['processed']\n",
    "    \n",
    "    success_rate = (processed/total*100) if total > 0 else 0\n",
    "    status = \"‚úÖ\" if success_rate > 90 else \"‚ö†Ô∏è\" if success_rate > 70 else \"‚ùå\"\n",
    "    \n",
    "    results_data.append({\n",
    "        'Split': split,\n",
    "        'Emotion': emotion,\n",
    "        'Status': status,\n",
    "        'Total': total,\n",
    "        'Processed': processed,\n",
    "        'Success Rate': f\"{success_rate:.1f}%\",\n",
    "        'Failed Read': len(stats['failed_read']),\n",
    "        'No Face': len(stats['no_face_detected']),\n",
    "        'Crop Failed': len(stats['crop_failed']),\n",
    "        'Other Errors': len(stats['other_errors'])\n",
    "    })\n",
    "    \n",
    "    # Acumular totais\n",
    "    total_images += total\n",
    "    total_processed += processed\n",
    "    \n",
    "    if stats['failed_read']:\n",
    "        total_failures['failed_read'] += len(stats['failed_read'])\n",
    "    if stats['no_face_detected']:\n",
    "        total_failures['no_face'] += len(stats['no_face_detected'])\n",
    "    if stats['crop_failed']:\n",
    "        total_failures['crop'] += len(stats['crop_failed'])\n",
    "    if stats['other_errors']:\n",
    "        total_failures['other'] += len(stats['other_errors'])\n",
    "\n",
    "# Mostrar tabela de resultados\n",
    "if results_data:\n",
    "    df_results = pd.DataFrame(results_data)\n",
    "    display(df_results.style.set_properties(**{'text-align': 'center'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2318b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 13: Resumo Geral e Gr√°ficos\n",
    "if total_images > 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìà RESUMO GERAL\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total de imagens: {total_images}\")\n",
    "    print(f\"‚úÖ Processadas: {total_processed} ({total_processed/total_images*100:.1f}%)\")\n",
    "    print(f\"‚ùå Perdidas: {total_images - total_processed} ({(total_images-total_processed)/total_images*100:.1f}%)\")\n",
    "    \n",
    "    # Gr√°fico de pizza para causas de falha\n",
    "    if total_failures:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Gr√°fico 1: Sucesso vs Falha\n",
    "        success_data = [total_processed, total_images - total_processed]\n",
    "        success_labels = ['Processadas', 'Perdidas']\n",
    "        colors1 = ['#2ecc71', '#e74c3c']\n",
    "        \n",
    "        ax1.pie(success_data, labels=success_labels, colors=colors1, \n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "        ax1.set_title('Taxa de Sucesso do Processamento')\n",
    "        \n",
    "        # Gr√°fico 2: Distribui√ß√£o de Falhas\n",
    "        if sum(total_failures.values()) > 0:\n",
    "            failure_values = list(total_failures.values())\n",
    "            failure_labels = list(total_failures.keys())\n",
    "            colors2 = plt.cm.Set3(np.linspace(0, 1, len(failure_labels)))\n",
    "            \n",
    "            ax2.pie(failure_values, labels=failure_labels, colors=colors2, \n",
    "                    autopct='%1.1f%%', startangle=90)\n",
    "            ax2.set_title('Distribui√ß√£o das Causas de Falha')\n",
    "        \n",
    "        plt.suptitle('An√°lise do Processamento RAF-DB', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nüìâ Principais causas de perda:\")\n",
    "        for cause, count in sorted(total_failures.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"   ‚Ä¢ {cause}: {count} ({count/total_images*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 14: Visualiza√ß√£o de Exemplos Processados (Opcional)\n",
    "def show_processing_examples(n_examples=5):\n",
    "    \"\"\"\n",
    "    Mostra exemplos de imagens antes e depois do processamento\n",
    "    \"\"\"\n",
    "    print(\"üñºÔ∏è Exemplos de Processamento\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    processed_examples = []\n",
    "    \n",
    "    # Buscar exemplos processados\n",
    "    for split in ['train', 'test']:\n",
    "        output_split_path = os.path.join(OUTPUT_PATH, split)\n",
    "        if not os.path.exists(output_split_path):\n",
    "            continue\n",
    "            \n",
    "        for emotion in os.listdir(output_split_path):\n",
    "            emotion_path = os.path.join(output_split_path, emotion)\n",
    "            if not os.path.isdir(emotion_path):\n",
    "                continue\n",
    "                \n",
    "            for img_file in os.listdir(emotion_path)[:2]:  # Pegar 2 de cada emo√ß√£o\n",
    "                if img_file.lower().endswith(('.jpg', '.png')):\n",
    "                    processed_examples.append({\n",
    "                        'path': os.path.join(emotion_path, img_file),\n",
    "                        'emotion': emotion,\n",
    "                        'split': split\n",
    "                    })\n",
    "                    \n",
    "                if len(processed_examples) >= n_examples:\n",
    "                    break\n",
    "            \n",
    "            if len(processed_examples) >= n_examples:\n",
    "                break\n",
    "    \n",
    "    # Mostrar exemplos\n",
    "    if processed_examples:\n",
    "        fig, axes = plt.subplots(1, min(n_examples, len(processed_examples)), \n",
    "                                 figsize=(15, 4))\n",
    "        if len(processed_examples) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, example in enumerate(processed_examples[:n_examples]):\n",
    "            img = cv2.imread(example['path'], cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                axes[idx].imshow(img, cmap='gray')\n",
    "                axes[idx].set_title(f\"{example['emotion']}\\n({example['split']})\")\n",
    "                axes[idx].axis('off')\n",
    "        \n",
    "        plt.suptitle('Exemplos de Faces Processadas (224x224, Grayscale)', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum exemplo processado encontrado\")\n",
    "\n",
    "# Chamar a fun√ß√£o\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    show_processing_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fde3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 15: An√°lise de Qualidade (Opcional)\n",
    "def analyze_processing_quality():\n",
    "    \"\"\"\n",
    "    Analisa a qualidade das imagens processadas\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç An√°lise de Qualidade\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    quality_metrics = []\n",
    "    \n",
    "    for split in ['train', 'test']:\n",
    "        output_split_path = os.path.join(OUTPUT_PATH, split)\n",
    "        if not os.path.exists(output_split_path):\n",
    "            continue\n",
    "        \n",
    "        for emotion in os.listdir(output_split_path):\n",
    "            emotion_path = os.path.join(output_split_path, emotion)\n",
    "            if not os.path.isdir(emotion_path):\n",
    "                continue\n",
    "            \n",
    "            # Amostrar algumas imagens para an√°lise\n",
    "            sample_images = [f for f in os.listdir(emotion_path) \n",
    "                           if f.lower().endswith(('.jpg', '.png'))][:10]\n",
    "            \n",
    "            for img_file in sample_images:\n",
    "                img_path = os.path.join(emotion_path, img_file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                \n",
    "                if img is not None:\n",
    "                    # Calcular m√©tricas\n",
    "                    quality_metrics.append({\n",
    "                        'split': split,\n",
    "                        'emotion': emotion,\n",
    "                        'brightness': np.mean(img),\n",
    "                        'contrast': np.std(img),\n",
    "                        'sharpness': cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "                    })\n",
    "    \n",
    "    if quality_metrics:\n",
    "        df_quality = pd.DataFrame(quality_metrics)\n",
    "        \n",
    "        # Estat√≠sticas gerais\n",
    "        print(\"\\nüìä M√©tricas de Qualidade (M√©dia):\")\n",
    "        print(f\"  ‚Ä¢ Brilho:    {df_quality['brightness'].mean():.2f} ¬± {df_quality['brightness'].std():.2f}\")\n",
    "        print(f\"  ‚Ä¢ Contraste: {df_quality['contrast'].mean():.2f} ¬± {df_quality['contrast'].std():.2f}\")\n",
    "        print(f\"  ‚Ä¢ Nitidez:   {df_quality['sharpness'].mean():.2f} ¬± {df_quality['sharpness'].std():.2f}\")\n",
    "        \n",
    "        # Gr√°ficos de distribui√ß√£o\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        axes[0].hist(df_quality['brightness'], bins=20, color='skyblue', edgecolor='black')\n",
    "        axes[0].set_title('Distribui√ß√£o de Brilho')\n",
    "        axes[0].set_xlabel('Brilho M√©dio')\n",
    "        \n",
    "        axes[1].hist(df_quality['contrast'], bins=20, color='lightcoral', edgecolor='black')\n",
    "        axes[1].set_title('Distribui√ß√£o de Contraste')\n",
    "        axes[1].set_xlabel('Desvio Padr√£o')\n",
    "        \n",
    "        axes[2].hist(df_quality['sharpness'], bins=20, color='lightgreen', edgecolor='black')\n",
    "        axes[2].set_title('Distribui√ß√£o de Nitidez')\n",
    "        axes[2].set_xlabel('Vari√¢ncia do Laplaciano')\n",
    "        \n",
    "        plt.suptitle('An√°lise de Qualidade das Imagens Processadas', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhuma imagem processada para an√°lise\")\n",
    "\n",
    "# Executar an√°lise\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    analyze_processing_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ebb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 16: Conclus√£o\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ú® PROCESSAMENTO FINALIZADO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if os.path.exists(LOG_PATH):\n",
    "    print(f\"\\nüìÅ Arquivos gerados:\")\n",
    "    print(f\"   ‚Ä¢ Logs: {LOG_PATH}\")\n",
    "    \n",
    "    log_files = [f for f in os.listdir(LOG_PATH) if f.endswith(('.json', '.csv'))]\n",
    "    for log_file in log_files:\n",
    "        file_path = os.path.join(LOG_PATH, log_file)\n",
    "        file_size = os.path.getsize(file_path) / 1024  # KB\n",
    "        print(f\"     - {log_file} ({file_size:.1f} KB)\")\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    print(f\"\\n   ‚Ä¢ Imagens processadas: {OUTPUT_PATH}\")\n",
    "    \n",
    "    total_processed_images = 0\n",
    "    for split in ['train', 'test']:\n",
    "        split_path = os.path.join(OUTPUT_PATH, split)\n",
    "        if os.path.exists(split_path):\n",
    "            for emotion in os.listdir(split_path):\n",
    "                emotion_path = os.path.join(split_path, emotion)\n",
    "                if os.path.isdir(emotion_path):\n",
    "                    n_images = len([f for f in os.listdir(emotion_path) \n",
    "                                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                    total_processed_images += n_images\n",
    "    \n",
    "    print(f\"     - Total: {total_processed_images} imagens processadas\")\n",
    "    \n",
    "    # Calcular espa√ßo em disco\n",
    "    total_size = 0\n",
    "    for root, dirs, files in os.walk(OUTPUT_PATH):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "    \n",
    "    total_size_mb = total_size / (1024 * 1024)\n",
    "    print(f\"     - Espa√ßo utilizado: {total_size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\nüìù Pr√≥ximos passos:\")\n",
    "print(\"   1. Revisar os logs em:\", LOG_PATH)\n",
    "print(\"   2. Verificar estat√≠sticas no CSV gerado\")\n",
    "print(\"   3. Validar qualidade das imagens processadas\")\n",
    "print(\"   4. Iniciar treinamento do modelo\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Notebook conclu√≠do com sucesso!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
