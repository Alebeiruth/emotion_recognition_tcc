{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75afafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "TREINAMENTO BASELINE - DATASET PR√â-PROCESSADO (SEM AUGMENTATION)\n",
    "=============================================================================\n",
    "Pipeline de treinamento para dataset processado:\n",
    "1. Carrega dataset EXPW\n",
    "2. N√ÉO aplica augmentation (dados j√° processados)\n",
    "3. Treina m√∫ltiplos modelos: ResNet50, EfficientNet-B0, EfficientViT\n",
    "4. Early stopping para evitar overfitting\n",
    "5. Monitoramento de tempo e mem√≥ria\n",
    "6. Salva m√©tricas completas + matriz normalizada + modelo .pth\n",
    "\n",
    "ESTRAT√âGIA BASELINE:\n",
    "- Dataset: Processado e n√£o balanceado\n",
    "- Modelos: 3 arquiteturas diferentes\n",
    "- M√©tricas: Completas (Acc, F1, Precision, Recall, por classe)\n",
    "- Monitoramento: Tempo e mem√≥ria (CPU/GPU)\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08af26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TREINAMENTO BASELINE - DATASET PR√â-PROCESSADO (SEM AUGMENTATION)\n",
      "================================================================================\n",
      "Dispositivo: cuda\n",
      "Dataset: ../data/processed/EXPW\n",
      "√âpocas m√°ximas: 100\n",
      "Batch size: 64\n",
      "Early Stopping: Patience=15\n",
      "Augmentation: N√ÉO (dados j√° processados)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURA√á√ïES\n",
    "# =============================================================================\n",
    "\n",
    "# Dispositivo\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Caminhos\n",
    "DATASET_PATH = r\"../data/processed/EXPW\"\n",
    "RESULTS_PATH = r\"../results/baseline/EXPW\"\n",
    "MODELS_PATH = os.path.join(RESULTS_PATH, \"models\")\n",
    "METRICS_PATH = os.path.join(RESULTS_PATH, \"metrics\")\n",
    "PLOTS_PATH = os.path.join(RESULTS_PATH, \"plots\")\n",
    "\n",
    "# Cria√ß√£o de diret√≥rios\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(METRICS_PATH, exist_ok=True)\n",
    "os.makedirs(PLOTS_PATH, exist_ok=True)\n",
    "\n",
    "# Par√¢metros de Treinamento\n",
    "EPOCHS = 100\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Early Stopping\n",
    "EARLY_STOP_PATIENCE = 15\n",
    "EARLY_STOP_MIN_DELTA = 0.001\n",
    "\n",
    "# Pesos para m√©tricas combinadas\n",
    "F1_WEIGHT = 0.6\n",
    "ACC_WEIGHT = 0.4\n",
    "\n",
    "# Mapeamento de classes\n",
    "EMOTION_LABELS = {\n",
    "    'Raiva': 0, 'Nojo': 1, 'Medo': 2, 'Felicidade': 3,\n",
    "    'Neutro': 4, 'Tristeza': 5, 'Surpresa': 6\n",
    "}\n",
    "\n",
    "# Seed para reprodutibilidade\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TREINAMENTO BASELINE - DATASET PR√â-PROCESSADO (SEM AUGMENTATION)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Dispositivo: {DEVICE}\")\n",
    "print(f\"Dataset: {DATASET_PATH}\")\n",
    "print(f\"√âpocas m√°ximas: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Early Stopping: Patience={EARLY_STOP_PATIENCE}\")\n",
    "print(f\"Augmentation: N√ÉO (dados j√° processados)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dada5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSE DE MONITORAMENTO\n",
    "class ResourceMonitor:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.peak_memory_mb = 0\n",
    "        self.initial_memory_mb = 0\n",
    "        self.training_time = 0\n",
    "        self.process = psutil.Process()\n",
    "        self.peak_gpu_memory_mb = 0\n",
    "        self.initial_gpu_memory_mb = 0\n",
    "        self.epoch_times = []\n",
    "\n",
    "    def record_epoch_time(self, seconds: float):\n",
    "        # guarda o tempo de √©poca\n",
    "        self.epoch_times.append(float(seconds))\n",
    "\n",
    "    def get_epoch_time_stats(self):\n",
    "        import numpy as np\n",
    "        if not self.epoch_times:\n",
    "            return {\"mean\": None, \"std\": None, \"n\": 0}\n",
    "        arr = np.array(self.epoch_times, dtype=float)\n",
    "        return {\"mean\": float(arr.mean()), \"std\": float(arr.std()), \"n\": int(arr.size)}\n",
    "        \n",
    "    def start_monitoring(self):\n",
    "        self.start_time = time.time()\n",
    "        self.initial_memory_mb = self._get_memory_usage()\n",
    "        self.peak_memory_mb = self.initial_memory_mb\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.initial_gpu_memory_mb = torch.cuda.memory_allocated() / 1024**2\n",
    "            self.peak_gpu_memory_mb = self.initial_gpu_memory_mb\n",
    "        \n",
    "        print(f\"\\nüîç Iniciando monitoramento: {self.model_name}\")\n",
    "        print(f\"  ‚Ä¢ Initial RAM: {self.initial_memory_mb:.2f} MB\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"  ‚Ä¢ Initial GPU: {self.initial_gpu_memory_mb:.2f} MB\")\n",
    "        \n",
    "    def _get_memory_usage(self):\n",
    "        return self.process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "    def update_peak_memory(self):\n",
    "        current_memory = self._get_memory_usage()\n",
    "        if current_memory > self.peak_memory_mb:\n",
    "            self.peak_memory_mb = current_memory\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            current_gpu = torch.cuda.max_memory_allocated() / 1024**2\n",
    "            if current_gpu > self.peak_gpu_memory_mb:\n",
    "                self.peak_gpu_memory_mb = current_gpu\n",
    "            \n",
    "    def end_monitoring(self):\n",
    "        self.end_time = time.time()\n",
    "        self.training_time = self.end_time - self.start_time\n",
    "        final_memory_mb = self._get_memory_usage()\n",
    "        memory_increase = final_memory_mb - self.initial_memory_mb\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"MONITORING REPORT: {self.model_name.upper()}\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total training time: {timedelta(seconds=int(self.training_time))}\")\n",
    "        print(f\"Initial RAM: {self.initial_memory_mb:.2f} MB\")\n",
    "        print(f\"Final RAM: {final_memory_mb:.2f} MB\")\n",
    "        print(f\"Peak RAM: {self.peak_memory_mb:.2f} MB\")\n",
    "        print(f\"Memory increase: {memory_increase:.2f} MB\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            final_gpu = torch.cuda.memory_allocated() / 1024**2\n",
    "            print(f\"Peak GPU Memory: {self.peak_gpu_memory_mb:.2f} MB\")\n",
    "            print(f\"Final GPU Memory: {final_gpu:.2f} MB\")\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return {\n",
    "            'training_time_seconds': self.training_time,\n",
    "            'initial_memory_mb': self.initial_memory_mb,\n",
    "            'final_memory_mb': final_memory_mb,\n",
    "            'peak_memory_mb': self.peak_memory_mb,\n",
    "            'memory_increase_mb': memory_increase,\n",
    "            'peak_gpu_memory_mb': self.peak_gpu_memory_mb if torch.cuda.is_available() else 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404305d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe Early Stopping configurada\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLASSE DE EARLY STOPPING\n",
    "# =============================================================================\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early Stopping para interromper o treinamento quando a m√©trica de valida√ß√£o\n",
    "    n√£o melhora por um n√∫mero espec√≠fico de √©pocas (patience).\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.0, mode='max', verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): N√∫mero de √©pocas sem melhoria antes de parar\n",
    "            min_delta (float): Mudan√ßa m√≠nima para considerar melhoria\n",
    "            mode (str): 'max' para m√©tricas que devem aumentar (F1, acc),\n",
    "                       'min' para m√©tricas que devem diminuir (loss)\n",
    "            verbose (bool): Se True, imprime mensagens\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_score_min = np.inf if mode == 'min' else -np.inf\n",
    "        \n",
    "    def __call__(self, val_score):\n",
    "        \"\"\"\n",
    "        Verifica se deve parar o treinamento\n",
    "        \n",
    "        Args:\n",
    "            val_score (float): M√©trica de valida√ß√£o atual\n",
    "            \n",
    "        Returns:\n",
    "            bool: True se deve parar o treinamento\n",
    "        \"\"\"\n",
    "        if self.mode == 'max':\n",
    "            score = val_score\n",
    "        else:\n",
    "            score = -val_score\n",
    "            \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.val_score_min = val_score\n",
    "            if self.verbose:\n",
    "                print(f'Early Stopping: Baseline estabelecida: {val_score:.4f}')\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'Early Stopping: Sem melhoria ({self.counter}/{self.patience})')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(f'Early Stopping: Treinamento interrompido ap√≥s {self.patience} √©pocas sem melhoria')\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                improvement = val_score - self.val_score_min\n",
    "                print(f'Early Stopping: Melhoria detectada ({val_score:.4f}, Delta={improvement:+.4f})')\n",
    "            self.best_score = score\n",
    "            self.val_score_min = val_score\n",
    "            self.counter = 0\n",
    "            \n",
    "        return self.early_stop\n",
    "\n",
    "print(\"Classe Early Stopping configurada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f10f2ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe Dataset configurada\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATASET CUSTOMIZADO (SEM AUGMENTATION)\n",
    "# =============================================================================\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para reconhecimento de emo√ß√µes.\n",
    "    Apenas normaliza para uso com modelos pr√©-treinados.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, split='train'):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Carregar todos os caminhos de imagem e r√≥tulos\n",
    "        for class_name, class_idx in EMOTION_LABELS.items():\n",
    "            class_path = os.path.join(self.root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_name in os.listdir(class_path):\n",
    "                    if img_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                        self.image_paths.append(os.path.join(class_path, img_name))\n",
    "                        self.labels.append(class_idx)\n",
    "\n",
    "        if len(self.image_paths) == 0:\n",
    "            raise ValueError(f\"Nenhuma imagem encontrada em {self.root_dir}. Verifique o caminho!\")\n",
    "        \n",
    "        print(f\"\\n{split.upper()} Dataset:\")\n",
    "        print(f\"   Total de imagens: {len(self.image_paths)}\")\n",
    "        \n",
    "        # Contar amostras por classe\n",
    "        label_counts = pd.Series(self.labels).value_counts().sort_index()\n",
    "        for idx, count in label_counts.items():\n",
    "            emotion_name = [k for k, v in EMOTION_LABELS.items() if v == idx][0]\n",
    "            print(f\"   {emotion_name:12s}: {count:5d} imagens\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Ler imagem em escala de cinza (j√° pr√©-processada em 224x224)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Erro ao carregar imagem: {img_path}\")\n",
    "        \n",
    "        # Normalizar para [0, 1]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Normaliza√ß√£o com m√©dia e desvio padr√£o (para modelos pr√©-treinados)\n",
    "        # Usando normaliza√ß√£o simples para grayscale\n",
    "        image = (image - 0.5) / 0.5\n",
    "        \n",
    "        # Adicionar dimens√£o de canal e converter para tensor\n",
    "        image = np.expand_dims(image, axis=0)  # [H, W] -> [1, H, W]\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "print(\"Classe Dataset configurada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008d8afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√£o de cria√ß√£o de modelos configurada\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DEFINI√á√ÉO DOS MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "def create_model(model_name, num_classes=7):\n",
    "    \"\"\"\n",
    "    Cria modelo baseado no nome.\n",
    "    \n",
    "    Args:\n",
    "        model_name: 'resnet50', 'efficientnet_b0', ou 'efficientvit_m5'\n",
    "        num_classes: N√∫mero de classes (7 emo√ß√µes)\n",
    "    \n",
    "    Returns:\n",
    "        model: Modelo PyTorch\n",
    "    \"\"\"\n",
    "    if model_name == 'resnet50':\n",
    "        model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Primeira camada adaptada para grayscale (1 canal)\n",
    "        original_weights = model.conv1.weight.data\n",
    "        avg_weights = torch.mean(original_weights, dim=1, keepdim=True)\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model.conv1.weight.data = avg_weights\n",
    "        \n",
    "        # Camada final para n√∫mero de classes\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    elif model_name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Primeira camada adaptada para grayscale (1 canal)\n",
    "        original_weights = model.features[0][0].weight.data\n",
    "        avg_weights = torch.mean(original_weights, dim=1, keepdim=True)\n",
    "        model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        model.features[0][0].weight.data = avg_weights\n",
    "        \n",
    "        # Camada final para n√∫mero de classes\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    elif model_name == 'efficientvit_m5':\n",
    "        try:\n",
    "            import timm\n",
    "            model = timm.create_model('efficientvit_m5', pretrained=True, num_classes=num_classes, in_chans=1)\n",
    "        except ImportError:\n",
    "            print(\"timm n√£o instalado. Execute: pip install timm\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao criar EfficientViT: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo n√£o suportado: {model_name}\")\n",
    "    \n",
    "    # Contar par√¢metros\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Modelo '{model_name}' criado com sucesso\")\n",
    "    print(f\"   Total de par√¢metros: {total_params:,}\")\n",
    "    print(f\"   Par√¢metros trein√°veis: {trainable_params:,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Fun√ß√£o de cria√ß√£o de modelos configurada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14d681b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√µes de treinamento configuradas\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FUN√á√ïES DE TREINAMENTO\n",
    "# =============================================================================\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, scaler, monitor):\n",
    "    \"\"\"\n",
    "    Treina o modelo por uma √©poca.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass com mixed precision\n",
    "        with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Atualizar monitoramento de mem√≥ria a cada 50 batches\n",
    "        if batch_idx % 50 == 0:\n",
    "            monitor.update_peak_memory()\n",
    "    \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Valida o modelo.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
    "                outputs = model(images)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "\n",
    "def train_model(model_name, train_loader, val_loader, device, epochs, early_stopping):\n",
    "    \"\"\"\n",
    "    Treina um modelo completo com monitoramento.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TREINANDO: {model_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Inicializar monitor\n",
    "    monitor = ResourceMonitor(model_name)\n",
    "    monitor.start_monitoring()\n",
    "    \n",
    "    # Criar modelo\n",
    "    model = create_model(model_name)\n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # Configura√ß√£o de treinamento\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device == \"cuda\"))\n",
    "    \n",
    "    # Hist√≥rico\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_accuracy': [],\n",
    "        'val_f1_macro': [],\n",
    "        'val_precision': [],\n",
    "        'val_recall': [],\n",
    "        'combined_metric': []\n",
    "    }\n",
    "    \n",
    "    best_combined_metric = 0.0\n",
    "    best_val_f1 = 0.0\n",
    "    best_val_accuracy = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_path = os.path.join(MODELS_PATH, f\"{model_name}_best.pth\")\n",
    "    \n",
    "    # Loop de treinamento\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Treinar\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, scaler, monitor)\n",
    "        \n",
    "        # Validar\n",
    "        val_preds, val_labels = validate(model, val_loader, device)\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1_macro = f1_score(val_labels, val_preds, average='macro')\n",
    "        val_precision = precision_score(val_labels, val_preds, average='macro', zero_division=0)\n",
    "        val_recall = recall_score(val_labels, val_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        # M√©trica combinada\n",
    "        combined_metric = (F1_WEIGHT * val_f1_macro) + (ACC_WEIGHT * val_accuracy)\n",
    "        \n",
    "        # Salvar hist√≥rico\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        history['val_f1_macro'].append(val_f1_macro)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['val_recall'].append(val_recall)\n",
    "        history['combined_metric'].append(combined_metric)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        monitor.record_epoch_time(epoch_time)\n",
    "        \n",
    "        # Relat√≥rio da √©poca\n",
    "        print(f\"\\n√âpoca [{epoch+1}/{epochs}] - Tempo: {epoch_time:.2f}s\")\n",
    "        print(f\"   Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"   Val Acc: {val_accuracy:.4f} | Val F1: {val_f1_macro:.4f}\")\n",
    "        print(f\"   Val Precision: {val_precision:.4f} | Val Recall: {val_recall:.4f}\")\n",
    "        print(f\"   M√©trica Combinada: {combined_metric:.4f}\")\n",
    "        \n",
    "        # Salvar melhor modelo\n",
    "        if combined_metric > best_combined_metric:\n",
    "            best_combined_metric = combined_metric\n",
    "            best_val_f1 = val_f1_macro\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_epoch = epoch\n",
    "            \n",
    "            # Salvar checkpoint completo em .pth\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_combined_metric': best_combined_metric,\n",
    "                'best_val_f1': best_val_f1,\n",
    "                'best_val_accuracy': best_val_accuracy,\n",
    "                'history': history,\n",
    "                'model_name': model_name\n",
    "            }, best_model_path)\n",
    "            \n",
    "            print(f\"   Modelo salvo: {best_model_path}\")\n",
    "        \n",
    "        # Verificar early stopping\n",
    "        if early_stopping(combined_metric):\n",
    "            print(f\"\\nEarly stopping ativado na √©poca {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Finalizar monitoramento\n",
    "    monitoring_stats = monitor.end_monitoring()\n",
    "    \n",
    "    # Carregar melhor modelo\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'model_name': model_name,\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_val_accuracy': best_val_accuracy,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'best_combined_metric': best_combined_metric,\n",
    "        'history': history,\n",
    "        'monitoring_stats': monitoring_stats,\n",
    "        'model_path': best_model_path,\n",
    "        'epochs_completed': epoch + 1\n",
    "    }\n",
    "\n",
    "print(\"Fun√ß√µes de treinamento configuradas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ad5d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√£o de avalia√ß√£o configurada\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# AVALIA√á√ÉO COM MATRIZ NORMALIZADA\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Avalia modelo com m√©tricas completas incluindo matriz de confus√£o normalizada.\n",
    "    \"\"\"\n",
    "    print(\"\\nAvaliando modelo no conjunto de teste...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testando\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=(device == \"cuda\")):\n",
    "                outputs = model(images)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    test_f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "    test_f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
    "    test_precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    test_recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    # M√©tricas por classe\n",
    "    precision_per_class, recall_per_class, f1_per_class, support = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=None, zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Matrizes de confus√£o\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    conf_matrix_normalized = confusion_matrix(all_labels, all_preds, normalize='true')\n",
    "    \n",
    "    # Relat√≥rio de classifica√ß√£o\n",
    "    emotion_names = [k for k, v in sorted(EMOTION_LABELS.items(), key=lambda x: x[1])]\n",
    "    class_report = classification_report(\n",
    "        all_labels, all_preds,\n",
    "        target_names=emotion_names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Imprimir resultados\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"RESULTADOS DA AVALIA√á√ÉO - CONJUNTO DE TESTE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Acur√°cia: {test_accuracy:.4f}\")\n",
    "    print(f\"\\nM√©tricas Macro:\")\n",
    "    print(f\"   Precis√£o: {test_precision:.4f}\")\n",
    "    print(f\"   Recall: {test_recall:.4f}\")\n",
    "    print(f\"   F1-Score: {test_f1_macro:.4f}\")\n",
    "    print(f\"\\nF1-Score Weighted: {test_f1_weighted:.4f}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Imprimir m√©tricas por classe\n",
    "    print(\"\\nM√©tricas por Classe:\")\n",
    "    print(f\"{'Classe':<15} {'Precis√£o':<12} {'Recall':<12} {'F1-Score':<12} {'Suporte':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    for i, emotion in enumerate(emotion_names):\n",
    "        print(f\"{emotion:<15} {precision_per_class[i]:<12.4f} {recall_per_class[i]:<12.4f} \"\n",
    "              f\"{f1_per_class[i]:<12.4f} {support[i]:<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    return {\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_f1_macro': test_f1_macro,\n",
    "        'test_f1_weighted': test_f1_weighted,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'confusion_matrix_normalized': conf_matrix_normalized,\n",
    "        'classification_report': class_report,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "\n",
    "print(\"Fun√ß√£o de avalia√ß√£o configurada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e0f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_visualizations(history, conf_matrix, metrics, class_report, \n",
    "                                       experiment_id, y_true, y_pred, model_name, \n",
    "                                       train_distribution):\n",
    "    \"\"\"\n",
    "    Visualiza√ß√µes completas com compara√ß√£o train vs test.\n",
    "    \n",
    "    Args:\n",
    "        train_distribution: dict com contagem de classes do treino\n",
    "                           formato: {0: count, 1: count, ...}\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(24, 18))\n",
    "    emotion_names = list(EMOTION_LABELS.keys())\n",
    "    \n",
    "    # 1. ACCURACY\n",
    "    ax1 = plt.subplot(3, 4, 1)\n",
    "    epochs = range(1, len(history['val_accuracy']) + 1)\n",
    "    plt.plot(epochs, [acc * 100 for acc in history['val_accuracy']], \n",
    "             'b-', linewidth=2, label='Val Accuracy', marker='o', markersize=3)\n",
    "    plt.title(f'{model_name.upper()}: Accuracy Evolution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. LOSS\n",
    "    ax2 = plt.subplot(3, 4, 2)\n",
    "    plt.plot(epochs, history['train_loss'], \n",
    "             'r-', linewidth=2, label='Train Loss', marker='o', markersize=3)\n",
    "    plt.title(f'{model_name.upper()}: Loss Evolution', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. MATRIZ RAW\n",
    "    ax3 = plt.subplot(3, 4, 3)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax3,\n",
    "                cbar_kws={'label': 'Amostras'})\n",
    "    plt.title('Matriz de Confus√£o (Test)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Classe Verdadeira')\n",
    "    plt.xlabel('Classe Predita')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # 4. MATRIZ NORMALIZADA\n",
    "    ax4 = plt.subplot(3, 4, 4)\n",
    "    conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    conf_matrix_norm = np.nan_to_num(conf_matrix_norm)\n",
    "    sns.heatmap(conf_matrix_norm, annot=True, fmt='.3f', cmap='Greens',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax4,\n",
    "                cbar_kws={'label': 'Propor√ß√£o'})\n",
    "    plt.title('Matriz Normalizada (Recall)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Classe Verdadeira')\n",
    "    plt.xlabel('Classe Predita')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # 5. DISTRIBUI√á√ÉO TRAIN VS TEST ‚Üê MODIFICADO\n",
    "    ax5 = plt.subplot(3, 4, 5)\n",
    "    \n",
    "    # Dados do TESTE\n",
    "    unique_test, counts_test = np.unique(y_true, return_counts=True)\n",
    "    test_dist = dict(zip(unique_test, counts_test))\n",
    "    \n",
    "    # Organizar dados para plotagem\n",
    "    train_counts = [train_distribution.get(i, 0) for i in range(len(emotion_names))]\n",
    "    test_counts = [test_dist.get(i, 0) for i in range(len(emotion_names))]\n",
    "    \n",
    "    x = np.arange(len(emotion_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, train_counts, width, label='Train (Balanceado)', \n",
    "                   alpha=0.8, color='steelblue', edgecolor='black')\n",
    "    bars2 = plt.bar(x + width/2, test_counts, width, label='Test (Original)', \n",
    "                   alpha=0.8, color='coral', edgecolor='black')\n",
    "    \n",
    "    plt.title('Distribui√ß√£o: Train vs Test', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Amostras')\n",
    "    plt.xlabel('Emo√ß√£o')\n",
    "    plt.xticks(x, emotion_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + max(train_counts + test_counts)*0.01,\n",
    "                    f'{int(height)}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # 6. F1-SCORE (Test)\n",
    "    ax6 = plt.subplot(3, 4, 6)\n",
    "    f1_scores = [class_report[emotion]['f1-score'] for emotion in emotion_names]\n",
    "    support_counts = [class_report[emotion]['support'] for emotion in emotion_names]\n",
    "    bars = plt.bar(emotion_names, f1_scores, color='steelblue', alpha=0.8, edgecolor='black')\n",
    "    plt.title('F1-Score por Emo√ß√£o (Test)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    for bar, score, support in zip(bars, f1_scores, support_counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{score:.3f}\\n(n={support})', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 7. PRECISION, RECALL, F1\n",
    "    ax7 = plt.subplot(3, 4, 7)\n",
    "    precision_scores = [class_report[emotion]['precision'] for emotion in emotion_names]\n",
    "    recall_scores = [class_report[emotion]['recall'] for emotion in emotion_names]\n",
    "    x = np.arange(len(emotion_names))\n",
    "    width = 0.25\n",
    "    bars1 = plt.bar(x - width, precision_scores, width, label='Precision', alpha=0.8, color='lightcoral')\n",
    "    bars2 = plt.bar(x, recall_scores, width, label='Recall', alpha=0.8, color='lightblue')\n",
    "    bars3 = plt.bar(x + width, f1_scores, width, label='F1-Score', alpha=0.8, color='lightgreen')\n",
    "    plt.title('M√©tricas por Classe (Test)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Emo√ß√£o')\n",
    "    plt.xticks(x, emotion_names, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # 8. F1 MACRO VS WEIGHTED\n",
    "    ax8 = plt.subplot(3, 4, 8)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0)\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted', zero_division=0)\n",
    "    metrics_comparison = {\n",
    "        'Precision': [precision_macro, precision_weighted],\n",
    "        'Recall': [recall_macro, recall_weighted],\n",
    "        'F1-Score': [f1_macro, f1_weighted]\n",
    "    }\n",
    "    x = np.arange(len(metrics_comparison))\n",
    "    width = 0.35\n",
    "    macro_values = [metrics_comparison[metric][0] for metric in metrics_comparison]\n",
    "    weighted_values = [metrics_comparison[metric][1] for metric in metrics_comparison]\n",
    "    bars1 = plt.bar(x - width/2, macro_values, width, label='Macro', alpha=0.8, color='lightcoral')\n",
    "    bars2 = plt.bar(x + width/2, weighted_values, width, label='Weighted', alpha=0.8, color='lightblue')\n",
    "    plt.title('Macro vs Weighted (Test)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('M√©trica')\n",
    "    plt.xticks(x, metrics_comparison.keys())\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1)\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.01,\n",
    "                    f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # 9. HEATMAP ERROS\n",
    "    ax9 = plt.subplot(3, 4, 9)\n",
    "    error_matrix = conf_matrix.copy()\n",
    "    np.fill_diagonal(error_matrix, 0)\n",
    "    error_matrix_norm = error_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    error_matrix_norm = np.nan_to_num(error_matrix_norm)\n",
    "    sns.heatmap(error_matrix_norm, annot=True, fmt='.3f', cmap='Reds',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=ax9,\n",
    "                cbar_kws={'label': 'Propor√ß√£o de Erros'})\n",
    "    plt.title('Heatmap de Erros (Test)', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Classe Verdadeira')\n",
    "    plt.xlabel('Classe Predita')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # 10. F1 POR √âPOCA\n",
    "    ax10 = plt.subplot(3, 4, 10)\n",
    "    plt.plot(epochs, history['val_f1_macro'], 'g-', linewidth=2, \n",
    "             label='Val F1-Macro', marker='o', markersize=3)\n",
    "    plt.title('F1-Score Evolution', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 11. RECURSOS COMPUTACIONAIS\n",
    "    ax11 = plt.subplot(3, 4, 11)\n",
    "    resource_data = {\n",
    "        'Tempo (min)': metrics['training_time_seconds'] / 60,\n",
    "        'Mem√≥ria (GB)': metrics['peak_memory_mb'] / 1024,\n",
    "        'Par√¢metros (M)': metrics['total_parameters'] / 1_000_000,\n",
    "        'Efici√™ncia': metrics['test_accuracy'] / (metrics['total_parameters'] / 1_000_000)\n",
    "    }\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    bars = plt.bar(range(len(resource_data)), list(resource_data.values()), \n",
    "                  color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.title(f'Recursos Computacionais\\n{model_name.upper()}', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(range(len(resource_data)), resource_data.keys(), rotation=45)\n",
    "    plt.ylabel('Valor')\n",
    "    for bar, (key, value) in zip(bars, resource_data.items()):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.02,\n",
    "                f'{value:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 12. RESUMO\n",
    "    ax12 = plt.subplot(3, 4, 12)\n",
    "    ax12.axis('off')\n",
    "    \n",
    "    # Calcular diferen√ßa de balanceamento\n",
    "    train_max = max(train_counts)\n",
    "    train_min = min(train_counts)\n",
    "    test_max = max(test_counts)\n",
    "    test_min = min(test_counts)\n",
    "    train_ratio = train_max / train_min if train_min > 0 else 0\n",
    "    test_ratio = test_max / test_min if test_min > 0 else 0\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "{model_name.upper()}\n",
    "RESUMO\n",
    "\n",
    "PERFORMANCE (Test):\n",
    "- Accuracy: {metrics['test_accuracy']:.4f}\n",
    "- F1-Macro: {f1_macro:.4f}\n",
    "- F1-Weighted: {f1_weighted:.4f}\n",
    "\n",
    "DISTRIBUI√á√ÉO:\n",
    "- Train Ratio: {train_ratio:.1f}:1\n",
    "- Test Ratio: {test_ratio:.1f}:1\n",
    "\n",
    "RECURSOS:\n",
    "- Par√¢metros: {metrics['total_parameters']/1_000_000:.1f}M\n",
    "- Tempo: {metrics['training_time_seconds']/60:.1f} min\n",
    "- Mem√≥ria: {metrics['peak_memory_mb']/1024:.2f} GB\n",
    "\n",
    "MELHOR/PIOR (Test):\n",
    "- Melhor: {emotion_names[np.argmax(f1_scores)]} ({max(f1_scores):.3f})\n",
    "- Pior: {emotion_names[np.argmin(f1_scores)]} ({min(f1_scores):.3f})\n",
    "    \"\"\"\n",
    "    ax12.text(0.05, 0.95, summary_text, fontsize=11, verticalalignment='top',\n",
    "             transform=ax12.transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_PATH, f'{model_name}_analysis_{experiment_id}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb44a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FUN√á√ïES DE VISUALIZA√á√ÉO\n",
    "# =============================================================================\n",
    "\n",
    "def plot_confusion_matrices(conf_matrix, conf_matrix_normalized, model_name, save_path):\n",
    "    \"\"\"\n",
    "    Plota matrizes de confus√£o (raw e normalizada).\n",
    "    \"\"\"\n",
    "    emotion_names = [k for k, v in sorted(EMOTION_LABELS.items(), key=lambda x: x[1])]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Matriz Raw\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=axes[0],\n",
    "                cbar_kws={'label': 'Amostras'})\n",
    "    axes[0].set_title(f'{model_name.upper()}: Matriz de Confus√£o (Raw)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Classe Verdadeira')\n",
    "    axes[0].set_xlabel('Classe Predita')\n",
    "    \n",
    "    # Matriz Normalizada\n",
    "    sns.heatmap(conf_matrix_normalized, annot=True, fmt='.3f', cmap='Greens',\n",
    "                xticklabels=emotion_names, yticklabels=emotion_names, ax=axes[1],\n",
    "                cbar_kws={'label': 'Propor√ß√£o'})\n",
    "    axes[1].set_title(f'{model_name.upper()}: Matriz Normalizada (Recall)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel('Classe Verdadeira')\n",
    "    axes[1].set_xlabel('Classe Predita')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Matrizes de confus√£o salvas: {save_path}\")\n",
    "\n",
    "def plot_training_history(history, model_name, save_path):\n",
    "    \"\"\"\n",
    "    Plota hist√≥rico de treinamento (Loss, Accuracy, F1).\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', linewidth=2, label='Train Loss', marker='o')\n",
    "    axes[0].set_title(f'{model_name.upper()}: Loss Evolution', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(epochs, [acc * 100 for acc in history['val_accuracy']], \n",
    "                 'g-', linewidth=2, label='Val Accuracy', marker='o')\n",
    "    axes[1].set_title(f'{model_name.upper()}: Accuracy Evolution', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1-Score\n",
    "    axes[2].plot(epochs, history['val_f1_macro'], 'r-', linewidth=2, label='Val F1-Macro', marker='o')\n",
    "    axes[2].set_title(f'{model_name.upper()}: F1-Score Evolution', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('F1-Score')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Hist√≥rico de treinamento salvo: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "933963a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√£o de salvamento configurada\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SALVAR RESULTADOS\n",
    "# =============================================================================\n",
    "\n",
    "def save_results(model_name, train_result, eval_result):\n",
    "    \"\"\"\n",
    "    Salva todos os resultados do experimento.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Salvar m√©tricas como JSON\n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'timestamp': timestamp,\n",
    "        'best_epoch': int(train_result['best_epoch']),\n",
    "        'epochs_completed': int(train_result['epochs_completed']),\n",
    "        'best_val_accuracy': float(train_result['best_val_accuracy']),\n",
    "        'best_val_f1': float(train_result['best_val_f1']),\n",
    "        'test_accuracy': float(eval_result['test_accuracy']),\n",
    "        'test_f1_macro': float(eval_result['test_f1_macro']),\n",
    "        'test_f1_weighted': float(eval_result['test_f1_weighted']),\n",
    "        'test_precision': float(eval_result['test_precision']),\n",
    "        'test_recall': float(eval_result['test_recall']),\n",
    "        'monitoring_stats': train_result['monitoring_stats']\n",
    "    }\n",
    "    \n",
    "    metrics_path = os.path.join(METRICS_PATH, f\"{model_name}_metrics_{timestamp}.json\")\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    print(f\"M√©tricas salvas: {metrics_path}\")\n",
    "    \n",
    "    # Salvar matrizes de confus√£o como CSV\n",
    "    emotion_names = [k for k, v in sorted(EMOTION_LABELS.items(), key=lambda x: x[1])]\n",
    "    \n",
    "    conf_matrix_df = pd.DataFrame(\n",
    "        eval_result['confusion_matrix'],\n",
    "        index=emotion_names,\n",
    "        columns=emotion_names\n",
    "    )\n",
    "    conf_matrix_df.to_csv(os.path.join(METRICS_PATH, f\"{model_name}_confusion_raw_{timestamp}.csv\"))\n",
    "    \n",
    "    conf_matrix_norm_df = pd.DataFrame(\n",
    "        eval_result['confusion_matrix_normalized'],\n",
    "        index=emotion_names,\n",
    "        columns=emotion_names\n",
    "    )\n",
    "    conf_matrix_norm_df.to_csv(os.path.join(METRICS_PATH, f\"{model_name}_confusion_normalized_{timestamp}.csv\"))\n",
    "    \n",
    "    # Salvar visualiza√ß√µes\n",
    "    plot_confusion_matrices(\n",
    "        eval_result['confusion_matrix'],\n",
    "        eval_result['confusion_matrix_normalized'],\n",
    "        model_name,\n",
    "        save_path=os.path.join(PLOTS_PATH, f\"{model_name}_confusion_{timestamp}.png\")\n",
    "    )\n",
    "    \n",
    "    plot_training_history(\n",
    "        train_result['history'],\n",
    "        model_name,\n",
    "        save_path=os.path.join(PLOTS_PATH, f\"{model_name}_history_{timestamp}.png\")\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTodos os resultados salvos para {model_name}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Fun√ß√£o de salvamento configurada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba6e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√£o principal configurada\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXECU√á√ÉO PRINCIPAL\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Fun√ß√£o principal de execu√ß√£o.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"INICIANDO TREINAMENTO BASELINE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Carregar datasets\n",
    "    print(\"Carregando datasets...\")\n",
    "    train_dataset = EmotionDataset(DATASET_PATH, split='train')\n",
    "\n",
    "    # Calcular distribui√ß√£o do conjunto de treino\n",
    "    train_distribution = {}\n",
    "    for _, label in train_dataset:\n",
    "        label_int = int(label)\n",
    "        train_distribution[label_int] = train_distribution.get(label_int, 0) + 1\n",
    "    test_dataset = EmotionDataset(DATASET_PATH, split='test')\n",
    "    \n",
    "    # Criar data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDatasets carregados com sucesso\")\n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Lista de modelos para treinar\n",
    "    models_to_train = ['resnet50', 'efficientnet_b0', 'efficientvit_m5']\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Treinar cada modelo\n",
    "    for model_name in models_to_train:\n",
    "        try:\n",
    "            # Inicializar early stopping\n",
    "            early_stopping = EarlyStopping(\n",
    "                patience=EARLY_STOP_PATIENCE,\n",
    "                min_delta=EARLY_STOP_MIN_DELTA,\n",
    "                mode='max',\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            # Treinar\n",
    "            train_result = train_model(\n",
    "                model_name,\n",
    "                train_loader,\n",
    "                test_loader,\n",
    "                DEVICE,\n",
    "                EPOCHS,\n",
    "                early_stopping\n",
    "            )\n",
    "            \n",
    "            if train_result is None:\n",
    "                continue\n",
    "            \n",
    "            # Avaliar\n",
    "            eval_result = evaluate_model(train_result['model'], test_loader, DEVICE)\n",
    "            \n",
    "            # Salvar resultados\n",
    "            metrics = save_results(model_name, train_result, eval_result)\n",
    "            all_results.append(metrics)\n",
    "            \n",
    "            # Limpar mem√≥ria\n",
    "            del train_result, eval_result\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nErro ao treinar {model_name}: {type(e).__name__}\")\n",
    "            print(f\"Mensagem: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Compara√ß√£o final\n",
    "    if all_results:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"COMPARA√á√ÉO FINAL - TODOS OS MODELOS\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        comparison_df = pd.DataFrame(all_results)\n",
    "        print(comparison_df[['model_name', 'test_accuracy', 'test_f1_macro', \n",
    "                            'test_f1_weighted', 'epochs_completed']].to_string(index=False))\n",
    "        \n",
    "        # Salvar compara√ß√£o\n",
    "        comparison_path = os.path.join(METRICS_PATH, 'model_comparison.csv')\n",
    "        comparison_df.to_csv(comparison_path, index=False)\n",
    "        print(f\"\\nCompara√ß√£o salva: {comparison_path}\")\n",
    "        \n",
    "        # Identificar melhor modelo\n",
    "        best_model = comparison_df.loc[comparison_df['test_accuracy'].idxmax()]\n",
    "        print(f\"\\nMelhor modelo (por acur√°cia): {best_model['model_name']} - {best_model['test_accuracy']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TREINAMENTO BASELINE CONCLU√çDO\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"Fun√ß√£o principal configurada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cdb9bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INICIANDO TREINAMENTO BASELINE\n",
      "================================================================================\n",
      "\n",
      "Carregando datasets...\n",
      "\n",
      "TRAIN Dataset:\n",
      "   Total de imagens: 61287\n",
      "   Raiva       :  2829 imagens\n",
      "   Nojo        :  2976 imagens\n",
      "   Medo        :   840 imagens\n",
      "   Felicidade  : 17605 imagens\n",
      "   Neutro      : 23787 imagens\n",
      "   Tristeza    :  7918 imagens\n",
      "   Surpresa    :  5332 imagens\n",
      "\n",
      "TEST Dataset:\n",
      "   Total de imagens: 17102\n",
      "   Raiva       :   725 imagens\n",
      "   Nojo        :   782 imagens\n",
      "   Medo        :   213 imagens\n",
      "   Felicidade  :  5343 imagens\n",
      "   Neutro      :  6590 imagens\n",
      "   Tristeza    :  2067 imagens\n",
      "   Surpresa    :  1382 imagens\n",
      "\n",
      "Datasets carregados com sucesso\n",
      "Train samples: 61287\n",
      "Test samples: 17102\n",
      "\n",
      "================================================================================\n",
      "TREINANDO: RESNET50\n",
      "================================================================================\n",
      "\n",
      "üîç Iniciando monitoramento: resnet50\n",
      "  ‚Ä¢ Initial RAM: 740.24 MB\n",
      "  ‚Ä¢ Initial GPU: 0.00 MB\n",
      "Modelo 'resnet50' criado com sucesso\n",
      "   Total de par√¢metros: 23,516,103\n",
      "   Par√¢metros trein√°veis: 23,516,103\n",
      "\n",
      "√âpoca [1/100] - Tempo: 162.54s\n",
      "   Train Loss: 1.2176\n",
      "   Val Acc: 0.6064 | Val F1: 0.3757\n",
      "   Val Precision: 0.4549 | Val Recall: 0.3578\n",
      "   M√©trica Combinada: 0.4680\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/resnet50_best.pth\n",
      "Early Stopping: Baseline estabelecida: 0.4680\n",
      "\n",
      "√âpoca [2/100] - Tempo: 162.75s\n",
      "   Train Loss: 1.0976\n",
      "   Val Acc: 0.6091 | Val F1: 0.3915\n",
      "   Val Precision: 0.3999 | Val Recall: 0.3938\n",
      "   M√©trica Combinada: 0.4785\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/resnet50_best.pth\n",
      "Early Stopping: Melhoria detectada (0.4785, Delta=+0.0106)\n",
      "\n",
      "√âpoca [3/100] - Tempo: 162.76s\n",
      "   Train Loss: 1.0072\n",
      "   Val Acc: 0.6160 | Val F1: 0.3920\n",
      "   Val Precision: 0.4558 | Val Recall: 0.3809\n",
      "   M√©trica Combinada: 0.4816\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/resnet50_best.pth\n",
      "Early Stopping: Melhoria detectada (0.4816, Delta=+0.0031)\n",
      "\n",
      "√âpoca [4/100] - Tempo: 166.73s\n",
      "   Train Loss: 0.8849\n",
      "   Val Acc: 0.6016 | Val F1: 0.4325\n",
      "   Val Precision: 0.4819 | Val Recall: 0.4121\n",
      "   M√©trica Combinada: 0.5001\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/resnet50_best.pth\n",
      "Early Stopping: Melhoria detectada (0.5001, Delta=+0.0185)\n",
      "\n",
      "√âpoca [5/100] - Tempo: 167.33s\n",
      "   Train Loss: 0.7365\n",
      "   Val Acc: 0.5961 | Val F1: 0.4053\n",
      "   Val Precision: 0.4643 | Val Recall: 0.3961\n",
      "   M√©trica Combinada: 0.4816\n",
      "Early Stopping: Sem melhoria (1/15)\n",
      "\n",
      "√âpoca [6/100] - Tempo: 167.73s\n",
      "   Train Loss: 0.5869\n",
      "   Val Acc: 0.5793 | Val F1: 0.4139\n",
      "   Val Precision: 0.4467 | Val Recall: 0.4077\n",
      "   M√©trica Combinada: 0.4800\n",
      "Early Stopping: Sem melhoria (2/15)\n",
      "\n",
      "√âpoca [7/100] - Tempo: 167.71s\n",
      "   Train Loss: 0.4698\n",
      "   Val Acc: 0.5811 | Val F1: 0.4192\n",
      "   Val Precision: 0.4580 | Val Recall: 0.4021\n",
      "   M√©trica Combinada: 0.4840\n",
      "Early Stopping: Sem melhoria (3/15)\n",
      "\n",
      "√âpoca [8/100] - Tempo: 167.68s\n",
      "   Train Loss: 0.4010\n",
      "   Val Acc: 0.5722 | Val F1: 0.4146\n",
      "   Val Precision: 0.4419 | Val Recall: 0.4030\n",
      "   M√©trica Combinada: 0.4776\n",
      "Early Stopping: Sem melhoria (4/15)\n",
      "\n",
      "√âpoca [9/100] - Tempo: 167.67s\n",
      "   Train Loss: 0.3490\n",
      "   Val Acc: 0.5529 | Val F1: 0.3980\n",
      "   Val Precision: 0.4181 | Val Recall: 0.3948\n",
      "   M√©trica Combinada: 0.4600\n",
      "Early Stopping: Sem melhoria (5/15)\n",
      "\n",
      "√âpoca [10/100] - Tempo: 167.66s\n",
      "   Train Loss: 0.3228\n",
      "   Val Acc: 0.5673 | Val F1: 0.4182\n",
      "   Val Precision: 0.4400 | Val Recall: 0.4071\n",
      "   M√©trica Combinada: 0.4779\n",
      "Early Stopping: Sem melhoria (6/15)\n",
      "\n",
      "√âpoca [11/100] - Tempo: 167.61s\n",
      "   Train Loss: 0.2963\n",
      "   Val Acc: 0.5664 | Val F1: 0.4174\n",
      "   Val Precision: 0.4341 | Val Recall: 0.4113\n",
      "   M√©trica Combinada: 0.4770\n",
      "Early Stopping: Sem melhoria (7/15)\n",
      "\n",
      "√âpoca [12/100] - Tempo: 166.90s\n",
      "   Train Loss: 0.2824\n",
      "   Val Acc: 0.5686 | Val F1: 0.4062\n",
      "   Val Precision: 0.4476 | Val Recall: 0.3875\n",
      "   M√©trica Combinada: 0.4712\n",
      "Early Stopping: Sem melhoria (8/15)\n",
      "\n",
      "√âpoca [13/100] - Tempo: 167.66s\n",
      "   Train Loss: 0.2650\n",
      "   Val Acc: 0.5713 | Val F1: 0.4131\n",
      "   Val Precision: 0.4355 | Val Recall: 0.4020\n",
      "   M√©trica Combinada: 0.4764\n",
      "Early Stopping: Sem melhoria (9/15)\n",
      "\n",
      "√âpoca [14/100] - Tempo: 167.69s\n",
      "   Train Loss: 0.2637\n",
      "   Val Acc: 0.5643 | Val F1: 0.4186\n",
      "   Val Precision: 0.4323 | Val Recall: 0.4096\n",
      "   M√©trica Combinada: 0.4769\n",
      "Early Stopping: Sem melhoria (10/15)\n",
      "\n",
      "√âpoca [15/100] - Tempo: 167.72s\n",
      "   Train Loss: 0.2454\n",
      "   Val Acc: 0.5589 | Val F1: 0.4028\n",
      "   Val Precision: 0.4310 | Val Recall: 0.3868\n",
      "   M√©trica Combinada: 0.4652\n",
      "Early Stopping: Sem melhoria (11/15)\n",
      "\n",
      "√âpoca [16/100] - Tempo: 167.69s\n",
      "   Train Loss: 0.2401\n",
      "   Val Acc: 0.5554 | Val F1: 0.4050\n",
      "   Val Precision: 0.4307 | Val Recall: 0.3889\n",
      "   M√©trica Combinada: 0.4651\n",
      "Early Stopping: Sem melhoria (12/15)\n",
      "\n",
      "√âpoca [17/100] - Tempo: 167.71s\n",
      "   Train Loss: 0.2320\n",
      "   Val Acc: 0.5606 | Val F1: 0.4031\n",
      "   Val Precision: 0.4429 | Val Recall: 0.3886\n",
      "   M√©trica Combinada: 0.4661\n",
      "Early Stopping: Sem melhoria (13/15)\n",
      "\n",
      "√âpoca [18/100] - Tempo: 167.67s\n",
      "   Train Loss: 0.2288\n",
      "   Val Acc: 0.5618 | Val F1: 0.3976\n",
      "   Val Precision: 0.4265 | Val Recall: 0.3868\n",
      "   M√©trica Combinada: 0.4633\n",
      "Early Stopping: Sem melhoria (14/15)\n",
      "\n",
      "√âpoca [19/100] - Tempo: 167.84s\n",
      "   Train Loss: 0.2241\n",
      "   Val Acc: 0.5591 | Val F1: 0.3949\n",
      "   Val Precision: 0.4324 | Val Recall: 0.3744\n",
      "   M√©trica Combinada: 0.4606\n",
      "Early Stopping: Sem melhoria (15/15)\n",
      "Early Stopping: Treinamento interrompido ap√≥s 15 √©pocas sem melhoria\n",
      "\n",
      "Early stopping ativado na √©poca 19\n",
      "\n",
      "======================================================================\n",
      "MONITORING REPORT: RESNET50\n",
      "======================================================================\n",
      "Total training time: 0:52:51\n",
      "Initial RAM: 740.24 MB\n",
      "Final RAM: 1394.14 MB\n",
      "Peak RAM: 1394.17 MB\n",
      "Memory increase: 653.90 MB\n",
      "Peak GPU Memory: 3119.31 MB\n",
      "Final GPU Memory: 382.08 MB\n",
      "======================================================================\n",
      "\n",
      "Avaliando modelo no conjunto de teste...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:13<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTADOS DA AVALIA√á√ÉO - CONJUNTO DE TESTE\n",
      "======================================================================\n",
      "Acur√°cia: 0.6016\n",
      "\n",
      "M√©tricas Macro:\n",
      "   Precis√£o: 0.4819\n",
      "   Recall: 0.4121\n",
      "   F1-Score: 0.4325\n",
      "\n",
      "F1-Score Weighted: 0.5865\n",
      "======================================================================\n",
      "\n",
      "\n",
      "M√©tricas por Classe:\n",
      "Classe          Precis√£o     Recall       F1-Score     Suporte   \n",
      "----------------------------------------------------------------------\n",
      "Raiva           0.5389       0.4110       0.4664       725       \n",
      "Nojo            0.2293       0.0601       0.0952       782       \n",
      "Medo            0.2456       0.1972       0.2188       213       \n",
      "Felicidade      0.6886       0.7039       0.6962       5343      \n",
      "Neutro          0.5970       0.7194       0.6525       6590      \n",
      "Tristeza        0.4636       0.4432       0.4531       2067      \n",
      "Surpresa        0.6103       0.3502       0.4451       1382      \n",
      "----------------------------------------------------------------------\n",
      "M√©tricas salvas: ../results/baseline/EXPW/metrics/resnet50_metrics_20251101_120131.json\n",
      "Matrizes de confus√£o salvas: ../results/baseline/EXPW/plots/resnet50_confusion_20251101_120131.png\n",
      "Hist√≥rico de treinamento salvo: ../results/baseline/EXPW/plots/resnet50_history_20251101_120131.png\n",
      "\n",
      "Todos os resultados salvos para resnet50\n",
      "\n",
      "================================================================================\n",
      "TREINANDO: EFFICIENTNET_B0\n",
      "================================================================================\n",
      "\n",
      "üîç Iniciando monitoramento: efficientnet_b0\n",
      "  ‚Ä¢ Initial RAM: 1459.28 MB\n",
      "  ‚Ä¢ Initial GPU: 16.25 MB\n",
      "Modelo 'efficientnet_b0' criado com sucesso\n",
      "   Total de par√¢metros: 4,015,939\n",
      "   Par√¢metros trein√°veis: 4,015,939\n",
      "\n",
      "√âpoca [1/100] - Tempo: 99.42s\n",
      "   Train Loss: 1.3068\n",
      "   Val Acc: 0.6018 | Val F1: 0.3832\n",
      "   Val Precision: 0.4648 | Val Recall: 0.3691\n",
      "   M√©trica Combinada: 0.4706\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientnet_b0_best.pth\n",
      "Early Stopping: Baseline estabelecida: 0.4706\n",
      "\n",
      "√âpoca [2/100] - Tempo: 99.22s\n",
      "   Train Loss: 1.1349\n",
      "   Val Acc: 0.6083 | Val F1: 0.3927\n",
      "   Val Precision: 0.4951 | Val Recall: 0.3745\n",
      "   M√©trica Combinada: 0.4789\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientnet_b0_best.pth\n",
      "Early Stopping: Melhoria detectada (0.4789, Delta=+0.0083)\n",
      "\n",
      "√âpoca [3/100] - Tempo: 99.17s\n",
      "   Train Loss: 1.0559\n",
      "   Val Acc: 0.6168 | Val F1: 0.4009\n",
      "   Val Precision: 0.5120 | Val Recall: 0.3867\n",
      "   M√©trica Combinada: 0.4872\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientnet_b0_best.pth\n",
      "Early Stopping: Melhoria detectada (0.4872, Delta=+0.0083)\n",
      "\n",
      "√âpoca [4/100] - Tempo: 99.14s\n",
      "   Train Loss: 0.9720\n",
      "   Val Acc: 0.6135 | Val F1: 0.4193\n",
      "   Val Precision: 0.4948 | Val Recall: 0.4024\n",
      "   M√©trica Combinada: 0.4970\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientnet_b0_best.pth\n",
      "Early Stopping: Melhoria detectada (0.4970, Delta=+0.0098)\n",
      "\n",
      "√âpoca [5/100] - Tempo: 99.26s\n",
      "   Train Loss: 0.8784\n",
      "   Val Acc: 0.6069 | Val F1: 0.4199\n",
      "   Val Precision: 0.4764 | Val Recall: 0.4040\n",
      "   M√©trica Combinada: 0.4947\n",
      "Early Stopping: Sem melhoria (1/15)\n",
      "\n",
      "√âpoca [6/100] - Tempo: 98.99s\n",
      "   Train Loss: 0.7840\n",
      "   Val Acc: 0.5968 | Val F1: 0.4250\n",
      "   Val Precision: 0.4700 | Val Recall: 0.4039\n",
      "   M√©trica Combinada: 0.4938\n",
      "Early Stopping: Sem melhoria (2/15)\n",
      "\n",
      "√âpoca [7/100] - Tempo: 99.01s\n",
      "   Train Loss: 0.6943\n",
      "   Val Acc: 0.5860 | Val F1: 0.4217\n",
      "   Val Precision: 0.4408 | Val Recall: 0.4105\n",
      "   M√©trica Combinada: 0.4874\n",
      "Early Stopping: Sem melhoria (3/15)\n",
      "\n",
      "√âpoca [8/100] - Tempo: 99.06s\n",
      "   Train Loss: 0.6217\n",
      "   Val Acc: 0.5847 | Val F1: 0.4233\n",
      "   Val Precision: 0.4511 | Val Recall: 0.4107\n",
      "   M√©trica Combinada: 0.4878\n",
      "Early Stopping: Sem melhoria (4/15)\n",
      "\n",
      "√âpoca [9/100] - Tempo: 99.05s\n",
      "   Train Loss: 0.5638\n",
      "   Val Acc: 0.5735 | Val F1: 0.4224\n",
      "   Val Precision: 0.4382 | Val Recall: 0.4116\n",
      "   M√©trica Combinada: 0.4828\n",
      "Early Stopping: Sem melhoria (5/15)\n",
      "\n",
      "√âpoca [10/100] - Tempo: 99.09s\n",
      "   Train Loss: 0.5213\n",
      "   Val Acc: 0.5789 | Val F1: 0.4220\n",
      "   Val Precision: 0.4445 | Val Recall: 0.4079\n",
      "   M√©trica Combinada: 0.4848\n",
      "Early Stopping: Sem melhoria (6/15)\n",
      "\n",
      "√âpoca [11/100] - Tempo: 98.98s\n",
      "   Train Loss: 0.4834\n",
      "   Val Acc: 0.5784 | Val F1: 0.4159\n",
      "   Val Precision: 0.4434 | Val Recall: 0.4017\n",
      "   M√©trica Combinada: 0.4809\n",
      "Early Stopping: Sem melhoria (7/15)\n",
      "\n",
      "√âpoca [12/100] - Tempo: 99.03s\n",
      "   Train Loss: 0.4580\n",
      "   Val Acc: 0.5726 | Val F1: 0.4224\n",
      "   Val Precision: 0.4431 | Val Recall: 0.4095\n",
      "   M√©trica Combinada: 0.4825\n",
      "Early Stopping: Sem melhoria (8/15)\n",
      "\n",
      "√âpoca [13/100] - Tempo: 99.06s\n",
      "   Train Loss: 0.4299\n",
      "   Val Acc: 0.5649 | Val F1: 0.4177\n",
      "   Val Precision: 0.4322 | Val Recall: 0.4070\n",
      "   M√©trica Combinada: 0.4766\n",
      "Early Stopping: Sem melhoria (9/15)\n",
      "\n",
      "√âpoca [14/100] - Tempo: 99.03s\n",
      "   Train Loss: 0.4171\n",
      "   Val Acc: 0.5634 | Val F1: 0.4144\n",
      "   Val Precision: 0.4287 | Val Recall: 0.4053\n",
      "   M√©trica Combinada: 0.4740\n",
      "Early Stopping: Sem melhoria (10/15)\n",
      "\n",
      "√âpoca [15/100] - Tempo: 99.00s\n",
      "   Train Loss: 0.3936\n",
      "   Val Acc: 0.5710 | Val F1: 0.4157\n",
      "   Val Precision: 0.4387 | Val Recall: 0.4031\n",
      "   M√©trica Combinada: 0.4778\n",
      "Early Stopping: Sem melhoria (11/15)\n",
      "\n",
      "√âpoca [16/100] - Tempo: 99.02s\n",
      "   Train Loss: 0.3816\n",
      "   Val Acc: 0.5684 | Val F1: 0.4088\n",
      "   Val Precision: 0.4345 | Val Recall: 0.3957\n",
      "   M√©trica Combinada: 0.4726\n",
      "Early Stopping: Sem melhoria (12/15)\n",
      "\n",
      "√âpoca [17/100] - Tempo: 99.04s\n",
      "   Train Loss: 0.3658\n",
      "   Val Acc: 0.5642 | Val F1: 0.4105\n",
      "   Val Precision: 0.4363 | Val Recall: 0.3963\n",
      "   M√©trica Combinada: 0.4720\n",
      "Early Stopping: Sem melhoria (13/15)\n",
      "\n",
      "√âpoca [18/100] - Tempo: 98.96s\n",
      "   Train Loss: 0.3518\n",
      "   Val Acc: 0.5573 | Val F1: 0.4093\n",
      "   Val Precision: 0.4270 | Val Recall: 0.3983\n",
      "   M√©trica Combinada: 0.4685\n",
      "Early Stopping: Sem melhoria (14/15)\n",
      "\n",
      "√âpoca [19/100] - Tempo: 98.07s\n",
      "   Train Loss: 0.3445\n",
      "   Val Acc: 0.5648 | Val F1: 0.4194\n",
      "   Val Precision: 0.4379 | Val Recall: 0.4071\n",
      "   M√©trica Combinada: 0.4776\n",
      "Early Stopping: Sem melhoria (15/15)\n",
      "Early Stopping: Treinamento interrompido ap√≥s 15 √©pocas sem melhoria\n",
      "\n",
      "Early stopping ativado na √©poca 19\n",
      "\n",
      "======================================================================\n",
      "MONITORING REPORT: EFFICIENTNET_B0\n",
      "======================================================================\n",
      "Total training time: 0:31:22\n",
      "Initial RAM: 1459.28 MB\n",
      "Final RAM: 1539.56 MB\n",
      "Peak RAM: 1539.62 MB\n",
      "Memory increase: 80.28 MB\n",
      "Peak GPU Memory: 3119.31 MB\n",
      "Final GPU Memory: 79.44 MB\n",
      "======================================================================\n",
      "\n",
      "Avaliando modelo no conjunto de teste...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:06<00:00, 39.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTADOS DA AVALIA√á√ÉO - CONJUNTO DE TESTE\n",
      "======================================================================\n",
      "Acur√°cia: 0.6135\n",
      "\n",
      "M√©tricas Macro:\n",
      "   Precis√£o: 0.4948\n",
      "   Recall: 0.4024\n",
      "   F1-Score: 0.4193\n",
      "\n",
      "F1-Score Weighted: 0.5910\n",
      "======================================================================\n",
      "\n",
      "\n",
      "M√©tricas por Classe:\n",
      "Classe          Precis√£o     Recall       F1-Score     Suporte   \n",
      "----------------------------------------------------------------------\n",
      "Raiva           0.4771       0.4455       0.4608       725       \n",
      "Nojo            0.2609       0.0230       0.0423       782       \n",
      "Medo            0.3065       0.0892       0.1382       213       \n",
      "Felicidade      0.7021       0.6906       0.6963       5343      \n",
      "Neutro          0.5889       0.7744       0.6690       6590      \n",
      "Tristeza        0.5677       0.3532       0.4354       2067      \n",
      "Surpresa        0.5603       0.4407       0.4933       1382      \n",
      "----------------------------------------------------------------------\n",
      "M√©tricas salvas: ../results/baseline/EXPW/metrics/efficientnet_b0_metrics_20251101_123302.json\n",
      "Matrizes de confus√£o salvas: ../results/baseline/EXPW/plots/efficientnet_b0_confusion_20251101_123302.png\n",
      "Hist√≥rico de treinamento salvo: ../results/baseline/EXPW/plots/efficientnet_b0_history_20251101_123302.png\n",
      "\n",
      "Todos os resultados salvos para efficientnet_b0\n",
      "\n",
      "================================================================================\n",
      "TREINANDO: EFFICIENTVIT_M5\n",
      "================================================================================\n",
      "\n",
      "üîç Iniciando monitoramento: efficientvit_m5\n",
      "  ‚Ä¢ Initial RAM: 1605.62 MB\n",
      "  ‚Ä¢ Initial GPU: 16.25 MB\n",
      "Modelo 'efficientvit_m5' criado com sucesso\n",
      "   Total de par√¢metros: 12,091,035\n",
      "   Par√¢metros trein√°veis: 12,091,035\n",
      "\n",
      "√âpoca [1/100] - Tempo: 77.26s\n",
      "   Train Loss: 1.5725\n",
      "   Val Acc: 0.5454 | Val F1: 0.2956\n",
      "   Val Precision: 0.3787 | Val Recall: 0.2855\n",
      "   M√©trica Combinada: 0.3955\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientvit_m5_best.pth\n",
      "Early Stopping: Baseline estabelecida: 0.3955\n",
      "\n",
      "√âpoca [2/100] - Tempo: 76.43s\n",
      "   Train Loss: 1.2533\n",
      "   Val Acc: 0.5707 | Val F1: 0.3334\n",
      "   Val Precision: 0.3940 | Val Recall: 0.3191\n",
      "   M√©trica Combinada: 0.4283\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientvit_m5_best.pth\n",
      "Early Stopping: Melhoria detectada (0.4283, Delta=+0.0328)\n",
      "\n",
      "√âpoca [3/100] - Tempo: 76.51s\n",
      "   Train Loss: 1.1552\n",
      "   Val Acc: 0.5868 | Val F1: 0.3684\n",
      "   Val Precision: 0.5195 | Val Recall: 0.3473\n",
      "   M√©trica Combinada: 0.4558\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientvit_m5_best.pth\n",
      "Early Stopping: Melhoria detectada (0.4558, Delta=+0.0274)\n",
      "\n",
      "√âpoca [4/100] - Tempo: 76.94s\n",
      "   Train Loss: 1.0695\n",
      "   Val Acc: 0.5875 | Val F1: 0.3627\n",
      "   Val Precision: 0.4284 | Val Recall: 0.3481\n",
      "   M√©trica Combinada: 0.4526\n",
      "Early Stopping: Sem melhoria (1/15)\n",
      "\n",
      "√âpoca [5/100] - Tempo: 76.35s\n",
      "   Train Loss: 0.9774\n",
      "   Val Acc: 0.5786 | Val F1: 0.3802\n",
      "   Val Precision: 0.4403 | Val Recall: 0.3655\n",
      "   M√©trica Combinada: 0.4595\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientvit_m5_best.pth\n",
      "Early Stopping: Melhoria detectada (0.4595, Delta=+0.0038)\n",
      "\n",
      "√âpoca [6/100] - Tempo: 77.29s\n",
      "   Train Loss: 0.8907\n",
      "   Val Acc: 0.5774 | Val F1: 0.3766\n",
      "   Val Precision: 0.4393 | Val Recall: 0.3596\n",
      "   M√©trica Combinada: 0.4570\n",
      "Early Stopping: Sem melhoria (1/15)\n",
      "\n",
      "√âpoca [7/100] - Tempo: 75.68s\n",
      "   Train Loss: 0.7849\n",
      "   Val Acc: 0.5646 | Val F1: 0.3783\n",
      "   Val Precision: 0.4245 | Val Recall: 0.3635\n",
      "   M√©trica Combinada: 0.4528\n",
      "Early Stopping: Sem melhoria (2/15)\n",
      "\n",
      "√âpoca [8/100] - Tempo: 76.26s\n",
      "   Train Loss: 0.6977\n",
      "   Val Acc: 0.5619 | Val F1: 0.3920\n",
      "   Val Precision: 0.4234 | Val Recall: 0.3775\n",
      "   M√©trica Combinada: 0.4600\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientvit_m5_best.pth\n",
      "Early Stopping: Sem melhoria (3/15)\n",
      "\n",
      "√âpoca [9/100] - Tempo: 77.58s\n",
      "   Train Loss: 0.6215\n",
      "   Val Acc: 0.5585 | Val F1: 0.3899\n",
      "   Val Precision: 0.4186 | Val Recall: 0.3736\n",
      "   M√©trica Combinada: 0.4574\n",
      "Early Stopping: Sem melhoria (4/15)\n",
      "\n",
      "√âpoca [10/100] - Tempo: 76.42s\n",
      "   Train Loss: 0.5640\n",
      "   Val Acc: 0.5647 | Val F1: 0.3909\n",
      "   Val Precision: 0.4267 | Val Recall: 0.3733\n",
      "   M√©trica Combinada: 0.4604\n",
      "   Modelo salvo: ../results/baseline/EXPW/models/efficientvit_m5_best.pth\n",
      "Early Stopping: Sem melhoria (5/15)\n",
      "\n",
      "√âpoca [11/100] - Tempo: 76.38s\n",
      "   Train Loss: 0.5020\n",
      "   Val Acc: 0.5561 | Val F1: 0.3901\n",
      "   Val Precision: 0.4239 | Val Recall: 0.3747\n",
      "   M√©trica Combinada: 0.4565\n",
      "Early Stopping: Sem melhoria (6/15)\n",
      "\n",
      "√âpoca [12/100] - Tempo: 76.51s\n",
      "   Train Loss: 0.4611\n",
      "   Val Acc: 0.5565 | Val F1: 0.3849\n",
      "   Val Precision: 0.4124 | Val Recall: 0.3699\n",
      "   M√©trica Combinada: 0.4535\n",
      "Early Stopping: Sem melhoria (7/15)\n",
      "\n",
      "√âpoca [13/100] - Tempo: 75.88s\n",
      "   Train Loss: 0.4303\n",
      "   Val Acc: 0.5494 | Val F1: 0.3907\n",
      "   Val Precision: 0.4149 | Val Recall: 0.3766\n",
      "   M√©trica Combinada: 0.4541\n",
      "Early Stopping: Sem melhoria (8/15)\n",
      "\n",
      "√âpoca [14/100] - Tempo: 76.62s\n",
      "   Train Loss: 0.4083\n",
      "   Val Acc: 0.5491 | Val F1: 0.3890\n",
      "   Val Precision: 0.4231 | Val Recall: 0.3734\n",
      "   M√©trica Combinada: 0.4530\n",
      "Early Stopping: Sem melhoria (9/15)\n",
      "\n",
      "√âpoca [15/100] - Tempo: 76.20s\n",
      "   Train Loss: 0.3831\n",
      "   Val Acc: 0.5503 | Val F1: 0.3890\n",
      "   Val Precision: 0.4138 | Val Recall: 0.3746\n",
      "   M√©trica Combinada: 0.4535\n",
      "Early Stopping: Sem melhoria (10/15)\n",
      "\n",
      "√âpoca [16/100] - Tempo: 76.25s\n",
      "   Train Loss: 0.3647\n",
      "   Val Acc: 0.5409 | Val F1: 0.3842\n",
      "   Val Precision: 0.3981 | Val Recall: 0.3751\n",
      "   M√©trica Combinada: 0.4469\n",
      "Early Stopping: Sem melhoria (11/15)\n",
      "\n",
      "√âpoca [17/100] - Tempo: 76.91s\n",
      "   Train Loss: 0.3475\n",
      "   Val Acc: 0.5506 | Val F1: 0.3913\n",
      "   Val Precision: 0.4188 | Val Recall: 0.3754\n",
      "   M√©trica Combinada: 0.4551\n",
      "Early Stopping: Sem melhoria (12/15)\n",
      "\n",
      "√âpoca [18/100] - Tempo: 76.57s\n",
      "   Train Loss: 0.3367\n",
      "   Val Acc: 0.5460 | Val F1: 0.3893\n",
      "   Val Precision: 0.4124 | Val Recall: 0.3754\n",
      "   M√©trica Combinada: 0.4520\n",
      "Early Stopping: Sem melhoria (13/15)\n",
      "\n",
      "√âpoca [19/100] - Tempo: 76.00s\n",
      "   Train Loss: 0.3258\n",
      "   Val Acc: 0.5520 | Val F1: 0.3902\n",
      "   Val Precision: 0.4173 | Val Recall: 0.3740\n",
      "   M√©trica Combinada: 0.4549\n",
      "Early Stopping: Sem melhoria (14/15)\n",
      "\n",
      "√âpoca [20/100] - Tempo: 76.73s\n",
      "   Train Loss: 0.3117\n",
      "   Val Acc: 0.5535 | Val F1: 0.3898\n",
      "   Val Precision: 0.4260 | Val Recall: 0.3720\n",
      "   M√©trica Combinada: 0.4553\n",
      "Early Stopping: Sem melhoria (15/15)\n",
      "Early Stopping: Treinamento interrompido ap√≥s 15 √©pocas sem melhoria\n",
      "\n",
      "Early stopping ativado na √©poca 20\n",
      "\n",
      "======================================================================\n",
      "MONITORING REPORT: EFFICIENTVIT_M5\n",
      "======================================================================\n",
      "Total training time: 0:25:34\n",
      "Initial RAM: 1605.62 MB\n",
      "Final RAM: 1855.44 MB\n",
      "Peak RAM: 1855.47 MB\n",
      "Memory increase: 249.82 MB\n",
      "Peak GPU Memory: 3119.31 MB\n",
      "Final GPU Memory: 211.16 MB\n",
      "======================================================================\n",
      "\n",
      "Avaliando modelo no conjunto de teste...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:06<00:00, 43.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTADOS DA AVALIA√á√ÉO - CONJUNTO DE TESTE\n",
      "======================================================================\n",
      "Acur√°cia: 0.5645\n",
      "\n",
      "M√©tricas Macro:\n",
      "   Precis√£o: 0.4268\n",
      "   Recall: 0.3741\n",
      "   F1-Score: 0.3917\n",
      "\n",
      "F1-Score Weighted: 0.5511\n",
      "======================================================================\n",
      "\n",
      "\n",
      "M√©tricas por Classe:\n",
      "Classe          Precis√£o     Recall       F1-Score     Suporte   \n",
      "----------------------------------------------------------------------\n",
      "Raiva           0.4603       0.3200       0.3775       725       \n",
      "Nojo            0.1978       0.0908       0.1245       782       \n",
      "Medo            0.1981       0.0986       0.1317       213       \n",
      "Felicidade      0.6478       0.6635       0.6556       5343      \n",
      "Neutro          0.5758       0.6821       0.6245       6590      \n",
      "Tristeza        0.4386       0.3420       0.3843       2067      \n",
      "Surpresa        0.4690       0.4219       0.4442       1382      \n",
      "----------------------------------------------------------------------\n",
      "M√©tricas salvas: ../results/baseline/EXPW/metrics/efficientvit_m5_metrics_20251101_125844.json\n",
      "Matrizes de confus√£o salvas: ../results/baseline/EXPW/plots/efficientvit_m5_confusion_20251101_125844.png\n",
      "Hist√≥rico de treinamento salvo: ../results/baseline/EXPW/plots/efficientvit_m5_history_20251101_125844.png\n",
      "\n",
      "Todos os resultados salvos para efficientvit_m5\n",
      "\n",
      "================================================================================\n",
      "COMPARA√á√ÉO FINAL - TODOS OS MODELOS\n",
      "================================================================================\n",
      "\n",
      "     model_name  test_accuracy  test_f1_macro  test_f1_weighted  epochs_completed\n",
      "       resnet50       0.601626       0.432454          0.586502                19\n",
      "efficientnet_b0       0.613495       0.419332          0.591015                19\n",
      "efficientvit_m5       0.564495       0.391749          0.551130                20\n",
      "\n",
      "Compara√ß√£o salva: ../results/baseline/EXPW/metrics/model_comparison.csv\n",
      "\n",
      "Melhor modelo (por acur√°cia): efficientnet_b0 - 0.6135\n",
      "\n",
      "================================================================================\n",
      "TREINAMENTO BASELINE CONCLU√çDO\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXECUTAR\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nInterrompido pelo usu√°rio\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nERRO: {type(e).__name__}\")\n",
    "        print(f\"Mensagem: {e}\")\n",
    "        import traceback\n",
    "        print(\"\\nTraceback:\")\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
