{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "=============================================================================\n",
    "BALANCEAMENTO TOGETHER COM VALIDA√á√ÉO DE CAMINHOS\n",
    "=============================================================================\n",
    "Aplica oversampling + augmentation leve no dataset TOGETHER pr√©-processado.\n",
    "\n",
    "ESTRAT√âGIA:\n",
    "- Oversampling: Duplica at√© a classe maior\n",
    "- Augmentation: LEVE (p=0.3) - conservador\n",
    "- Preserva todas as imagens originais\n",
    "- TEST sem modifica√ß√£o (apenas c√≥pia)\n",
    "- Valida√ß√£o completa de diret√≥rios\n",
    "\n",
    "CAMINHOS FIXOS:\n",
    "- INPUT:  ../data/processed/TOGETHER\n",
    "- OUTPUT: ../data/augmented/TOGETHER\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# CONFIGURA√á√ïES\n",
    "# =============================================================================\n",
    "\n",
    "BASE_PATH = r'../data/processed/TOGETHER'\n",
    "OUTPUT_PATH = r'../data/augmented/TOGETHER'\n",
    "\n",
    "# Configura√ß√µes de Augmentation (LEVE - conservador)\n",
    "AUGMENTATION_PROBABILITY = 0.3  # 30% chance (leve)\n",
    "ROTATION_LIMIT = 10\n",
    "BRIGHTNESS_LIMIT = 0.15\n",
    "CONTRAST_LIMIT = 0.15\n",
    "PIXEL_DROPOUT_PROB = 0.005\n",
    "\n",
    "# Controle\n",
    "VERBOSE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce3bd6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VALIDA√á√ÉO DE CAMINHOS\n",
    "# =============================================================================\n",
    "\n",
    "def validate_and_create_paths():\n",
    "    \"\"\"\n",
    "    Valida diret√≥rio de entrada e cria diret√≥rio de sa√≠da.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (input_exists: bool, error_message: str)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VALIDA√á√ÉO DE CAMINHOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Verificar INPUT\n",
    "    print(f\"\\nüîç Verificando INPUT:\")\n",
    "    print(f\"   Caminho: {BASE_PATH}\")\n",
    "    \n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        error_msg = f\"‚ùå ERRO: Diret√≥rio de entrada n√£o encontrado!\\n   {BASE_PATH}\"\n",
    "        return False, error_msg\n",
    "    \n",
    "    if not os.path.isdir(BASE_PATH):\n",
    "        error_msg = f\"‚ùå ERRO: Caminho existe mas n√£o √© um diret√≥rio!\\n   {BASE_PATH}\"\n",
    "        return False, error_msg\n",
    "    \n",
    "    # Verificar estrutura do dataset\n",
    "    train_path = os.path.join(BASE_PATH, 'train')\n",
    "    test_path = os.path.join(BASE_PATH, 'test')\n",
    "    \n",
    "    if not os.path.exists(train_path):\n",
    "        error_msg = f\"‚ùå ERRO: Pasta 'train' n√£o encontrada!\\n   {train_path}\"\n",
    "        return False, error_msg\n",
    "    \n",
    "    if not os.path.exists(test_path):\n",
    "        error_msg = f\"‚ùå ERRO: Pasta 'test' n√£o encontrada!\\n   {test_path}\"\n",
    "        return False, error_msg\n",
    "    \n",
    "    print(f\"   ‚úÖ Diret√≥rio existe\")\n",
    "    print(f\"   ‚úÖ Estrutura v√°lida (train + test)\")\n",
    "    \n",
    "    # Contar arquivos\n",
    "    total_train = sum([len([f for f in os.listdir(os.path.join(train_path, d)) \n",
    "                            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "                       for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))])\n",
    "    \n",
    "    total_test = sum([len([f for f in os.listdir(os.path.join(test_path, d)) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "                      for d in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, d))])\n",
    "    \n",
    "    print(f\"   üìä Imagens encontradas:\")\n",
    "    print(f\"      ‚Ä¢ Train: {total_train:,} imagens\")\n",
    "    print(f\"      ‚Ä¢ Test:  {total_test:,} imagens\")\n",
    "    \n",
    "    # Criar OUTPUT\n",
    "    print(f\"\\nüìÅ Criando OUTPUT:\")\n",
    "    print(f\"   Caminho: {OUTPUT_PATH}\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "        print(f\"   ‚úÖ Diret√≥rio criado/verificado\")\n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå ERRO: N√£o foi poss√≠vel criar diret√≥rio de sa√≠da!\\n   {e}\"\n",
    "        return False, error_msg\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ VALIDA√á√ÉO CONCLU√çDA COM SUCESSO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return True, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f4bd4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PIPELINE DE AUGMENTATION LEVE\n",
    "# =============================================================================\n",
    "\n",
    "def create_augmentation_pipeline():\n",
    "    \"\"\"\n",
    "    Augmentation LEVE e CONSERVADOR para balanceamento offline.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.OneOf([\n",
    "            A.HorizontalFlip(p=1.0),\n",
    "            A.Rotate(limit=ROTATION_LIMIT, p=1.0),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.05,\n",
    "                scale_limit=0.05,\n",
    "                rotate_limit=ROTATION_LIMIT,\n",
    "                p=1.0\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=BRIGHTNESS_LIMIT,\n",
    "                contrast_limit=CONTRAST_LIMIT,\n",
    "                p=1.0\n",
    "            ),\n",
    "            A.GaussNoise(var_limit=(5.0, 20.0), p=1.0),\n",
    "            A.PixelDropout(dropout_prob=PIXEL_DROPOUT_PROB, p=1.0),\n",
    "            A.ImageCompression(quality_lower=90, quality_upper=100, p=1.0),\n",
    "            A.Blur(blur_limit=3, p=1.0),\n",
    "        ], p=AUGMENTATION_PROBABILITY),\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "976ca41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FUN√á√ïES DE AN√ÅLISE\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_dataset_distribution(dataset_path):\n",
    "    \"\"\"\n",
    "    Analisa distribui√ß√£o de classes no dataset.\n",
    "    \"\"\"\n",
    "    distribution = {}\n",
    "    \n",
    "    for emotion_folder in os.listdir(dataset_path):\n",
    "        emotion_path = os.path.join(dataset_path, emotion_folder)\n",
    "        \n",
    "        if not os.path.isdir(emotion_path):\n",
    "            continue\n",
    "        \n",
    "        image_files = [\n",
    "            f for f in os.listdir(emotion_path)\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))\n",
    "        ]\n",
    "        \n",
    "        distribution[emotion_folder] = len(image_files)\n",
    "    \n",
    "    return distribution\n",
    "\n",
    "\n",
    "def calculate_oversampling_strategy(distribution):\n",
    "    \"\"\"\n",
    "    Calcula estrat√©gia de oversampling at√© classe maior.\n",
    "    \"\"\"\n",
    "    target_samples = max(distribution.values())\n",
    "    strategy = {}\n",
    "    \n",
    "    for emotion, count in distribution.items():\n",
    "        if count < target_samples:\n",
    "            copies_needed = target_samples // count\n",
    "            remainder = target_samples % count\n",
    "            \n",
    "            strategy[emotion] = {\n",
    "                'original_count': count,\n",
    "                'target_count': target_samples,\n",
    "                'full_copies': copies_needed,\n",
    "                'partial_samples': remainder,\n",
    "                'total_new': target_samples - count\n",
    "            }\n",
    "        else:\n",
    "            strategy[emotion] = {\n",
    "                'original_count': count,\n",
    "                'target_count': count,\n",
    "                'full_copies': 1,\n",
    "                'partial_samples': 0,\n",
    "                'total_new': 0\n",
    "            }\n",
    "    \n",
    "    return strategy, target_samples\n",
    "\n",
    "\n",
    "def print_balancing_report(dataset_name, distribution, strategy, target_samples):\n",
    "    \"\"\"\n",
    "    Imprime relat√≥rio de balanceamento.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"RELAT√ìRIO DE BALANCEAMENTO - {dataset_name}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüìä Distribui√ß√£o ORIGINAL (Train):\")\n",
    "    total_original = sum(distribution.values())\n",
    "    for emotion, count in sorted(distribution.items()):\n",
    "        percentage = (count / total_original) * 100\n",
    "        print(f\"  ‚Ä¢ {emotion:15s}: {count:5d} imagens ({percentage:5.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Target por classe: {target_samples} imagens\")\n",
    "    \n",
    "    total_new = sum(s['total_new'] for s in strategy.values())\n",
    "    total_final = total_original + total_new\n",
    "    \n",
    "    print(f\"\\nüìà Mudan√ßas por classe:\")\n",
    "    for emotion, info in sorted(strategy.items()):\n",
    "        if info['total_new'] > 0:\n",
    "            print(f\"  ‚Ä¢ {emotion:15s}: {info['original_count']:5d} ‚Üí {info['target_count']:5d} \"\n",
    "                  f\"(+{info['total_new']:5d} novas)\")\n",
    "        else:\n",
    "            print(f\"  ‚Ä¢ {emotion:15s}: {info['original_count']:5d} (sem mudan√ßa)\")\n",
    "    \n",
    "    print(f\"\\nüì¶ Totais (Train):\")\n",
    "    print(f\"  ‚Ä¢ Imagens originais: {total_original:,}\")\n",
    "    print(f\"  ‚Ä¢ Imagens a criar:   {total_new:,}\")\n",
    "    print(f\"  ‚Ä¢ Total final:       {total_final:,}\")\n",
    "    print(f\"  ‚Ä¢ Aumento:           {(total_new/total_original)*100:.1f}%\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44269cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROCESSAMENTO\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def apply_augmentation_to_image(image, transform):\n",
    "    \"\"\"\n",
    "    Aplica augmentation a uma imagem.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        augmented = transform(image=image)\n",
    "        return augmented['image']\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"‚ö†Ô∏è Erro no augmentation: {e}\")\n",
    "        return image\n",
    "\n",
    "\n",
    "def balance_dataset(strategy, target_samples, transform):\n",
    "    \"\"\"\n",
    "    Balanceia dataset TOGETHER com oversampling + augmentation.\n",
    "    TRAIN: balanceamento completo\n",
    "    TEST: apenas c√≥pia (sem modifica√ß√£o)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(\"PROCESSANDO TOGETHER\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    stats = {\n",
    "        'images_copied': 0,\n",
    "        'images_created': 0,\n",
    "        'augmentations_applied': 0,\n",
    "        'errors': 0\n",
    "    }\n",
    "    \n",
    "    # Processar cada split\n",
    "    for split_name in ['train', 'test']:\n",
    "        input_split_path = os.path.join(BASE_PATH, split_name)\n",
    "        output_split_path = os.path.join(OUTPUT_PATH, split_name)\n",
    "        \n",
    "        print(f\"\\nüìÇ Processando split: {split_name}\")\n",
    "        \n",
    "        # ============================================================\n",
    "        # TEST: apenas copia, SEM balanceamento/augmentation\n",
    "        # ============================================================\n",
    "        if split_name == 'test':\n",
    "            print(\"  ‚ÑπÔ∏è  TEST: Copiando imagens originais SEM modifica√ß√£o\")\n",
    "            \n",
    "            for emotion in strategy.keys():\n",
    "                emotion_input_path = os.path.join(input_split_path, emotion)\n",
    "                emotion_output_path = os.path.join(output_split_path, emotion)\n",
    "                \n",
    "                if not os.path.exists(emotion_input_path):\n",
    "                    continue\n",
    "                \n",
    "                os.makedirs(emotion_output_path, exist_ok=True)\n",
    "                \n",
    "                image_files = [\n",
    "                    f for f in os.listdir(emotion_input_path)\n",
    "                    if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))\n",
    "                ]\n",
    "                \n",
    "                for img_file in image_files:\n",
    "                    src = os.path.join(emotion_input_path, img_file)\n",
    "                    dst = os.path.join(emotion_output_path, img_file)\n",
    "                    \n",
    "                    try:\n",
    "                        shutil.copy2(src, dst)\n",
    "                        stats['images_copied'] += 1\n",
    "                    except Exception as e:\n",
    "                        if VERBOSE:\n",
    "                            print(f\"    ‚úó Erro ao copiar {img_file}: {e}\")\n",
    "                        stats['errors'] += 1\n",
    "                \n",
    "                print(f\"  ‚Ä¢ {emotion:15s}: {len(image_files)} imagens copiadas\")\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        # ============================================================\n",
    "        # TRAIN: balanceamento + augmentation\n",
    "        # ============================================================\n",
    "        print(\"  ‚ÑπÔ∏è  TRAIN: Aplicando balanceamento + augmentation\")\n",
    "        \n",
    "        for emotion, info in strategy.items():\n",
    "            emotion_input_path = os.path.join(input_split_path, emotion)\n",
    "            emotion_output_path = os.path.join(output_split_path, emotion)\n",
    "            \n",
    "            if not os.path.exists(emotion_input_path):\n",
    "                continue\n",
    "            \n",
    "            os.makedirs(emotion_output_path, exist_ok=True)\n",
    "            \n",
    "            image_files = [\n",
    "                f for f in os.listdir(emotion_input_path)\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))\n",
    "            ]\n",
    "            \n",
    "            if not image_files:\n",
    "                continue\n",
    "            \n",
    "            print(f\"  ‚Ä¢ {emotion:15s}: {info['original_count']} ‚Üí {info['target_count']}\")\n",
    "            \n",
    "            # 1. COPIAR ORIGINAIS\n",
    "            for img_file in tqdm(image_files, desc=f\"    Copiando {emotion}\", leave=False):\n",
    "                src = os.path.join(emotion_input_path, img_file)\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                ext = os.path.splitext(img_file)[1]\n",
    "                dst = os.path.join(emotion_output_path, f\"original_{base_name}{ext}\")\n",
    "                \n",
    "                try:\n",
    "                    shutil.copy2(src, dst)\n",
    "                    stats['images_copied'] += 1\n",
    "                except Exception as e:\n",
    "                    if VERBOSE:\n",
    "                        print(f\"    ‚úó Erro ao copiar {img_file}: {e}\")\n",
    "                    stats['errors'] += 1\n",
    "            \n",
    "            # 2. GERAR AUMENTADAS\n",
    "            if info['total_new'] > 0:\n",
    "                augmentations_per_image = info['total_new'] // len(image_files)\n",
    "                remainder = info['total_new'] % len(image_files)\n",
    "                \n",
    "                for idx, img_file in enumerate(tqdm(image_files, \n",
    "                                                    desc=f\"    Aumentando {emotion}\", \n",
    "                                                    leave=False)):\n",
    "                    src_path = os.path.join(emotion_input_path, img_file)\n",
    "                    \n",
    "                    try:\n",
    "                        img = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        \n",
    "                        if img is None:\n",
    "                            stats['errors'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        num_augmentations = augmentations_per_image\n",
    "                        if idx < remainder:\n",
    "                            num_augmentations += 1\n",
    "                        \n",
    "                        for aug_idx in range(num_augmentations):\n",
    "                            augmented_img = apply_augmentation_to_image(img, transform)\n",
    "                            \n",
    "                            base_name = os.path.splitext(img_file)[0]\n",
    "                            ext = os.path.splitext(img_file)[1]\n",
    "                            aug_name = f\"aug{aug_idx:03d}_{base_name}{ext}\"\n",
    "                            aug_path = os.path.join(emotion_output_path, aug_name)\n",
    "                            \n",
    "                            cv2.imwrite(aug_path, augmented_img)\n",
    "                            stats['images_created'] += 1\n",
    "                            stats['augmentations_applied'] += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        if VERBOSE:\n",
    "                            print(f\"    ‚úó Erro ao processar {img_file}: {e}\")\n",
    "                        stats['errors'] += 1\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea938fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FUN√á√ÉO PRINCIPAL\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Fun√ß√£o principal - processa TOGETHER.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"BALANCEAMENTO TOGETHER - VERS√ÉO CORRIGIDA\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"INPUT:  {BASE_PATH}\")\n",
    "    print(f\"OUTPUT: {OUTPUT_PATH}\")\n",
    "    print(f\"Augmentation: OneOf com p={AUGMENTATION_PROBABILITY} (LEVE)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. VALIDAR CAMINHOS\n",
    "    is_valid, error_msg = validate_and_create_paths()\n",
    "    \n",
    "    if not is_valid:\n",
    "        print(f\"\\n{error_msg}\")\n",
    "        print(\"\\n‚ùå PROCESSAMENTO ABORTADO - Corrija os caminhos!\")\n",
    "        return\n",
    "    \n",
    "    # 2. CRIAR PIPELINE\n",
    "    print(\"\\nüîß Criando pipeline de augmentation...\")\n",
    "    transform = create_augmentation_pipeline()\n",
    "    print(\"‚úÖ Pipeline criado!\")\n",
    "    \n",
    "    # 3. ANALISAR TRAIN\n",
    "    train_path = os.path.join(BASE_PATH, 'train')\n",
    "    distribution = analyze_dataset_distribution(train_path)\n",
    "    \n",
    "    if not distribution:\n",
    "        print(f\"\\n‚ùå Nenhuma classe encontrada em {train_path}\")\n",
    "        return\n",
    "    \n",
    "    # 4. CALCULAR ESTRAT√âGIA\n",
    "    strategy, target_samples = calculate_oversampling_strategy(distribution)\n",
    "    print_balancing_report(\"TOGETHER\",distribution, strategy, target_samples)\n",
    "    \n",
    "    # 5. BALANCEAR\n",
    "    stats = balance_dataset(strategy, target_samples, transform)\n",
    "    \n",
    "    # 6. RELAT√ìRIO FINAL\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROCESSAMENTO CONCLU√çDO!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüìä Estat√≠sticas Finais:\")\n",
    "    print(f\"  ‚Ä¢ Imagens copiadas: {stats['images_copied']:,}\")\n",
    "    print(f\"  ‚Ä¢ Imagens criadas:  {stats['images_created']:,}\")\n",
    "    print(f\"  ‚Ä¢ Augmentations:    {stats['augmentations_applied']:,}\")\n",
    "    print(f\"  ‚Ä¢ Total final:      {stats['images_copied'] + stats['images_created']:,}\")\n",
    "    \n",
    "    if stats['errors'] > 0:\n",
    "        print(f\"  ‚ö†Ô∏è Erros: {stats['errors']}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataset balanceado salvo em:\")\n",
    "    print(f\"   {OUTPUT_PATH}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b22fb1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BALANCEAMENTO RAF-DB - VERS√ÉO CORRIGIDA\n",
      "================================================================================\n",
      "INPUT:  ../data/processed/RAF-DB\n",
      "OUTPUT: ../data/augmented/RAF-DB\n",
      "Augmentation: OneOf com p=0.3 (LEVE)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "VALIDA√á√ÉO DE CAMINHOS\n",
      "================================================================================\n",
      "\n",
      "üîç Verificando INPUT:\n",
      "   Caminho: ../data/processed/RAF-DB\n",
      "   ‚úÖ Diret√≥rio existe\n",
      "   ‚úÖ Estrutura v√°lida (train + test)\n",
      "   üìä Imagens encontradas:\n",
      "      ‚Ä¢ Train: 12,271 imagens\n",
      "      ‚Ä¢ Test:  3,068 imagens\n",
      "\n",
      "üìÅ Criando OUTPUT:\n",
      "   Caminho: ../data/augmented/RAF-DB\n",
      "   ‚úÖ Diret√≥rio criado/verificado\n",
      "\n",
      "================================================================================\n",
      "‚úÖ VALIDA√á√ÉO CONCLU√çDA COM SUCESSO\n",
      "================================================================================\n",
      "\n",
      "üîß Criando pipeline de augmentation...\n",
      "‚úÖ Pipeline criado!\n",
      "\n",
      "================================================================================\n",
      "RELAT√ìRIO DE BALANCEAMENTO - RAF-DB\n",
      "================================================================================\n",
      "\n",
      "üìä Distribui√ß√£o ORIGINAL (Train):\n",
      "  ‚Ä¢ Felicidade     :  4772 imagens (38.89%)\n",
      "  ‚Ä¢ Medo           :   281 imagens ( 2.29%)\n",
      "  ‚Ä¢ Neutro         :  2524 imagens (20.57%)\n",
      "  ‚Ä¢ Nojo           :   717 imagens ( 5.84%)\n",
      "  ‚Ä¢ Raiva          :   705 imagens ( 5.75%)\n",
      "  ‚Ä¢ Surpresa       :  1290 imagens (10.51%)\n",
      "  ‚Ä¢ Tristeza       :  1982 imagens (16.15%)\n",
      "\n",
      "üéØ Target por classe: 4772 imagens\n",
      "\n",
      "üìà Mudan√ßas por classe:\n",
      "  ‚Ä¢ Felicidade     :  4772 (sem mudan√ßa)\n",
      "  ‚Ä¢ Medo           :   281 ‚Üí  4772 (+ 4491 novas)\n",
      "  ‚Ä¢ Neutro         :  2524 ‚Üí  4772 (+ 2248 novas)\n",
      "  ‚Ä¢ Nojo           :   717 ‚Üí  4772 (+ 4055 novas)\n",
      "  ‚Ä¢ Raiva          :   705 ‚Üí  4772 (+ 4067 novas)\n",
      "  ‚Ä¢ Surpresa       :  1290 ‚Üí  4772 (+ 3482 novas)\n",
      "  ‚Ä¢ Tristeza       :  1982 ‚Üí  4772 (+ 2790 novas)\n",
      "\n",
      "üì¶ Totais (Train):\n",
      "  ‚Ä¢ Imagens originais: 12,271\n",
      "  ‚Ä¢ Imagens a criar:   21,133\n",
      "  ‚Ä¢ Total final:       33,404\n",
      "  ‚Ä¢ Aumento:           172.2%\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PROCESSANDO RAF-DB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÇ Processando split: train\n",
      "  ‚ÑπÔ∏è  TRAIN: Aplicando balanceamento + augmentation\n",
      "  ‚Ä¢ Tristeza       : 1982 ‚Üí 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Copiando Tristeza:   0%|          | 0/1982 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ Raiva          : 705 ‚Üí 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ Neutro         : 2524 ‚Üí 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ Surpresa       : 1290 ‚Üí 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ Felicidade     : 4772 ‚Üí 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ Medo           : 281 ‚Üí 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Ä¢ Nojo           : 717 ‚Üí 4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processando split: test\n",
      "  ‚ÑπÔ∏è  TEST: Copiando imagens originais SEM modifica√ß√£o\n",
      "  ‚Ä¢ Tristeza       : 478 imagens copiadas\n",
      "  ‚Ä¢ Raiva          : 162 imagens copiadas\n",
      "  ‚Ä¢ Neutro         : 680 imagens copiadas\n",
      "  ‚Ä¢ Surpresa       : 329 imagens copiadas\n",
      "  ‚Ä¢ Felicidade     : 1185 imagens copiadas\n",
      "  ‚Ä¢ Medo           : 74 imagens copiadas\n",
      "  ‚Ä¢ Nojo           : 160 imagens copiadas\n",
      "\n",
      "================================================================================\n",
      "PROCESSAMENTO CONCLU√çDO!\n",
      "================================================================================\n",
      "\n",
      "üìä Estat√≠sticas Finais:\n",
      "  ‚Ä¢ Imagens copiadas: 15,339\n",
      "  ‚Ä¢ Imagens criadas:  21,133\n",
      "  ‚Ä¢ Augmentations:    21,133\n",
      "  ‚Ä¢ Total final:      36,472\n",
      "\n",
      "‚úÖ Dataset balanceado salvo em:\n",
      "   ../data/augmented/RAF-DB\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PONTO DE ENTRADA\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è Processamento interrompido pelo usu√°rio.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\n‚ùå ERRO FATAL: {type(e).__name__}\")\n",
    "        print(f\"Mensagem: {e}\")\n",
    "        \n",
    "        import traceback\n",
    "        print(\"\\nTraceback completo:\")\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
