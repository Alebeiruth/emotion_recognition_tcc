{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75afafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 1: Imports necess√°rios\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# M√©tricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Verificar GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Dispositivo: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Mem√≥ria: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08af26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 2: Configura√ß√£o Global\n",
    "CONFIG = {\n",
    "    # Caminhos\n",
    "    'data_path': '../data/processed/RAF-DB',\n",
    "    'output_path': '../models/raf_db',\n",
    "    'results_path': '../results/raf_db',\n",
    "    \n",
    "    # Dados\n",
    "    'num_classes': 7,\n",
    "    'emotions': ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise'],\n",
    "    'input_size': 224,\n",
    "    \n",
    "    # Treinamento\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    \n",
    "    # Early Stopping\n",
    "    'patience': 10,\n",
    "    'min_delta': 0.001,\n",
    "    \n",
    "    # Modelos\n",
    "    'models_to_train': ['resnet50', 'efficientnet_b0', 'vit_b_16'],\n",
    "    \n",
    "    # Seed para reprodutibilidade\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Criar diret√≥rios\n",
    "os.makedirs(CONFIG['output_path'], exist_ok=True)\n",
    "os.makedirs(CONFIG['results_path'], exist_ok=True)\n",
    "\n",
    "# Setar seeds\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['seed'])\n",
    "\n",
    "print(\"‚úÖ Configura√ß√µes carregadas\")\n",
    "print(f\"üìÅ Dados: {CONFIG['data_path']}\")\n",
    "print(f\"üíæ Modelos: {CONFIG['output_path']}\")\n",
    "print(f\"üìä Resultados: {CONFIG['results_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88dcad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 3: Classe Dataset para RAF-DB\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "class RAFDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        Dataset para carregar imagens pr√©-processadas do RAF-DB\n",
    "        \"\"\"\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.emotions = CONFIG['emotions']\n",
    "        self.emotion_to_idx = {emotion: idx for idx, emotion in enumerate(self.emotions)}\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Carregar caminhos e labels\n",
    "        for emotion in self.emotions:\n",
    "            emotion_dir = os.path.join(self.root_dir, emotion)\n",
    "            if os.path.exists(emotion_dir):\n",
    "                for img_name in os.listdir(emotion_dir):\n",
    "                    if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        self.images.append(os.path.join(emotion_dir, img_name))\n",
    "                        self.labels.append(self.emotion_to_idx[emotion])\n",
    "        \n",
    "        print(f\"üìÇ {split.upper()} Dataset:\")\n",
    "        print(f\"   Total de imagens: {len(self.images)}\")\n",
    "        \n",
    "        # Contar amostras por classe\n",
    "        label_counts = pd.Series(self.labels).value_counts().sort_index()\n",
    "        for idx, count in label_counts.items():\n",
    "            print(f\"   {self.emotions[idx]:12s}: {count:5d} imagens\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Carregar imagem\n",
    "        img_path = self.images[idx]\n",
    "        \n",
    "        # Ler como grayscale e converter para RGB\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "print(\"‚úÖ Classe Dataset criada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d213f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 4: Definir transforma√ß√µes\n",
    "# Normaliza√ß√£o ImageNet (mesmo para grayscale convertido para RGB)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transforma√ß√µes para treino (sem augmentation por enquanto)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['input_size'], CONFIG['input_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Transforma√ß√µes para valida√ß√£o/teste\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['input_size'], CONFIG['input_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Transforma√ß√µes definidas\")\n",
    "print(f\"   Input size: {CONFIG['input_size']}x{CONFIG['input_size']}\")\n",
    "print(f\"   Normaliza√ß√£o: ImageNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc89cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 5: Criar datasets e dataloaders\n",
    "print(\"üîÑ Carregando datasets...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Criar datasets\n",
    "train_dataset = RAFDataset(\n",
    "    root_dir=CONFIG['data_path'],\n",
    "    split='train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = RAFDataset(\n",
    "    root_dir=CONFIG['data_path'],\n",
    "    split='test',\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "# Criar dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ DataLoaders criados\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404305d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 6: Visualizar algumas amostras\n",
    "def show_batch(dataloader, num_samples=8):\n",
    "    \"\"\"Visualiza um batch de imagens\"\"\"\n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    # Desnormalizar imagens\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    images_denorm = images * std + mean\n",
    "    images_denorm = torch.clamp(images_denorm, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        img = images_denorm[i].permute(1, 2, 0).numpy()\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{CONFIG['emotions'][labels[i]]}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Amostras do Dataset RAF-DB', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar amostras\n",
    "show_batch(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 7: Definir fun√ß√µes para criar modelos\n",
    "def create_resnet50(num_classes=7):\n",
    "    \"\"\"Cria ResNet50 pr√©-treinada e ajusta para o n√∫mero de classes\"\"\"\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def create_efficientnet_b0(num_classes=7):\n",
    "    \"\"\"Cria EfficientNet-B0 pr√©-treinada\"\"\"\n",
    "    model = models.efficientnet_b0(pretrained=True)\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def create_vit_b_16(num_classes=7):\n",
    "    \"\"\"Cria Vision Transformer (ViT-B/16) pr√©-treinado\"\"\"\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    num_features = model.heads.head.in_features\n",
    "    model.heads.head = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Dicion√°rio de modelos\n",
    "MODEL_CREATORS = {\n",
    "    'resnet50': create_resnet50,\n",
    "    'efficientnet_b0': create_efficientnet_b0,\n",
    "    'vit_b_16': create_vit_b_16\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Arquiteturas de modelo definidas:\")\n",
    "for model_name in CONFIG['models_to_train']:\n",
    "    print(f\"   ‚Ä¢ {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d8afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 8: Implementar Early Stopping\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping para evitar overfitting\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_weights = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'   EarlyStopping counter: {self.counter}/{self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Salva o estado do modelo\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f'   Validation loss decreased ({self.best_loss:.4f}). Saving model...')\n",
    "        self.best_model_weights = model.state_dict().copy()\n",
    "    \n",
    "    def load_best_weights(self, model):\n",
    "        \"\"\"Carrega os melhores pesos\"\"\"\n",
    "        if self.best_model_weights is not None:\n",
    "            model.load_state_dict(self.best_model_weights)\n",
    "        return model\n",
    "\n",
    "print(\"‚úÖ Early Stopping implementado\")\n",
    "print(f\"   Patience: {CONFIG['patience']}\")\n",
    "print(f\"   Min delta: {CONFIG['min_delta']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d681b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 9: Fun√ß√µes de treinamento e valida√ß√£o\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Treina o modelo por uma √©poca\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Estat√≠sticas\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Atualizar barra de progresso\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Valida o modelo\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation', leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Guardar para m√©tricas\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_predictions, all_labels, all_probs\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de treinamento definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 10: Fun√ß√£o principal de treinamento com early stopping\n",
    "def train_model(model_name, train_loader, test_loader, device, config):\n",
    "    \"\"\"\n",
    "    Treina um modelo com early stopping e retorna m√©tricas\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ Treinando {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Criar modelo\n",
    "    model = MODEL_CREATORS[model_name](num_classes=config['num_classes'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Configurar treinamento\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), \n",
    "                          lr=config['learning_rate'],\n",
    "                          weight_decay=config['weight_decay'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    early_stopping = EarlyStopping(patience=config['patience'], \n",
    "                                  min_delta=config['min_delta'])\n",
    "    \n",
    "    # Hist√≥rico\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Loop de treinamento\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Treinar\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, \n",
    "                                           criterion, optimizer, device)\n",
    "        \n",
    "        # Validar\n",
    "        val_loss, val_acc, _, _, _ = validate_epoch(model, test_loader, \n",
    "                                                    criterion, device)\n",
    "        \n",
    "        # Atualizar scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Guardar hist√≥rico\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Print estat√≠sticas\n",
    "        print(f\"   Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"   Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\n‚èπÔ∏è Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Carregar melhores pesos\n",
    "    model = early_stopping.load_best_weights(model)\n",
    "    \n",
    "    # Avaliar modelo final\n",
    "    print(\"\\nüìä Avalia√ß√£o final no conjunto de teste...\")\n",
    "    val_loss, val_acc, predictions, labels, probs = validate_epoch(\n",
    "        model, test_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    return model, history, predictions, labels, probs\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de treinamento principal configurada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0640c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 11: Calcular todas as m√©tricas\n",
    "def calculate_metrics(y_true, y_pred, y_probs, class_names):\n",
    "    \"\"\"\n",
    "    Calcula todas as m√©tricas de avalia√ß√£o\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # M√©tricas b√°sicas\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    metrics['precision_macro'] = precision_score(y_true, y_pred, average='macro')\n",
    "    metrics['precision_weighted'] = precision_score(y_true, y_pred, average='weighted')\n",
    "    metrics['recall_macro'] = recall_score(y_true, y_pred, average='macro')\n",
    "    metrics['recall_weighted'] = recall_score(y_true, y_pred, average='weighted')\n",
    "    metrics['f1_macro'] = f1_score(y_true, y_pred, average='macro')\n",
    "    metrics['f1_weighted'] = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # M√©tricas por classe\n",
    "    metrics['precision_per_class'] = precision_score(y_true, y_pred, average=None)\n",
    "    metrics['recall_per_class'] = recall_score(y_true, y_pred, average=None)\n",
    "    metrics['f1_per_class'] = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Matriz de confus√£o\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # ROC-AUC (One-vs-Rest)\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(len(class_names))))\n",
    "    try:\n",
    "        metrics['roc_auc_ovr'] = roc_auc_score(y_true_bin, y_probs, multi_class='ovr')\n",
    "        metrics['roc_auc_ovo'] = roc_auc_score(y_true_bin, y_probs, multi_class='ovo')\n",
    "    except:\n",
    "        metrics['roc_auc_ovr'] = None\n",
    "        metrics['roc_auc_ovo'] = None\n",
    "    \n",
    "    # Classification report\n",
    "    metrics['classification_report'] = classification_report(\n",
    "        y_true, y_pred, target_names=class_names, output_dict=True\n",
    "    )\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_metrics_summary(metrics, class_names):\n",
    "    \"\"\"\n",
    "    Imprime resumo das m√©tricas\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä M√âTRICAS DE AVALIA√á√ÉO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüéØ M√©tricas Gerais:\")\n",
    "    print(f\"   Accuracy:           {metrics['accuracy']:.4f}\")\n",
    "    print(f\"   Precision (macro):  {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"   Recall (macro):     {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"   F1-Score (macro):   {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"   Precision (weighted): {metrics['precision_weighted']:.4f}\")\n",
    "    print(f\"   Recall (weighted):    {metrics['recall_weighted']:.4f}\")\n",
    "    print(f\"   F1-Score (weighted):  {metrics['f1_weighted']:.4f}\")\n",
    "    \n",
    "    if metrics['roc_auc_ovr']:\n",
    "        print(f\"   ROC-AUC (OvR):      {metrics['roc_auc_ovr']:.4f}\")\n",
    "        print(f\"   ROC-AUC (OvO):      {metrics['roc_auc_ovo']:.4f}\")\n",
    "    \n",
    "    print(\"\\nüìà M√©tricas por Classe:\")\n",
    "    print(f\"{'Emo√ß√£o':12s} | {'Precision':>10s} | {'Recall':>10s} | {'F1-Score':>10s}\")\n",
    "    print(\"-\"*50)\n",
    "    for i, emotion in enumerate(class_names):\n",
    "        print(f\"{emotion:12s} | {metrics['precision_per_class'][i]:10.4f} | \"\n",
    "              f\"{metrics['recall_per_class'][i]:10.4f} | \"\n",
    "              f\"{metrics['f1_per_class'][i]:10.4f}\")\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de m√©tricas configuradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933963a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 12: Fun√ß√µes de visualiza√ß√£o\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plota hist√≥rico de treinamento\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "    ax1.plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title(f'{model_name} - Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(history['train_acc'], label='Train Acc', linewidth=2)\n",
    "    ax2.plot(history['val_acc'], label='Val Acc', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title(f'{model_name} - Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Training History - {model_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, model_name):\n",
    "    \"\"\"Plota matriz de confus√£o\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Normalizar matriz\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Plotar\n",
    "    sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Normalized Value'},\n",
    "                ax=ax)\n",
    "    \n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_title(f'Confusion Matrix - {model_name}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_metrics_comparison(all_metrics, model_names):\n",
    "    \"\"\"Compara m√©tricas entre modelos\"\"\"\n",
    "    metrics_to_plot = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        values = [all_metrics[model][metric] for model in model_names]\n",
    "        \n",
    "        bars = axes[idx].bar(model_names, values, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "        axes[idx].set_title(metric.replace('_', ' ').title())\n",
    "        axes[idx].set_ylim([0, 1])\n",
    "        axes[idx].set_ylabel('Score')\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for bar, val in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                          f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.suptitle('Model Comparison - Main Metrics', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de visualiza√ß√£o configuradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 13: Treinar ResNet50\n",
    "resnet_model, resnet_history, resnet_pred, resnet_true, resnet_probs = train_model(\n",
    "    'resnet50', \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    device, \n",
    "    CONFIG\n",
    ")\n",
    "\n",
    "# Calcular m√©tricas\n",
    "resnet_metrics = calculate_metrics(\n",
    "    resnet_true, \n",
    "    resnet_pred, \n",
    "    resnet_probs,\n",
    "    CONFIG['emotions']\n",
    ")\n",
    "\n",
    "# Mostrar m√©tricas\n",
    "print_metrics_summary(resnet_metrics, CONFIG['emotions'])\n",
    "\n",
    "# Visualiza√ß√µes\n",
    "fig1 = plot_training_history(resnet_history, 'ResNet50')\n",
    "plt.show()\n",
    "\n",
    "fig2 = plot_confusion_matrix(resnet_metrics['confusion_matrix'], \n",
    "                             CONFIG['emotions'], 'ResNet50')\n",
    "plt.show()\n",
    "\n",
    "# Salvar modelo\n",
    "torch.save({\n",
    "    'model_state_dict': resnet_model.state_dict(),\n",
    "    'metrics': resnet_metrics,\n",
    "    'history': resnet_history,\n",
    "    'config': CONFIG\n",
    "}, os.path.join(CONFIG['output_path'], 'resnet50_baseline.pth'))\n",
    "\n",
    "print(\"‚úÖ ResNet50 treinado e salvo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ea191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 14: Treinar EfficientNet-B0\n",
    "efficientnet_model, efficientnet_history, efficientnet_pred, efficientnet_true, efficientnet_probs = train_model(\n",
    "    'efficientnet_b0', \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    device, \n",
    "    CONFIG\n",
    ")\n",
    "\n",
    "# Calcular m√©tricas\n",
    "efficientnet_metrics = calculate_metrics(\n",
    "    efficientnet_true, \n",
    "    efficientnet_pred, \n",
    "    efficientnet_probs,\n",
    "    CONFIG['emotions']\n",
    ")\n",
    "\n",
    "# Mostrar m√©tricas\n",
    "print_metrics_summary(efficientnet_metrics, CONFIG['emotions'])\n",
    "\n",
    "# Visualiza√ß√µes\n",
    "fig1 = plot_training_history(efficientnet_history, 'EfficientNet-B0')\n",
    "plt.show()\n",
    "\n",
    "fig2 = plot_confusion_matrix(efficientnet_metrics['confusion_matrix'], \n",
    "                             CONFIG['emotions'], 'EfficientNet-B0')\n",
    "plt.show()\n",
    "\n",
    "# Salvar modelo\n",
    "torch.save({\n",
    "    'model_state_dict': efficientnet_model.state_dict(),\n",
    "    'metrics': efficientnet_metrics,\n",
    "    'history': efficientnet_history,\n",
    "    'config': CONFIG\n",
    "}, os.path.join(CONFIG['output_path'], 'efficientnet_b0_baseline.pth'))\n",
    "\n",
    "print(\"‚úÖ EfficientNet-B0 treinado e salvo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5690ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 15: Treinar Vision Transformer\n",
    "vit_model, vit_history, vit_pred, vit_true, vit_probs = train_model(\n",
    "    'vit_b_16', \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    device, \n",
    "    CONFIG\n",
    ")\n",
    "\n",
    "# Calcular m√©tricas\n",
    "vit_metrics = calculate_metrics(\n",
    "    vit_true, \n",
    "    vit_pred, \n",
    "    vit_probs,\n",
    "    CONFIG['emotions']\n",
    ")\n",
    "\n",
    "# Mostrar m√©tricas\n",
    "print_metrics_summary(vit_metrics, CONFIG['emotions'])\n",
    "\n",
    "# Visualiza√ß√µes\n",
    "fig1 = plot_training_history(vit_history, 'ViT-B/16')\n",
    "plt.show()\n",
    "\n",
    "fig2 = plot_confusion_matrix(vit_metrics['confusion_matrix'], \n",
    "                             CONFIG['emotions'], 'ViT-B/16')\n",
    "plt.show()\n",
    "\n",
    "# Salvar modelo\n",
    "torch.save({\n",
    "    'model_state_dict': vit_model.state_dict(),\n",
    "    'metrics': vit_metrics,\n",
    "    'history': vit_history,\n",
    "    'config': CONFIG\n",
    "}, os.path.join(CONFIG['output_path'], 'vit_b_16_baseline.pth'))\n",
    "\n",
    "print(\"‚úÖ Vision Transformer treinado e salvo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 16: Comparar todos os modelos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ COMPARA√á√ÉO DE MODELOS (BASELINE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Consolidar m√©tricas\n",
    "all_metrics = {\n",
    "    'ResNet50': resnet_metrics,\n",
    "    'EfficientNet-B0': efficientnet_metrics,\n",
    "    'ViT-B/16': vit_metrics\n",
    "}\n",
    "\n",
    "# Criar tabela comparativa\n",
    "comparison_data = []\n",
    "for model_name, metrics in all_metrics.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "        'Precision (macro)': f\"{metrics['precision_macro']:.4f}\",\n",
    "        'Recall (macro)': f\"{metrics['recall_macro']:.4f}\",\n",
    "        'F1-Score (macro)': f\"{metrics['f1_macro']:.4f}\",\n",
    "        'F1-Score (weighted)': f\"{metrics['f1_weighted']:.4f}\",\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\nüìä Tabela Comparativa:\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Identificar melhor modelo\n",
    "best_model = max(all_metrics.items(), key=lambda x: x[1]['accuracy'])\n",
    "print(f\"\\nü•á Melhor modelo (por accuracy): {best_model[0]} - {best_model[1]['accuracy']:.4f}\")\n",
    "\n",
    "# Plotar compara√ß√£o\n",
    "fig = plot_metrics_comparison(all_metrics, list(all_metrics.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eed45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 17: An√°lise detalhada por classe\n",
    "def analyze_class_performance(all_metrics, emotions):\n",
    "    \"\"\"Analisa performance por classe em todos os modelos\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for idx, metric_type in enumerate(['precision_per_class', 'recall_per_class', 'f1_per_class']):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        x = np.arange(len(emotions))\n",
    "        width = 0.25\n",
    "        \n",
    "        for i, (model_name, metrics) in enumerate(all_metrics.items()):\n",
    "            values = metrics[metric_type]\n",
    "            ax.bar(x + i*width, values, width, label=model_name)\n",
    "        \n",
    "        ax.set_xlabel('Emotion')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_title(metric_type.replace('_', ' ').title().replace('Per Class', ''))\n",
    "        ax.set_xticks(x + width)\n",
    "        ax.set_xticklabels(emotions, rotation=45)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Performance by Emotion Class', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Executar an√°lise\n",
    "fig = analyze_class_performance(all_metrics, CONFIG['emotions'])\n",
    "plt.show()\n",
    "\n",
    "# Identificar classes problem√°ticas\n",
    "print(\"\\nüîç An√°lise de Classes Problem√°ticas:\")\n",
    "for emotion_idx, emotion in enumerate(CONFIG['emotions']):\n",
    "    print(f\"\\n{emotion}:\")\n",
    "    for model_name, metrics in all_metrics.items():\n",
    "        f1 = metrics['f1_per_class'][emotion_idx]\n",
    "        print(f\"   {model_name:15s}: F1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcf736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 18: Salvar todos os resultados para compara√ß√£o futura\n",
    "import pickle\n",
    "\n",
    "# Consolidar todos os resultados\n",
    "baseline_results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'config': CONFIG,\n",
    "    'models': {\n",
    "        'resnet50': {\n",
    "            'metrics': resnet_metrics,\n",
    "            'history': resnet_history,\n",
    "            'predictions': resnet_pred,\n",
    "            'true_labels': resnet_true,\n",
    "            'probabilities': resnet_probs\n",
    "        },\n",
    "        'efficientnet_b0': {\n",
    "            'metrics': efficientnet_metrics,\n",
    "            'history': efficientnet_history,\n",
    "            'predictions': efficientnet_pred,\n",
    "            'true_labels': efficientnet_true,\n",
    "            'probabilities': efficientnet_probs\n",
    "        },\n",
    "        'vit_b_16': {\n",
    "            'metrics': vit_metrics,\n",
    "            'history': vit_history,\n",
    "            'predictions': vit_pred,\n",
    "            'true_labels': vit_true,\n",
    "            'probabilities': vit_probs\n",
    "        }\n",
    "    },\n",
    "    'comparison': df_comparison.to_dict()\n",
    "}\n",
    "\n",
    "# Salvar em diferentes formatos\n",
    "# 1. Pickle (preserva tudo)\n",
    "with open(os.path.join(CONFIG['results_path'], 'baseline_results.pkl'), 'wb') as f:\n",
    "    pickle.dump(baseline_results, f)\n",
    "\n",
    "# 2. JSON (apenas m√©tricas, sem arrays numpy)\n",
    "json_results = {\n",
    "    'timestamp': baseline_results['timestamp'],\n",
    "    'config': CONFIG,\n",
    "    'models': {}\n",
    "}\n",
    "\n",
    "for model_name in ['resnet50', 'efficientnet_b0', 'vit_b_16']:\n",
    "    json_results['models'][model_name] = {\n",
    "        'accuracy': float(baseline_results['models'][model_name]['metrics']['accuracy']),\n",
    "        'precision_macro': float(baseline_results['models'][model_name]['metrics']['precision_macro']),\n",
    "        'recall_macro': float(baseline_results['models'][model_name]['metrics']['recall_macro']),\n",
    "        'f1_macro': float(baseline_results['models'][model_name]['metrics']['f1_macro']),\n",
    "        'f1_weighted': float(baseline_results['models'][model_name]['metrics']['f1_weighted']),\n",
    "    }\n",
    "\n",
    "with open(os.path.join(CONFIG['results_path'], 'baseline_metrics.json'), 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "# 3. CSV com m√©tricas principais\n",
    "df_comparison.to_csv(os.path.join(CONFIG['results_path'], 'baseline_comparison.csv'), index=False)\n",
    "\n",
    "print(\"‚úÖ Resultados salvos em:\")\n",
    "print(f\"   ‚Ä¢ {CONFIG['results_path']}/baseline_results.pkl\")\n",
    "print(f\"   ‚Ä¢ {CONFIG['results_path']}/baseline_metrics.json\")\n",
    "print(f\"   ‚Ä¢ {CONFIG['results_path']}/baseline_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 19: Gerar relat√≥rio final\n",
    "def generate_report(all_metrics, config):\n",
    "    \"\"\"Gera relat√≥rio em texto com todos os resultados\"\"\"\n",
    "    \n",
    "    report = []\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(\"RELAT√ìRIO DE TREINAMENTO - MODELOS BASELINE RAF-DB\")\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(f\"\\nData: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report.append(f\"Dataset: RAF-DB (Preprocessado)\")\n",
    "    report.append(f\"Dispositivo: {device}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"-\"*80)\n",
    "    report.append(\"CONFIGURA√á√ïES DE TREINAMENTO:\")\n",
    "    report.append(\"-\"*80)\n",
    "    report.append(f\"Batch Size: {config['batch_size']}\")\n",
    "    report.append(f\"Learning Rate: {config['learning_rate']}\")\n",
    "    report.append(f\"Weight Decay: {config['weight_decay']}\")\n",
    "    report.append(f\"Max Epochs: {config['num_epochs']}\")\n",
    "    report.append(f\"Early Stopping Patience: {config['patience']}\")\n",
    "    report.append(f\"Input Size: {config['input_size']}x{config['input_size']}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"-\"*80)\n",
    "    report.append(\"RESULTADOS POR MODELO:\")\n",
    "    report.append(\"-\"*80)\n",
    "    \n",
    "    for model_name, metrics in all_metrics.items():\n",
    "        report.append(f\"\\n### {model_name}\")\n",
    "        report.append(f\"   Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        report.append(f\"   Precision (macro): {metrics['precision_macro']:.4f}\")\n",
    "        report.append(f\"   Recall (macro): {metrics['recall_macro']:.4f}\")\n",
    "        report.append(f\"   F1-Score (macro): {metrics['f1_macro']:.4f}\")\n",
    "        report.append(f\"   F1-Score (weighted): {metrics['f1_weighted']:.4f}\")\n",
    "        if metrics['roc_auc_ovr']:\n",
    "            report.append(f\"   ROC-AUC (OvR): {metrics['roc_auc_ovr']:.4f}\")\n",
    "    \n",
    "    # Melhor modelo\n",
    "    best_model = max(all_metrics.items(), key=lambda x: x[1]['accuracy'])\n",
    "    report.append(\"\\n\" + \"-\"*80)\n",
    "    report.append(\"MELHOR MODELO:\")\n",
    "    report.append(\"-\"*80)\n",
    "    report.append(f\"Modelo: {best_model[0]}\")\n",
    "    report.append(f\"Accuracy: {best_model[1]['accuracy']:.4f}\")\n",
    "    \n",
    "    # Classes problem√°ticas\n",
    "    report.append(\"\\n\" + \"-\"*80)\n",
    "    report.append(\"AN√ÅLISE POR CLASSE (F1-Score):\")\n",
    "    report.append(\"-\"*80)\n",
    "    \n",
    "    for emotion_idx, emotion in enumerate(config['emotions']):\n",
    "        report.append(f\"\\n{emotion}:\")\n",
    "        for model_name, metrics in all_metrics.items():\n",
    "            f1 = metrics['f1_per_class'][emotion_idx]\n",
    "            report.append(f\"   {model_name}: {f1:.4f}\")\n",
    "    \n",
    "    # Identificar classe mais dif√≠cil\n",
    "    avg_f1_per_class = {}\n",
    "    for emotion_idx, emotion in enumerate(config['emotions']):\n",
    "        avg_f1 = np.mean([m['f1_per_class'][emotion_idx] for m in all_metrics.values()])\n",
    "        avg_f1_per_class[emotion] = avg_f1\n",
    "    \n",
    "    hardest_class = min(avg_f1_per_class.items(), key=lambda x: x[1])\n",
    "    easiest_class = max(avg_f1_per_class.items(), key=lambda x: x[1])\n",
    "    \n",
    "    report.append(\"\\n\" + \"-\"*80)\n",
    "    report.append(\"INSIGHTS:\")\n",
    "    report.append(\"-\"*80)\n",
    "    report.append(f\"Classe mais f√°cil: {easiest_class[0]} (F1 m√©dio: {easiest_class[1]:.4f})\")\n",
    "    report.append(f\"Classe mais dif√≠cil: {hardest_class[0]} (F1 m√©dio: {hardest_class[1]:.4f})\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"FIM DO RELAT√ìRIO\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "# Gerar e salvar relat√≥rio\n",
    "report = generate_report(all_metrics, CONFIG)\n",
    "print(report)\n",
    "\n",
    "# Salvar relat√≥rio em arquivo\n",
    "with open(os.path.join(CONFIG['results_path'], 'baseline_report.txt'), 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\nüìÑ Relat√≥rio salvo em: {CONFIG['results_path']}/baseline_report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd853c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√©lula 20: Preparar estrutura para compara√ß√£o futura\n",
    "comparison_structure = {\n",
    "    'baseline': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'data_type': 'original_preprocessed',\n",
    "        'models': {}\n",
    "    },\n",
    "    'augmented': {\n",
    "        'timestamp': None,\n",
    "        'data_type': 'with_augmentation',\n",
    "        'models': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Preencher com resultados baseline\n",
    "for model_name in ['resnet50', 'efficientnet_b0', 'vit_b_16']:\n",
    "    model_data = baseline_results['models'][model_name]\n",
    "    comparison_structure['baseline']['models'][model_name] = {\n",
    "        'accuracy': float(model_data['metrics']['accuracy']),\n",
    "        'f1_macro': float(model_data['metrics']['f1_macro']),\n",
    "        'f1_weighted': float(model_data['metrics']['f1_weighted']),\n",
    "        'best_epoch': len(model_data['history']['train_loss'])\n",
    "    }\n",
    "\n",
    "# Salvar estrutura para futura compara√ß√£o\n",
    "with open(os.path.join(CONFIG['results_path'], 'comparison_structure.json'), 'w') as f:\n",
    "    json.dump(comparison_structure, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Estrutura de compara√ß√£o preparada!\")\n",
    "print(\"üìå Use este arquivo para comparar com resultados augmentados:\")\n",
    "print(f\"   {CONFIG['results_path']}/comparison_structure.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TREINAMENTO BASELINE COMPLETO!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPr√≥ximos passos:\")\n",
    "print(\"1. Implementar data augmentation\")\n",
    "print(\"2. Treinar modelos com dados augmentados\")\n",
    "print(\"3. Comparar resultados usando a estrutura salva\")\n",
    "print(\"4. Analisar melhorias obtidas com augmentation\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
