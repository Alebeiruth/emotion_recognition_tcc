{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 1: Imports necessários\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    balanced_accuracy_score, cohen_kappa_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Verificar GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🖥️ Dispositivo: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memória: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "print(\"\\n📊 Dataset: EXPW (Expression in-the-Wild)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c8041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 2: Configuração Global para EXPW\n",
    "CONFIG = {\n",
    "    # Caminhos\n",
    "    'data_path': '../data/processed/EXPW',  # Caminho para EXPW processado\n",
    "    'output_path': '../models/expw',\n",
    "    'results_path': '../results/expw',\n",
    "    \n",
    "    # Informações do Dataset\n",
    "    'dataset_name': 'EXPW',\n",
    "    'num_classes': 7,\n",
    "    'emotions': ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise'],\n",
    "    'input_size': 224,\n",
    "    \n",
    "    # Treinamento\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    \n",
    "    # Early Stopping\n",
    "    'patience': 10,\n",
    "    'min_delta': 0.001,\n",
    "    \n",
    "    # Modelos a treinar\n",
    "    'models_to_train': ['resnet50', 'efficientnet_b0', 'vit_b_16'],\n",
    "    \n",
    "    # Configurações avançadas\n",
    "    'use_weighted_sampler': True,  # Para lidar com desbalanceamento\n",
    "    'label_smoothing': 0.1,  # Suavização de rótulos\n",
    "    \n",
    "    # Seed para reprodutibilidade\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Criar diretórios\n",
    "os.makedirs(CONFIG['output_path'], exist_ok=True)\n",
    "os.makedirs(CONFIG['results_path'], exist_ok=True)\n",
    "\n",
    "# Setar seeds\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['seed'])\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"✅ Configurações carregadas para EXPW\")\n",
    "print(f\"📁 Dados: {CONFIG['data_path']}\")\n",
    "print(f\"💾 Modelos: {CONFIG['output_path']}\")\n",
    "print(f\"📊 Resultados: {CONFIG['results_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 3: Classe Dataset para EXPW\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "class EXPWDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        Dataset para carregar imagens pré-processadas do EXPW\n",
    "        \"\"\"\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.emotions = CONFIG['emotions']\n",
    "        self.emotion_to_idx = {emotion: idx for idx, emotion in enumerate(self.emotions)}\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Carregar caminhos e labels\n",
    "        for emotion in self.emotions:\n",
    "            emotion_dir = os.path.join(self.root_dir, emotion)\n",
    "            if os.path.exists(emotion_dir):\n",
    "                for img_name in os.listdir(emotion_dir):\n",
    "                    if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        self.images.append(os.path.join(emotion_dir, img_name))\n",
    "                        self.labels.append(self.emotion_to_idx[emotion])\n",
    "        \n",
    "        print(f\"📂 EXPW {split.upper()} Dataset:\")\n",
    "        print(f\"   Total de imagens: {len(self.images)}\")\n",
    "        \n",
    "        # Contar e mostrar distribuição\n",
    "        self.class_counts = np.bincount(self.labels, minlength=len(self.emotions))\n",
    "        self.class_weights = len(self.labels) / (len(self.emotions) * self.class_counts + 1e-6)\n",
    "        \n",
    "        print(\"\\n   Distribuição por classe:\")\n",
    "        for idx, emotion in enumerate(self.emotions):\n",
    "            count = self.class_counts[idx]\n",
    "            percentage = (count / len(self.labels)) * 100 if len(self.labels) > 0 else 0\n",
    "            print(f\"   {emotion:12s}: {count:5d} imagens ({percentage:5.1f}%)\")\n",
    "            \n",
    "        # Calcular pesos para balanceamento\n",
    "        self.sample_weights = [self.class_weights[label] for label in self.labels]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Carregar imagem\n",
    "        img_path = self.images[idx]\n",
    "        \n",
    "        try:\n",
    "            # Ler como grayscale e converter para RGB\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if image is None:\n",
    "                # Fallback: criar imagem preta se falhar\n",
    "                image = np.zeros((224, 224), dtype=np.uint8)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "            image = Image.fromarray(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {img_path}: {e}\")\n",
    "            # Criar imagem placeholder\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "    def get_sample_weights(self):\n",
    "        return self.sample_weights\n",
    "\n",
    "print(\"✅ Classe Dataset EXPW criada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 4: Definir transformações (incluindo augmentation suave)\n",
    "# Normalização ImageNet\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transformações para treino (com augmentation suave para EXPW)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['input_size'], CONFIG['input_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# Transformações para validação/teste (sem augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['input_size'], CONFIG['input_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "print(\"✅ Transformações definidas para EXPW\")\n",
    "print(f\"   Input size: {CONFIG['input_size']}x{CONFIG['input_size']}\")\n",
    "print(f\"   Normalização: ImageNet\")\n",
    "print(f\"   Augmentation no treino: Flip, Rotação (±10°), ColorJitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd82b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 5: Criar datasets e dataloaders com balanceamento\n",
    "print(\"🔄 Carregando datasets EXPW...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Criar datasets\n",
    "train_dataset = EXPWDataset(\n",
    "    root_dir=CONFIG['data_path'],\n",
    "    split='train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = EXPWDataset(\n",
    "    root_dir=CONFIG['data_path'],\n",
    "    split='test',\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "# Configurar sampler balanceado para treino se necessário\n",
    "train_loader_params = {\n",
    "    'batch_size': CONFIG['batch_size'],\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "if CONFIG['use_weighted_sampler'] and len(train_dataset) > 0:\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=train_dataset.get_sample_weights(),\n",
    "        num_samples=len(train_dataset),\n",
    "        replacement=True\n",
    "    )\n",
    "    train_loader_params['sampler'] = sampler\n",
    "    print(\"✅ Usando WeightedRandomSampler para balancear classes\")\n",
    "else:\n",
    "    train_loader_params['shuffle'] = True\n",
    "\n",
    "# Criar dataloaders\n",
    "train_loader = DataLoader(train_dataset, **train_loader_params)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ DataLoaders EXPW criados\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Análise de desbalanceamento\n",
    "if len(train_dataset) > 0:\n",
    "    imbalance_ratio = max(train_dataset.class_counts) / min(train_dataset.class_counts + [1])\n",
    "    print(f\"   Razão de desbalanceamento: {imbalance_ratio:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 6: Visualizar algumas amostras do EXPW\n",
    "def show_expw_batch(dataloader, num_samples=8):\n",
    "    \"\"\"Visualiza um batch de imagens do EXPW\"\"\"\n",
    "    if len(dataloader) == 0:\n",
    "        print(\"⚠️ DataLoader vazio\")\n",
    "        return\n",
    "        \n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    # Desnormalizar imagens\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    images_denorm = images * std + mean\n",
    "    images_denorm = torch.clamp(images_denorm, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        img = images_denorm[i].permute(1, 2, 0).numpy()\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{CONFIG['emotions'][labels[i]]}\", fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Esconder eixos não usados\n",
    "    for i in range(min(num_samples, len(images)), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Amostras do Dataset EXPW', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar amostras\n",
    "if len(train_loader) > 0:\n",
    "    show_expw_batch(train_loader)\n",
    "else:\n",
    "    print(\"⚠️ Sem dados para visualizar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 7: Definir funções para criar modelos\n",
    "def create_resnet50(num_classes=7):\n",
    "    \"\"\"Cria ResNet50 pré-treinada e ajusta para EXPW\"\"\"\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def create_efficientnet_b0(num_classes=7):\n",
    "    \"\"\"Cria EfficientNet-B0 pré-treinada para EXPW\"\"\"\n",
    "    model = models.efficientnet_b0(pretrained=True)\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def create_vit_b_16(num_classes=7):\n",
    "    \"\"\"Cria Vision Transformer (ViT-B/16) pré-treinado para EXPW\"\"\"\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    num_features = model.heads.head.in_features\n",
    "    model.heads.head = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Dicionário de modelos\n",
    "MODEL_CREATORS = {\n",
    "    'resnet50': create_resnet50,\n",
    "    'efficientnet_b0': create_efficientnet_b0,\n",
    "    'vit_b_16': create_vit_b_16\n",
    "}\n",
    "\n",
    "print(\"✅ Arquiteturas de modelo definidas para EXPW:\")\n",
    "for model_name in CONFIG['models_to_train']:\n",
    "    print(f\"   • {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 8: Implementar Early Stopping melhorado\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping para evitar overfitting\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0, verbose=True, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_weights = None\n",
    "        \n",
    "    def __call__(self, score, model):\n",
    "        if self.mode == 'min':\n",
    "            score = -score\n",
    "            \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'   EarlyStopping counter: {self.counter}/{self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Salva o estado do modelo\"\"\"\n",
    "        if self.verbose:\n",
    "            score_str = f\"{abs(self.best_score):.4f}\" if self.mode == 'min' else f\"{self.best_score:.4f}\"\n",
    "            print(f'   Métrica melhorou ({score_str}). Salvando modelo...')\n",
    "        self.best_model_weights = model.state_dict().copy()\n",
    "    \n",
    "    def load_best_weights(self, model):\n",
    "        \"\"\"Carrega os melhores pesos\"\"\"\n",
    "        if self.best_model_weights is not None:\n",
    "            model.load_state_dict(self.best_model_weights)\n",
    "        return model\n",
    "\n",
    "print(\"✅ Early Stopping implementado\")\n",
    "print(f\"   Patience: {CONFIG['patience']}\")\n",
    "print(f\"   Min delta: {CONFIG['min_delta']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f1b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 9: Funções de treinamento e validação\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        n_classes = pred.size(-1)\n",
    "        log_preds = torch.log_softmax(pred, dim=-1)\n",
    "        loss = -log_preds.sum(dim=-1)\n",
    "        nll = torch.nn.functional.nll_loss(log_preds, target, reduction='none')\n",
    "        smooth_loss = loss / n_classes\n",
    "        loss = (1 - self.smoothing) * nll + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Treina o modelo por uma época\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Estatísticas\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Atualizar barra de progresso\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader) if len(dataloader) > 0 else 0\n",
    "    epoch_acc = 100 * correct / total if total > 0 else 0\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Valida o modelo\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation', leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Guardar para métricas\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader) if len(dataloader) > 0 else 0\n",
    "    epoch_acc = 100 * correct / total if total > 0 else 0\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_predictions, all_labels, all_probs\n",
    "\n",
    "print(\"✅ Funções de treinamento com label smoothing definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25567929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 10: Função principal de treinamento\n",
    "def train_model(model_name, train_loader, test_loader, device, config):\n",
    "    \"\"\"\n",
    "    Treina um modelo com early stopping e retorna métricas\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🚀 Treinando {model_name} no EXPW\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Verificar se há dados\n",
    "    if len(train_loader) == 0 or len(test_loader) == 0:\n",
    "        print(\"⚠️ Sem dados suficientes para treinar\")\n",
    "        return None, {}, [], [], []\n",
    "    \n",
    "    # Criar modelo\n",
    "    model = MODEL_CREATORS[model_name](num_classes=config['num_classes'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Configurar loss com label smoothing\n",
    "    if config.get('label_smoothing', 0) > 0:\n",
    "        criterion = LabelSmoothingCrossEntropy(smoothing=config['label_smoothing'])\n",
    "        print(f\"   Usando Label Smoothing: {config['label_smoothing']}\")\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Otimizador com agendador\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                            lr=config['learning_rate'],\n",
    "                            weight_decay=config['weight_decay'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    early_stopping = EarlyStopping(patience=config['patience'], \n",
    "                                  min_delta=config['min_delta'])\n",
    "    \n",
    "    # Histórico\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Loop de treinamento\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config['num_epochs']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Treinar\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, \n",
    "                                           criterion, optimizer, device)\n",
    "        \n",
    "        # Validar\n",
    "        val_loss, val_acc, _, _, _ = validate_epoch(model, test_loader, \n",
    "                                                    criterion, device)\n",
    "        \n",
    "        # Atualizar scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Guardar histórico\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Atualizar melhor accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "        # Print estatísticas\n",
    "        print(f\"   Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"   Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"   Best Val Acc: {best_val_acc:.2f}%\")\n",
    "        print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"\\n⏹️ Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    # Carregar melhores pesos\n",
    "    model = early_stopping.load_best_weights(model)\n",
    "    \n",
    "    # Avaliar modelo final\n",
    "    print(\"\\n📊 Avaliação final no conjunto de teste...\")\n",
    "    val_loss, val_acc, predictions, labels, probs = validate_epoch(\n",
    "        model, test_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    print(f\"   Final Test Accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "    return model, history, predictions, labels, probs\n",
    "\n",
    "print(\"✅ Função de treinamento principal configurada para EXPW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cbdc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 11: Calcular todas as métricas\n",
    "def calculate_metrics(y_true, y_pred, y_probs, class_names):\n",
    "    \"\"\"\n",
    "    Calcula todas as métricas de avaliação\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Métricas básicas\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "    metrics['cohen_kappa'] = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "    metrics['precision_macro'] = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics['precision_weighted'] = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    metrics['recall_macro'] = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics['recall_weighted'] = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    metrics['f1_macro'] = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics['f1_weighted'] = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Métricas por classe\n",
    "    metrics['precision_per_class'] = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    metrics['recall_per_class'] = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    metrics['f1_per_class'] = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # ROC-AUC (One-vs-Rest)\n",
    "    try:\n",
    "        y_true_bin = label_binarize(y_true, classes=list(range(len(class_names))))\n",
    "        metrics['roc_auc_ovr'] = roc_auc_score(y_true_bin, y_probs, multi_class='ovr')\n",
    "        metrics['roc_auc_ovo'] = roc_auc_score(y_true_bin, y_probs, multi_class='ovo')\n",
    "    except:\n",
    "        metrics['roc_auc_ovr'] = None\n",
    "        metrics['roc_auc_ovo'] = None\n",
    "    \n",
    "    # Classification report\n",
    "    metrics['classification_report'] = classification_report(\n",
    "        y_true, y_pred, target_names=class_names, output_dict=True, zero_division=0\n",
    "    )\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_metrics_summary(metrics, class_names):\n",
    "    \"\"\"\n",
    "    Imprime resumo das métricas\n",
    "    \"\"\"\n",
    "    print(\"\\n📊 MÉTRICAS DE AVALIAÇÃO - EXPW\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n🎯 Métricas Gerais:\")\n",
    "    print(f\"   Accuracy:              {metrics['accuracy']:.4f}\")\n",
    "    print(f\"   Balanced Accuracy:     {metrics['balanced_accuracy']:.4f}\")\n",
    "    print(f\"   Cohen's Kappa:         {metrics['cohen_kappa']:.4f}\")\n",
    "    print(f\"   Precision (macro):     {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"   Recall (macro):        {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"   F1-Score (macro):      {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"   Precision (weighted):  {metrics['precision_weighted']:.4f}\")\n",
    "    print(f\"   Recall (weighted):     {metrics['recall_weighted']:.4f}\")\n",
    "    print(f\"   F1-Score (weighted):   {metrics['f1_weighted']:.4f}\")\n",
    "    \n",
    "    if metrics['roc_auc_ovr']:\n",
    "        print(f\"   ROC-AUC (OvR):        {metrics['roc_auc_ovr']:.4f}\")\n",
    "        print(f\"   ROC-AUC (OvO):        {metrics['roc_auc_ovo']:.4f}\")\n",
    "    \n",
    "    print(\"\\n📈 Métricas por Classe:\")\n",
    "    print(f\"{'Emoção':12s} | {'Precision':>10s} | {'Recall':>10s} | {'F1-Score':>10s}\")\n",
    "    print(\"-\"*50)\n",
    "    for i, emotion in enumerate(class_names):\n",
    "        if i < len(metrics['precision_per_class']):\n",
    "            print(f\"{emotion:12s} | {metrics['precision_per_class'][i]:10.4f} | \"\n",
    "                  f\"{metrics['recall_per_class'][i]:10.4f} | \"\n",
    "                  f\"{metrics['f1_per_class'][i]:10.4f}\")\n",
    "\n",
    "print(\"✅ Funções de métricas configuradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 12: Funções de visualização\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plota histórico de treinamento\"\"\"\n",
    "    if not history['train_loss']:\n",
    "        print(\"⚠️ Sem histórico para plotar\")\n",
    "        return None\n",
    "        \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(history['train_loss'], label='Train Loss', linewidth=2, color='#3498db')\n",
    "    ax1.plot(history['val_loss'], label='Val Loss', linewidth=2, color='#e74c3c')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title(f'{model_name} - Loss (EXPW)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(history['train_acc'], label='Train Acc', linewidth=2, color='#2ecc71')\n",
    "    ax2.plot(history['val_acc'], label='Val Acc', linewidth=2, color='#f39c12')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title(f'{model_name} - Accuracy (EXPW)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Training History - {model_name} on EXPW', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, model_name):\n",
    "    \"\"\"Plota matriz de confusão\"\"\"\n",
    "    if cm is None or cm.size == 0:\n",
    "        print(\"⚠️ Matriz de confusão vazia\")\n",
    "        return None\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Normalizar matriz\n",
    "    cm_normalized = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-6)\n",
    "    \n",
    "    # Plotar\n",
    "    sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Normalized Value'},\n",
    "                ax=ax)\n",
    "    \n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_title(f'Confusion Matrix - {model_name} (EXPW)')\n",
    "    \n",
    "    # Rotacionar labels se necessário\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    plt.setp(ax.yaxis.get_majorticklabels(), rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_metrics_comparison(all_metrics, model_names):\n",
    "    \"\"\"Compara métricas entre modelos\"\"\"\n",
    "    metrics_to_plot = ['accuracy', 'balanced_accuracy', 'f1_macro', 'cohen_kappa']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        values = []\n",
    "        valid_models = []\n",
    "        for model in model_names:\n",
    "            if model in all_metrics and metric in all_metrics[model]:\n",
    "                values.append(all_metrics[model][metric])\n",
    "                valid_models.append(model)\n",
    "        \n",
    "        if values:\n",
    "            bars = axes[idx].bar(valid_models, values, color=colors[:len(valid_models)])\n",
    "            axes[idx].set_title(metric.replace('_', ' ').title())\n",
    "            axes[idx].set_ylim([0, 1])\n",
    "            axes[idx].set_ylabel('Score')\n",
    "            \n",
    "            # Adicionar valores nas barras\n",
    "            for bar, val in zip(bars, values):\n",
    "                height = bar.get_height()\n",
    "                axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                              f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.suptitle('Model Comparison - EXPW Dataset', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "print(\"✅ Funções de visualização configuradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 13: Treinar ResNet50 no EXPW\n",
    "print(\"🔄 Iniciando treinamento ResNet50 no EXPW...\")\n",
    "\n",
    "if len(train_loader) > 0 and len(test_loader) > 0:\n",
    "    resnet_model, resnet_history, resnet_pred, resnet_true, resnet_probs = train_model(\n",
    "        'resnet50', \n",
    "        train_loader, \n",
    "        test_loader, \n",
    "        device, \n",
    "        CONFIG\n",
    "    )\n",
    "    \n",
    "    if resnet_model is not None and len(resnet_pred) > 0:\n",
    "        # Calcular métricas\n",
    "        resnet_metrics = calculate_metrics(\n",
    "            resnet_true, \n",
    "            resnet_pred, \n",
    "            resnet_probs,\n",
    "            CONFIG['emotions']\n",
    "        )\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print_metrics_summary(resnet_metrics, CONFIG['emotions'])\n",
    "        \n",
    "        # Visualizações\n",
    "        fig1 = plot_training_history(resnet_history, 'ResNet50')\n",
    "        if fig1:\n",
    "            plt.show()\n",
    "        \n",
    "        fig2 = plot_confusion_matrix(resnet_metrics['confusion_matrix'], \n",
    "                                     CONFIG['emotions'], 'ResNet50')\n",
    "        if fig2:\n",
    "            plt.show()\n",
    "        \n",
    "        # Salvar modelo\n",
    "        torch.save({\n",
    "            'model_state_dict': resnet_model.state_dict(),\n",
    "            'metrics': resnet_metrics,\n",
    "            'history': resnet_history,\n",
    "            'config': CONFIG,\n",
    "            'dataset': 'EXPW'\n",
    "        }, os.path.join(CONFIG['output_path'], 'resnet50_expw_baseline.pth'))\n",
    "        \n",
    "        print(\"✅ ResNet50 treinado e salvo para EXPW!\")\n",
    "    else:\n",
    "        print(\"⚠️ Treinamento ResNet50 falhou ou sem dados\")\n",
    "        resnet_metrics = {}\n",
    "else:\n",
    "    print(\"⚠️ Sem dados suficientes para treinar ResNet50\")\n",
    "    resnet_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 14: Treinar EfficientNet-B0 no EXPW\n",
    "print(\"🔄 Iniciando treinamento EfficientNet-B0 no EXPW...\")\n",
    "\n",
    "if len(train_loader) > 0 and len(test_loader) > 0:\n",
    "    efficientnet_model, efficientnet_history, efficientnet_pred, efficientnet_true, efficientnet_probs = train_model(\n",
    "        'efficientnet_b0', \n",
    "        train_loader, \n",
    "        test_loader, \n",
    "        device, \n",
    "        CONFIG\n",
    "    )\n",
    "    \n",
    "    if efficientnet_model is not None and len(efficientnet_pred) > 0:\n",
    "        # Calcular métricas\n",
    "        efficientnet_metrics = calculate_metrics(\n",
    "            efficientnet_true, \n",
    "            efficientnet_pred, \n",
    "            efficientnet_probs,\n",
    "            CONFIG['emotions']\n",
    "        )\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print_metrics_summary(efficientnet_metrics, CONFIG['emotions'])\n",
    "        \n",
    "        # Visualizações\n",
    "        fig1 = plot_training_history(efficientnet_history, 'EfficientNet-B0')\n",
    "        if fig1:\n",
    "            plt.show()\n",
    "        \n",
    "        fig2 = plot_confusion_matrix(efficientnet_metrics['confusion_matrix'], \n",
    "                                     CONFIG['emotions'], 'EfficientNet-B0')\n",
    "        if fig2:\n",
    "            plt.show()\n",
    "        \n",
    "        # Salvar modelo\n",
    "        torch.save({\n",
    "            'model_state_dict': efficientnet_model.state_dict(),\n",
    "            'metrics': efficientnet_metrics,\n",
    "            'history': efficientnet_history,\n",
    "            'config': CONFIG,\n",
    "            'dataset': 'EXPW'\n",
    "        }, os.path.join(CONFIG['output_path'], 'efficientnet_b0_expw_baseline.pth'))\n",
    "        \n",
    "        print(\"✅ EfficientNet-B0 treinado e salvo para EXPW!\")\n",
    "    else:\n",
    "        print(\"⚠️ Treinamento EfficientNet-B0 falhou ou sem dados\")\n",
    "        efficientnet_metrics = {}\n",
    "else:\n",
    "    print(\"⚠️ Sem dados suficientes para treinar EfficientNet-B0\")\n",
    "    efficientnet_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 15: Treinar Vision Transformer no EXPW\n",
    "print(\"🔄 Iniciando treinamento Vision Transformer no EXPW...\")\n",
    "\n",
    "if len(train_loader) > 0 and len(test_loader) > 0:\n",
    "    vit_model, vit_history, vit_pred, vit_true, vit_probs = train_model(\n",
    "        'vit_b_16', \n",
    "        train_loader, \n",
    "        test_loader, \n",
    "        device, \n",
    "        CONFIG\n",
    "    )\n",
    "    \n",
    "    if vit_model is not None and len(vit_pred) > 0:\n",
    "        # Calcular métricas\n",
    "        vit_metrics = calculate_metrics(\n",
    "            vit_true, \n",
    "            vit_pred, \n",
    "            vit_probs,\n",
    "            CONFIG['emotions']\n",
    "        )\n",
    "        \n",
    "        # Mostrar métricas\n",
    "        print_metrics_summary(vit_metrics, CONFIG['emotions'])\n",
    "        \n",
    "        # Visualizações\n",
    "        fig1 = plot_training_history(vit_history, 'ViT-B/16')\n",
    "        if fig1:\n",
    "            plt.show()\n",
    "        \n",
    "        fig2 = plot_confusion_matrix(vit_metrics['confusion_matrix'], \n",
    "                                     CONFIG['emotions'], 'ViT-B/16')\n",
    "        if fig2:\n",
    "            plt.show()\n",
    "        \n",
    "        # Salvar modelo\n",
    "        torch.save({\n",
    "            'model_state_dict': vit_model.state_dict(),\n",
    "            'metrics': vit_metrics,\n",
    "            'history': vit_history,\n",
    "            'config': CONFIG,\n",
    "            'dataset': 'EXPW'\n",
    "        }, os.path.join(CONFIG['output_path'], 'vit_b_16_expw_baseline.pth'))\n",
    "        \n",
    "        print(\"✅ Vision Transformer treinado e salvo para EXPW!\")\n",
    "    else:\n",
    "        print(\"⚠️ Treinamento ViT falhou ou sem dados\")\n",
    "        vit_metrics = {}\n",
    "else:\n",
    "    print(\"⚠️ Sem dados suficientes para treinar ViT\")\n",
    "    vit_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 16: Comparar todos os modelos no EXPW\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🏆 COMPARAÇÃO DE MODELOS - EXPW (BASELINE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Consolidar métricas\n",
    "all_metrics = {}\n",
    "if 'resnet_metrics' in locals() and resnet_metrics:\n",
    "    all_metrics['ResNet50'] = resnet_metrics\n",
    "if 'efficientnet_metrics' in locals() and efficientnet_metrics:\n",
    "    all_metrics['EfficientNet-B0'] = efficientnet_metrics\n",
    "if 'vit_metrics' in locals() and vit_metrics:\n",
    "    all_metrics['ViT-B/16'] = vit_metrics\n",
    "\n",
    "if all_metrics:\n",
    "    # Criar tabela comparativa\n",
    "    comparison_data = []\n",
    "    for model_name, metrics in all_metrics.items():\n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'Dataset': 'EXPW',\n",
    "            'Accuracy': f\"{metrics.get('accuracy', 0):.4f}\",\n",
    "            'Balanced Acc': f\"{metrics.get('balanced_accuracy', 0):.4f}\",\n",
    "            'Precision (macro)': f\"{metrics.get('precision_macro', 0):.4f}\",\n",
    "            'Recall (macro)': f\"{metrics.get('recall_macro', 0):.4f}\",\n",
    "            'F1-Score (macro)': f\"{metrics.get('f1_macro', 0):.4f}\",\n",
    "            'F1-Score (weighted)': f\"{metrics.get('f1_weighted', 0):.4f}\",\n",
    "            'Cohen Kappa': f\"{metrics.get('cohen_kappa', 0):.4f}\"\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    print(\"\\n📊 Tabela Comparativa - EXPW:\")\n",
    "    print(df_comparison.to_string(index=False))\n",
    "    \n",
    "    # Identificar melhor modelo\n",
    "    best_model = max(all_metrics.items(), \n",
    "                     key=lambda x: x[1].get('balanced_accuracy', 0))\n",
    "    print(f\"\\n🥇 Melhor modelo (por balanced accuracy): {best_model[0]} - {best_model[1].get('balanced_accuracy', 0):.4f}\")\n",
    "    \n",
    "    # Plotar comparação\n",
    "    if len(all_metrics) > 0:\n",
    "        fig = plot_metrics_comparison(all_metrics, list(all_metrics.keys()))\n",
    "        if fig:\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"⚠️ Nenhuma métrica disponível para comparação\")\n",
    "    df_comparison = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57927d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 17: Análise detalhada por classe no EXPW\n",
    "def analyze_class_performance_expw(all_metrics, emotions):\n",
    "    \"\"\"Analisa performance por classe em todos os modelos para EXPW\"\"\"\n",
    "    \n",
    "    if not all_metrics:\n",
    "        print(\"⚠️ Sem métricas para análise\")\n",
    "        return None\n",
    "        \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for idx, metric_type in enumerate(['precision_per_class', 'recall_per_class', 'f1_per_class']):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        x = np.arange(len(emotions))\n",
    "        width = 0.25\n",
    "        colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "        \n",
    "        for i, (model_name, metrics) in enumerate(all_metrics.items()):\n",
    "            if metric_type in metrics:\n",
    "                values = metrics[metric_type]\n",
    "                if len(values) > 0:\n",
    "                    ax.bar(x + i*width, values, width, \n",
    "                          label=model_name, color=colors[i % len(colors)])\n",
    "        \n",
    "        ax.set_xlabel('Emotion')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_title(metric_type.replace('_', ' ').title().replace('Per Class', ''))\n",
    "        ax.set_xticks(x + width)\n",
    "        ax.set_xticklabels(emotions, rotation=45)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Performance by Emotion Class - EXPW Dataset', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Executar análise\n",
    "if all_metrics:\n",
    "    fig = analyze_class_performance_expw(all_metrics, CONFIG['emotions'])\n",
    "    if fig:\n",
    "        plt.show()\n",
    "    \n",
    "    # Identificar classes problemáticas\n",
    "    print(\"\\n🔍 Análise de Classes Problemáticas no EXPW:\")\n",
    "    for emotion_idx, emotion in enumerate(CONFIG['emotions']):\n",
    "        print(f\"\\n{emotion}:\")\n",
    "        for model_name, metrics in all_metrics.items():\n",
    "            if 'f1_per_class' in metrics and emotion_idx < len(metrics['f1_per_class']):\n",
    "                f1 = metrics['f1_per_class'][emotion_idx]\n",
    "                print(f\"   {model_name:15s}: F1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 18: Salvar todos os resultados EXPW para comparação futura\n",
    "import pickle\n",
    "\n",
    "# Consolidar todos os resultados\n",
    "expw_baseline_results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'dataset': 'EXPW',\n",
    "    'config': CONFIG,\n",
    "    'models': {},\n",
    "    'comparison': df_comparison.to_dict() if not df_comparison.empty else {}\n",
    "}\n",
    "\n",
    "# Adicionar resultados de cada modelo se existirem\n",
    "if 'resnet_metrics' in locals() and resnet_metrics:\n",
    "    expw_baseline_results['models']['resnet50'] = {\n",
    "        'metrics': resnet_metrics,\n",
    "        'history': resnet_history if 'resnet_history' in locals() else {},\n",
    "    }\n",
    "\n",
    "if 'efficientnet_metrics' in locals() and efficientnet_metrics:\n",
    "    expw_baseline_results['models']['efficientnet_b0'] = {\n",
    "        'metrics': efficientnet_metrics,\n",
    "        'history': efficientnet_history if 'efficientnet_history' in locals() else {},\n",
    "    }\n",
    "\n",
    "if 'vit_metrics' in locals() and vit_metrics:\n",
    "    expw_baseline_results['models']['vit_b_16'] = {\n",
    "        'metrics': vit_metrics,\n",
    "        'history': vit_history if 'vit_history' in locals() else {},\n",
    "    }\n",
    "\n",
    "# Salvar em diferentes formatos\n",
    "# 1. Pickle (preserva tudo)\n",
    "with open(os.path.join(CONFIG['results_path'], 'expw_baseline_results.pkl'), 'wb') as f:\n",
    "    pickle.dump(expw_baseline_results, f)\n",
    "\n",
    "# 2. JSON (apenas métricas principais)\n",
    "json_results = {\n",
    "    'timestamp': expw_baseline_results['timestamp'],\n",
    "    'dataset': 'EXPW',\n",
    "    'config': {k: v for k, v in CONFIG.items() if not callable(v)},\n",
    "    'models': {}\n",
    "}\n",
    "\n",
    "for model_name, model_data in expw_baseline_results['models'].items():\n",
    "    if 'metrics' in model_data:\n",
    "        json_results['models'][model_name] = {\n",
    "            'accuracy': float(model_data['metrics'].get('accuracy', 0)),\n",
    "            'balanced_accuracy': float(model_data['metrics'].get('balanced_accuracy', 0)),\n",
    "            'precision_macro': float(model_data['metrics'].get('precision_macro', 0)),\n",
    "            'recall_macro': float(model_data['metrics'].get('recall_macro', 0)),\n",
    "            'f1_macro': float(model_data['metrics'].get('f1_macro', 0)),\n",
    "            'f1_weighted': float(model_data['metrics'].get('f1_weighted', 0)),\n",
    "            'cohen_kappa': float(model_data['metrics'].get('cohen_kappa', 0))\n",
    "        }\n",
    "\n",
    "with open(os.path.join(CONFIG['results_path'], 'expw_baseline_metrics.json'), 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "# 3. CSV com métricas principais\n",
    "if not df_comparison.empty:\n",
    "    df_comparison.to_csv(os.path.join(CONFIG['results_path'], 'expw_baseline_comparison.csv'), index=False)\n",
    "\n",
    "print(\"✅ Resultados EXPW salvos em:\")\n",
    "print(f\"   • {CONFIG['results_path']}/expw_baseline_results.pkl\")\n",
    "print(f\"   • {CONFIG['results_path']}/expw_baseline_metrics.json\")\n",
    "if not df_comparison.empty:\n",
    "    print(f\"   • {CONFIG['results_path']}/expw_baseline_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ca4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 19: Gerar relatório final EXPW\n",
    "def generate_expw_report(all_metrics, config):\n",
    "    \"\"\"Gera relatório em texto com todos os resultados do EXPW\"\"\"\n",
    "    \n",
    "    report = []\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(\"RELATÓRIO DE TREINAMENTO - MODELOS BASELINE EXPW\")\n",
    "    report.append(\"=\"*80)\n",
    "    report.append(f\"\\nData: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report.append(f\"Dataset: EXPW (Expression in-the-Wild)\")\n",
    "    report.append(f\"Caminho: {config['data_path']}\")\n",
    "    report.append(f\"Dispositivo: {device}\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"-\"*80)\n",
    "    report.append(\"CONFIGURAÇÕES DE TREINAMENTO:\")\n",
    "    report.append(\"-\"*80)\n",
    "    report.append(f\"Batch Size: {config['batch_size']}\")\n",
    "    report.append(f\"Learning Rate: {config['learning_rate']}\")\n",
    "    report.append(f\"Weight Decay: {config['weight_decay']}\")\n",
    "    report.append(f\"Max Epochs: {config['num_epochs']}\")\n",
    "    report.append(f\"Early Stopping Patience: {config['patience']}\")\n",
    "    report.append(f\"Input Size: {config['input_size']}x{config['input_size']}\")\n",
    "    report.append(f\"Label Smoothing: {config.get('label_smoothing', 0)}\")\n",
    "    report.append(f\"Weighted Sampler: {config.get('use_weighted_sampler', False)}\")\n",
    "    \n",
    "    if all_metrics:\n",
    "        report.append(\"\\n\" + \"-\"*80)\n",
    "        report.append(\"RESULTADOS POR MODELO:\")\n",
    "        report.append(\"-\"*80)\n",
    "        \n",
    "        for model_name, metrics in all_metrics.items():\n",
    "            report.append(f\"\\n### {model_name}\")\n",
    "            report.append(f\"   Accuracy: {metrics.get('accuracy', 0):.4f}\")\n",
    "            report.append(f\"   Balanced Accuracy: {metrics.get('balanced_accuracy', 0):.4f}\")\n",
    "            report.append(f\"   Cohen's Kappa: {metrics.get('cohen_kappa', 0):.4f}\")\n",
    "            report.append(f\"   Precision (macro): {metrics.get('precision_macro', 0):.4f}\")\n",
    "            report.append(f\"   Recall (macro): {metrics.get('recall_macro', 0):.4f}\")\n",
    "            report.append(f\"   F1-Score (macro): {metrics.get('f1_macro', 0):.4f}\")\n",
    "            report.append(f\"   F1-Score (weighted): {metrics.get('f1_weighted', 0):.4f}\")\n",
    "            if metrics.get('roc_auc_ovr'):\n",
    "                report.append(f\"   ROC-AUC (OvR): {metrics['roc_auc_ovr']:.4f}\")\n",
    "        \n",
    "        # Melhor modelo\n",
    "        if all_metrics:\n",
    "            best_model = max(all_metrics.items(), \n",
    "                           key=lambda x: x[1].get('balanced_accuracy', 0))\n",
    "            report.append(\"\\n\" + \"-\"*80)\n",
    "            report.append(\"MELHOR MODELO:\")\n",
    "            report.append(\"-\"*80)\n",
    "            report.append(f\"Modelo: {best_model[0]}\")\n",
    "            report.append(f\"Balanced Accuracy: {best_model[1].get('balanced_accuracy', 0):.4f}\")\n",
    "        \n",
    "        # Classes problemáticas\n",
    "        report.append(\"\\n\" + \"-\"*80)\n",
    "        report.append(\"ANÁLISE POR CLASSE (F1-Score):\")\n",
    "        report.append(\"-\"*80)\n",
    "        \n",
    "        for emotion_idx, emotion in enumerate(config['emotions']):\n",
    "            report.append(f\"\\n{emotion}:\")\n",
    "            for model_name, metrics in all_metrics.items():\n",
    "                if 'f1_per_class' in metrics and emotion_idx < len(metrics['f1_per_class']):\n",
    "                    f1 = metrics['f1_per_class'][emotion_idx]\n",
    "                    report.append(f\"   {model_name}: {f1:.4f}\")\n",
    "        \n",
    "        # Identificar classe mais difícil\n",
    "        avg_f1_per_class = {}\n",
    "        for emotion_idx, emotion in enumerate(config['emotions']):\n",
    "            f1_scores = []\n",
    "            for m in all_metrics.values():\n",
    "                if 'f1_per_class' in m and emotion_idx < len(m['f1_per_class']):\n",
    "                    f1_scores.append(m['f1_per_class'][emotion_idx])\n",
    "            if f1_scores:\n",
    "                avg_f1_per_class[emotion] = np.mean(f1_scores)\n",
    "        \n",
    "        if avg_f1_per_class:\n",
    "            hardest_class = min(avg_f1_per_class.items(), key=lambda x: x[1])\n",
    "            easiest_class = max(avg_f1_per_class.items(), key=lambda x: x[1])\n",
    "            \n",
    "            report.append(\"\\n\" + \"-\"*80)\n",
    "            report.append(\"INSIGHTS:\")\n",
    "            report.append(\"-\"*80)\n",
    "            report.append(f\"Classe mais fácil: {easiest_class[0]} (F1 médio: {easiest_class[1]:.4f})\")\n",
    "            report.append(f\"Classe mais difícil: {hardest_class[0]} (F1 médio: {hardest_class[1]:.4f})\")\n",
    "    else:\n",
    "        report.append(\"\\n⚠️ Nenhum modelo foi treinado com sucesso\")\n",
    "    \n",
    "    report.append(\"\\n\" + \"=\"*80)\n",
    "    report.append(\"FIM DO RELATÓRIO\")\n",
    "    report.append(\"=\"*80)\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "# Gerar e salvar relatório\n",
    "report = generate_expw_report(all_metrics if 'all_metrics' in locals() else {}, CONFIG)\n",
    "print(report)\n",
    "\n",
    "# Salvar relatório em arquivo\n",
    "with open(os.path.join(CONFIG['results_path'], 'expw_baseline_report.txt'), 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\n📄 Relatório salvo em: {CONFIG['results_path']}/expw_baseline_report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26811eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 20: Preparar estrutura para comparação futura com versão augmented\n",
    "comparison_structure = {\n",
    "    'baseline': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'dataset': 'EXPW',\n",
    "        'data_type': 'original_preprocessed',\n",
    "        'models': {}\n",
    "    },\n",
    "    'augmented': {\n",
    "        'timestamp': None,\n",
    "        'dataset': 'EXPW',\n",
    "        'data_type': 'with_augmentation',\n",
    "        'models': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Preencher com resultados baseline\n",
    "for model_key, model_name in [('resnet50', 'ResNet50'), \n",
    "                               ('efficientnet_b0', 'EfficientNet-B0'), \n",
    "                               ('vit_b_16', 'ViT-B/16')]:\n",
    "    if model_name in all_metrics:\n",
    "        model_metrics = all_metrics[model_name]\n",
    "        comparison_structure['baseline']['models'][model_key] = {\n",
    "            'accuracy': float(model_metrics.get('accuracy', 0)),\n",
    "            'balanced_accuracy': float(model_metrics.get('balanced_accuracy', 0)),\n",
    "            'f1_macro': float(model_metrics.get('f1_macro', 0)),\n",
    "            'f1_weighted': float(model_metrics.get('f1_weighted', 0)),\n",
    "            'cohen_kappa': float(model_metrics.get('cohen_kappa', 0))\n",
    "        }\n",
    "\n",
    "# Salvar estrutura para futura comparação\n",
    "with open(os.path.join(CONFIG['results_path'], 'expw_comparison_structure.json'), 'w') as f:\n",
    "    json.dump(comparison_structure, f, indent=2)\n",
    "\n",
    "print(\"✅ Estrutura de comparação EXPW preparada!\")\n",
    "print(\"📌 Use este arquivo para comparar com resultados augmentados:\")\n",
    "print(f\"   {CONFIG['results_path']}/expw_comparison_structure.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 TREINAMENTO BASELINE EXPW COMPLETO!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPróximos passos:\")\n",
    "print(\"1. Implementar data augmentation avançada para EXPW\")\n",
    "print(\"2. Treinar modelos com dados augmentados\")\n",
    "print(\"3. Comparar resultados usando a estrutura salva\")\n",
    "print(\"4. Analisar melhorias obtidas com augmentation\")\n",
    "print(\"5. Considerar técnicas específicas para datasets desbalanceados\")\n",
    "\n",
    "# Resumo final\n",
    "if all_metrics:\n",
    "    print(\"\\n📊 Resumo dos Resultados:\")\n",
    "    for model_name, metrics in all_metrics.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  • Accuracy: {metrics.get('accuracy', 0):.2%}\")\n",
    "        print(f\"  • F1-Score (macro): {metrics.get('f1_macro', 0):.2%}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
