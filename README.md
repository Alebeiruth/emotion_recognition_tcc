# Emotion Recognition TCC - Deep Learning Project

Um projeto abrangente de TCC focado no reconhecimento de emo√ß√µes faciais usando t√©cnicas modernas de Deep Learning. Este projeto implementa e compara diferentes arquiteturas de redes neurais para classifica√ß√£o de emo√ß√µes, incluindo an√°lises de erro detalhadas, estudos de abla√ß√£o e estrat√©gias avan√ßadas de data augmentation.

## üìã √çndice

- [Caracter√≠sticas](#caracter√≠sticas)
- [Arquiteturas Implementadas](#arquiteturas-implementadas)
- [Datasets](#datasets)
- [Requisitos do Sistema](#requisitos-do-sistema)
- [Instala√ß√£o](#instala√ß√£o)
- [Uso R√°pido](#uso-r√°pido)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Configura√ß√£o](#configura√ß√£o)
- [Experimentos](#experimentos)
- [Docker](#docker)
- [Resultados](#resultados)
- [API de Infer√™ncia](#api-de-infer√™ncia)
- [Contribui√ß√£o](#contribui√ß√£o)

## ‚ú® Caracter√≠sticas

### üß† Modelos de Deep Learning
- **EfficientNet-B0** com fine-tuning em duas fases
- **ResNet-50** com transfer learning
- **EfficientViT** para efici√™ncia computacional
- Fus√£o de classificadores para melhor performance

### üìä An√°lises Avan√ßadas
- An√°lise de erro detalhada com identifica√ß√£o de vieses
- Estudos de abla√ß√£o para componentes dos modelos
- An√°lise de drift entre datasets
- M√©tricas de fairness e equidade
- Visualiza√ß√£o de espa√ßos de features

### üîß Ferramentas e Utilit√°rios
- Monitoramento completo de recursos (CPU, GPU, mem√≥ria)
- Tracking de experimentos com Weights & Biases e MLflow
- Data augmentation robusta e adaptativa
- Containeriza√ß√£o com Docker
- Notebooks Jupyter organizados para cada experimento

### üìà M√©tricas e Visualiza√ß√µes
- Relat√≥rios detalhados de performance
- Matrizes de confus√£o interativas
- An√°lise de complexidade computacional
- Exporta√ß√£o autom√°tica de resultados em CSV

## üèóÔ∏è Arquiteturas Implementadas

| Modelo | Par√¢metros | Complexidade | Caracter√≠sticas |
|--------|------------|--------------|----------------|
| **EfficientNet-B0** | ~5.3M | Baixa-M√©dia | Compound scaling, Mobile-friendly |
| **ResNet-50** | ~25.6M | M√©dia | Skip connections, Proven architecture |
| **EfficientViT** | ~3.2M | Baixa | Vision Transformer, Efficient attention |

## üìÇ Datasets

### Principais Datasets
1. **FER2013** - 35,887 imagens em escala de cinza (48x48)
2. **RAF-DB** - 29,672 imagens de alta qualidade com anota√ß√µes
3. **DFEW** - V√≠deos din√¢micos para an√°lise temporal

### Emo√ß√µes Reconhecidas
- üò† Raiva (Anger)
- ü§¢ Desgosto (Disgust) 
- üò® Medo (Fear)
- üòä Felicidade (Happy)
- üòê Neutro (Neutral)
- üò¢ Tristeza (Sadness)
- üò≤ Surpresa (Surprise)

## üíª Requisitos do Sistema

### Hardware Recomendado
- **GPU**: NVIDIA GPU com CUDA 12.1+ (RTX 3060 ou superior)
- **RAM**: 16GB m√≠nimo, 32GB recomendado
- **Storage**: 50GB de espa√ßo livre (datasets + modelos)
- **CPU**: Intel Core i7 ou AMD Ryzen 7

### Software
- **OS**: Ubuntu 24.04 LTS (recomendado)
- **Python**: 3.8 ou superior
- **Docker**: 20.10+
- **NVIDIA Drivers**: 525.60+ para suporte CUDA

## üöÄ Instala√ß√£o

### Op√ß√£o 1: Instala√ß√£o Automatizada (Recomendada)

```bash
# Clone o reposit√≥rio
git clone https://github.com/seu-usuario/emotion-recognition-tcc.git
cd emotion-recognition-tcc

# Execute o script de setup automatizado
python scripts/setup_environment.py

# Ative o ambiente virtual
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### Op√ß√£o 2: Instala√ß√£o Manual

```bash
# 1. Criar ambiente virtual
python3.12 -m venv venv
source venv/bin/activate

# 2. Atualizar pip
pip install --upgrade pip

# 3. Instalar PyTorch com CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 4. Instalar TensorFlow com GPU
pip install tensorflow[and-cuda]

# 5. Instalar outras depend√™ncias
pip install -r requirements.txt

# 6. Instalar projeto em modo desenvolvimento
pip install -e .
```

### Op√ß√£o 3: Docker (Mais Simples)

```bash
# Build e execute o container
docker-compose up --build

# Acesse Jupyter Lab em: http://localhost:8888
```

## ‚ö° Uso R√°pido

### 1. Preparar Dados
```bash
# Baixe os datasets e organize na estrutura:
data/raw/FER2013/
data/raw/RAF-DB/DATASET/
data/raw/DFEW/

# Execute o script de download (se dispon√≠vel)
python scripts/download_datasets.py
```

### 2. Executar Experimentos

```bash
# Todos os modelos
python scripts/run_experiments.py

# Modelo espec√≠fico
python scripts/run_experiments.py --models efficientnet

# Com configura√ß√£o customizada
python scripts/run_experiments.py --config custom_config.yaml
```

### 3. Usar Notebooks

```bash
# Iniciar Jupyter Lab
jupyter lab

# Notebooks dispon√≠veis:
# - 01_exploratory_data_analysis.ipynb
# - 05_model_training_efficientnet.ipynb
# - 08_ablation_studies.ipynb
```

## üìÅ Estrutura do Projeto

```
emotion_recognition_tcc/
‚îú‚îÄ‚îÄ üìã README.md
‚îú‚îÄ‚îÄ üê≥ Dockerfile & docker-compose.yml
‚îú‚îÄ‚îÄ üì¶ requirements.txt & setup.py
‚îÇ
‚îú‚îÄ‚îÄ üîß config/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml              # Configura√ß√£o principal
‚îÇ   ‚îî‚îÄ‚îÄ model_config.py          # Configura√ß√µes de modelo
‚îÇ
‚îú‚îÄ‚îÄ üìä data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                     # Datasets originais
‚îÇ   ‚îú‚îÄ‚îÄ processed/               # Dados processados
‚îÇ   ‚îî‚îÄ‚îÄ splits/                  # Divis√µes train/val/test
‚îÇ
‚îú‚îÄ‚îÄ üìì notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploratory_data_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_model_training_efficientnet.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 08_ablation_studies.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 11_real_time_inference.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üß† src/
‚îÇ   ‚îú‚îÄ‚îÄ models/                  # Implementa√ß√µes dos modelos
‚îÇ   ‚îú‚îÄ‚îÄ data/                    # Carregamento e preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ training/                # Pipeline de treinamento
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/              # Avalia√ß√£o e m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ inference/               # Infer√™ncia em tempo real
‚îÇ   ‚îî‚îÄ‚îÄ utils/                   # Utilit√°rios
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/                    # Testes automatizados
‚îÇ
‚îú‚îÄ‚îÄ üìú scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_environment.py    # Setup automatizado
‚îÇ   ‚îú‚îÄ‚îÄ run_experiments.py      # Executor de experimentos
‚îÇ   ‚îî‚îÄ‚îÄ generate_reports.py     # Gera√ß√£o de relat√≥rios
‚îÇ
‚îî‚îÄ‚îÄ üìà results/
    ‚îú‚îÄ‚îÄ models/                  # Modelos treinados
    ‚îú‚îÄ‚îÄ logs/                    # Logs de treinamento
    ‚îú‚îÄ‚îÄ plots/                   # Visualiza√ß√µes
    ‚îî‚îÄ‚îÄ csv_outputs/             # Resultados em CSV
```

## ‚öôÔ∏è Configura√ß√£o

O arquivo `config/config.yaml` centraliza todas as configura√ß√µes:

```yaml
# Exemplo de configura√ß√µes principais
data:
  datasets:
    fer2013:
      path: "data/raw/FER2013"
    raf_db:
      path: "data/raw/RAF-DB/DATASET"
  
  preprocessing:
    image_size: 224
    normalize: true

training:
  batch_size: 32
  epochs: 0
  learning_rate: 0.001

models:
  efficientnet:
    pretrained: true
    dropout_rate: 0.5
```

### Configura√ß√µes Importantes

| Par√¢metro | Descri√ß√£o | Valor Padr√£o |
|-----------|-----------|--------------|
| `image_size` | Tamanho das imagens | 224 |
| `batch_size` | Tamanho do batch | 32 |
| `epochs` | √âpocas de treinamento | -*- |
| `validation_split` | Divis√£o para valida√ß√£o | 0.3 |
| `mixed_precision` | Precis√£o mista (GPU) | true |

## üß™ Experimentos

### Execu√ß√£o Completa
```bash
# Todos os experimentos com monitoramento
python scripts/run_experiments.py \
    --config config/config.yaml \
    --output-dir results/experiment_$(date +%Y%m%d)
```

### Experimentos Espec√≠ficos
```bash
# Apenas EfficientNet
python scripts/run_experiments.py --models efficientnet

# Compara√ß√£o de arquiteturas
python scripts/run_experiments.py --models efficientnet resnet50

# Estudos de abla√ß√£o
python scripts/run_experiments.py --config config/ablation_config.yaml
```

### Notebooks Interativos

1. **EDA** - `01_exploratory_data_analysis.ipynb`
   - An√°lise explorat√≥ria dos dados
   - Distribui√ß√£o de classes
   - Qualidade das imagens

2. **Treinamento** - `05_model_training_efficientnet.ipynb`
   - Treinamento step-by-step
   - Visualiza√ß√£o em tempo real
   - Fine-tuning detalhado

3. **Avalia√ß√£o** - `09_bias_analysis.ipynb`
   - An√°lise de vieses
   - M√©tricas de fairness
   - Casos de falha

## üê≥ Docker

### Desenvolvimento
```bash
# Ambiente completo com Jupyter
docker-compose up

# Acesso:
# - Jupyter Lab: http://localhost:8888
# - MLflow: http://localhost:5000
```

### Produ√ß√£o
```bash
# Apenas API de infer√™ncia
docker-compose --profile production up

# Acesso: http://localhost:8000
```

### Treinamento
```bash
# Container dedicado para treinamento
docker-compose --profile training up
```

### Arquivos Gerados

Cada experimento gera automaticamente:

- `model_comparison_TIMESTAMP.csv` - Compara√ß√£o entre modelos
- `efficientnet_overall_TIMESTAMP.csv` - Resultados gerais
- `efficientnet_per_class_TIMESTAMP.csv` - M√©tricas por classe
- `efficientnet_training_history_TIMESTAMP.csv` - Hist√≥rico de treinamento
- `experiment_summary_TIMESTAMP.txt` - Relat√≥rio completo

## üîå API de Infer√™ncia

### Iniciar API
```bash
# Modo desenvolvimento
python -m src.inference.model_serving

# Com Docker
docker-compose --profile production up
```

### Contribui√ß√µes
Contribui√ß√µes s√£o bem-vindas! Veja [CONTRIBUTING.md](CONTRIBUTING.md) para detalhes.

## üìö Refer√™ncias Acad√™micas

1. **EfficientNet**: Tan, M., & Le, Q. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.
2. **ResNet**: He, K., et al. (2016). Deep Residual Learning for Image Recognition.
3. **FER2013**: Goodfellow, I., et al. (2013). Challenges in Representation Learning.
4. **RAF-DB**: Li, S., et al. (2017). Reliable Crowdsourcing and Deep Locality-Preserving Learning.


## üôè Agradecimentos

- Orientador: Prof. Rayson Laroca
- Pontif√≠cia Universidade Cat√≥lica do Paran√°
- Comunidade open-source do TensorFlow e PyTorch
- Datasets disponibilizados publicamente

---

**üìß Contato**: alexandre.beiruth@pucpr.edu.br 
**üîó LinkedIn**: https://www.linkedin.com/in/alexandre-beiruth-bcc/

> Este projeto foi desenvolvido como Trabalho de Conclus√£o de Curso (TCC) em Ci√™ncia da Computa√ß√£o, focando na aplica√ß√£o pr√°tica de t√©cnicas modernas de Deep Learning para reconhecimento de emo√ß√µes faciais.